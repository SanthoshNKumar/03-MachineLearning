{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TV  Radio  News  Sales\n",
      "0  230.1   37.8  69.1   22.1\n",
      "1   44.5   39.3  23.1   10.4\n",
      "2   17.2   45.9  34.7   18.3\n",
      "3  151.5   41.3  13.2   18.5\n",
      "Input Data = X\n",
      "      TV  Radio  News\n",
      "0  230.1   37.8  69.1\n",
      "1   44.5   39.3  23.1\n",
      "2   17.2   45.9  34.7\n",
      "3  151.5   41.3  13.2\n",
      "Shape of input X (4, 3) \n",
      "\n",
      "Target = y\n",
      "0    22.1\n",
      "1    10.4\n",
      "2    18.3\n",
      "3    18.5\n",
      "Name: Sales, dtype: float64\n",
      "Shape of input y (4,) \n",
      "\n",
      "No of training samples : 4 \n",
      "\n",
      "Normalize the Input data X\n",
      "         TV     Radio      News\n",
      "0  1.399713 -1.073807  1.615424\n",
      "1 -0.778336 -0.581987 -0.565339\n",
      "2 -1.098706  1.582020 -0.015408\n",
      "3  0.477328  0.073773 -1.034678 \n",
      "\n",
      "[[ 1.          1.39971314 -1.07380656  1.6154245 ]\n",
      " [ 1.         -0.77833556 -0.58198676 -0.56533931]\n",
      " [ 1.         -1.09870587  1.58202036 -0.01540757]\n",
      " [ 1.          0.47732829  0.07377297 -1.03467761]]\n",
      "Shape of X (4, 4) \n",
      "\n",
      "[[22.1]\n",
      " [10.4]\n",
      " [18.3]\n",
      " [18.5]]\n",
      "Shape of y (4, 1) \n",
      "\n",
      "alpha : 0.01\n",
      "num_iters : 400 \n",
      "\n",
      "theta :\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Shape of theta (4, 1) \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  0\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-22.1]\n",
      " [-10.4]\n",
      " [-18.3]\n",
      " [-18.5]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[488.41]\n",
      " [108.16]\n",
      " [334.89]\n",
      " [342.25]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  159.21375 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[0.17325   ]\n",
      " [0.02890807]\n",
      " [0.00132996]\n",
      " [0.02599465]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  1\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[0.25427726]\n",
      " [0.13528001]\n",
      " [0.14319205]\n",
      " [0.16025068]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-21.84572274]\n",
      " [-10.26471999]\n",
      " [-18.15680795]\n",
      " [-18.33974932]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[477.23560184]\n",
      " [105.36447651]\n",
      " [329.66967487]\n",
      " [336.34640528]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  156.07701981290077 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[0.3447675 ]\n",
      " [0.05739166]\n",
      " [0.00294348]\n",
      " [0.05157361]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  2\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[0.50525191]\n",
      " [0.26922787]\n",
      " [0.28557296]\n",
      " [0.31901725]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-21.59474809]\n",
      " [-10.13077213]\n",
      " [-18.01442704]\n",
      " [-18.18098275]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[466.33314509]\n",
      " [102.63254385]\n",
      " [324.51958152]\n",
      " [330.54813361]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  153.0041755089866 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[0.51456983]\n",
      " [0.08545929]\n",
      " [0.00483322]\n",
      " [0.07674448]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  3\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[0.75297328]\n",
      " [0.40185428]\n",
      " [0.42713901]\n",
      " [0.47631273]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-21.34702672]\n",
      " [ -9.99814572]\n",
      " [-17.87286099]\n",
      " [-18.02368727]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[455.69554959]\n",
      " [ 99.96291792]\n",
      " [319.4391601 ]\n",
      " [324.85330268]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  149.99386628731892 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[0.68267413]\n",
      " [0.11311929]\n",
      " [0.00699203]\n",
      " [0.10151468]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  4\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[0.9974899 ]\n",
      " [0.53316985]\n",
      " [0.56788674]\n",
      " [0.63215002]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-21.1025101 ]\n",
      " [ -9.86683015]\n",
      " [-17.73211326]\n",
      " [-17.86784998]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[445.31593251]\n",
      " [ 97.35433731]\n",
      " [314.42784065]\n",
      " [319.26006286]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  147.04477166600037 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[0.84909739]\n",
      " [0.14037982]\n",
      " [0.00941291]\n",
      " [0.12589151]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  5\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[1.23884945]\n",
      " [0.66318517]\n",
      " [0.70781299]\n",
      " [0.78654193]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-20.86115055]\n",
      " [ -9.73681483]\n",
      " [-17.59218701]\n",
      " [-17.71345807]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[435.18760241]\n",
      " [ 94.80556299]\n",
      " [309.48504384]\n",
      " [313.76659663]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  144.15560073516664 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[1.01385641]\n",
      " [0.16724885]\n",
      " [0.012089  ]\n",
      " [0.14988211]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  6\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[1.47709881]\n",
      " [0.7919108 ]\n",
      " [0.84691484]\n",
      " [0.9395012 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-20.62290119]\n",
      " [ -9.6080892 ]\n",
      " [-17.45308516]\n",
      " [-17.5604988 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[425.30405367]\n",
      " [ 92.31537805]\n",
      " [304.61018166]\n",
      " [308.37111806]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  141.32509143080284 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[1.17696785]\n",
      " [0.19373421]\n",
      " [0.01501359]\n",
      " [0.17349347]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  7\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[1.71228407]\n",
      " [0.91935723]\n",
      " [0.98518963]\n",
      " [1.09104046]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-20.38771593]\n",
      " [ -9.48064277]\n",
      " [-17.31481037]\n",
      " [-17.40895954]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[415.6589609 ]\n",
      " [ 89.88258729]\n",
      " [299.80265809]\n",
      " [303.07187234]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  138.55200982872296 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[1.33844817]\n",
      " [0.21984355]\n",
      " [0.01818015]\n",
      " [0.19673246]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  8\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[1.94445055]\n",
      " [1.04553492]\n",
      " [1.12263496]\n",
      " [1.24117225]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-20.15554945]\n",
      " [ -9.35446508]\n",
      " [-17.17736504]\n",
      " [-17.25882775]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[406.24617367]\n",
      " [ 87.506017  ]\n",
      " [295.06186974]\n",
      " [297.86713525]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  135.83514945807434 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[1.49831369]\n",
      " [0.24558438]\n",
      " [0.02158225]\n",
      " [0.2196058 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  9\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[2.1736428 ]\n",
      " [1.17045426]\n",
      " [1.25924865]\n",
      " [1.38990904]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-19.9263572 ]\n",
      " [ -9.22954574]\n",
      " [-17.04075135]\n",
      " [-17.11009096]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[397.05971133]\n",
      " [ 85.18451459]\n",
      " [290.3872065 ]\n",
      " [292.75521265]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  133.17333063375278 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[1.65658055]\n",
      " [0.27096402]\n",
      " [0.02521362]\n",
      " [0.24212009]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  10\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[2.39990462]\n",
      " [1.29412562]\n",
      " [1.39502878]\n",
      " [1.53726319]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-19.70009538]\n",
      " [ -9.10587438]\n",
      " [-16.90497122]\n",
      " [-16.96273681]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[388.09375802]\n",
      " [ 82.9169483 ]\n",
      " [285.7780521 ]\n",
      " [287.73444005]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  130.5653998071338 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[1.81326474]\n",
      " [0.29598967]\n",
      " [0.02906815]\n",
      " [0.26428179]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  11\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[2.62327908]\n",
      " [1.4165593 ]\n",
      " [1.52997362]\n",
      " [1.68324698]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-19.47672092]\n",
      " [ -8.9834407 ]\n",
      " [-16.77002638]\n",
      " [-16.81675302]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[379.34265782]\n",
      " [ 80.70220688]\n",
      " [281.23378472]\n",
      " [282.80318205]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  128.01022893454723 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[1.9683821 ]\n",
      " [0.32066836]\n",
      " [0.03313983]\n",
      " [0.28609723]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  12\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[2.84380853]\n",
      " [1.53776556]\n",
      " [1.6640817 ]\n",
      " [1.8278726 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-19.25619147]\n",
      " [ -8.86223444]\n",
      " [-16.6359183 ]\n",
      " [-16.6721274 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[370.80091009]\n",
      " [ 78.53919932]\n",
      " [276.75377755]\n",
      " [277.95983194]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  125.50671486294357 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[2.12194828]\n",
      " [0.34500698]\n",
      " [0.03742279]\n",
      " [0.30757262]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  13\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[3.0615346 ]\n",
      " [1.65775461]\n",
      " [1.79735175]\n",
      " [1.97115215]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-19.0384654 ]\n",
      " [ -8.74224539]\n",
      " [-16.50264825]\n",
      " [-16.52884785]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[362.46316488]\n",
      " [ 76.4268545 ]\n",
      " [272.33739929]\n",
      " [273.20281118]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  123.05377873221633 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[2.27397879]\n",
      " [0.36901228]\n",
      " [0.04191131]\n",
      " [0.32871406]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  14\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[3.27649824]\n",
      " [1.7765366 ]\n",
      " [1.92978269]\n",
      " [2.11309764]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-18.82350176]\n",
      " [ -8.6234634 ]\n",
      " [-16.37021731]\n",
      " [-16.38690236]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[354.32421856]\n",
      " [ 74.36412095]\n",
      " [267.9840147 ]\n",
      " [268.53056895]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  120.65036539366777 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[2.42448901]\n",
      " [0.39269087]\n",
      " [0.04659978]\n",
      " [0.3495275 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  15\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[3.48873971]\n",
      " [1.89412165]\n",
      " [2.06137367]\n",
      " [2.25372099]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-18.61126029]\n",
      " [ -8.50587835]\n",
      " [-16.23862633]\n",
      " [-16.24627901]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[346.37900952]\n",
      " [ 72.34996648]\n",
      " [263.69298506]\n",
      " [263.94158169]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  118.2954428441192 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[2.57349412]\n",
      " [0.4160492 ]\n",
      " [0.0514827 ]\n",
      " [0.3700188 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  16\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[3.69829861]\n",
      " [2.01051981]\n",
      " [2.19212402]\n",
      " [2.39303403]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-18.40170139]\n",
      " [ -8.38948019]\n",
      " [-16.10787598]\n",
      " [-16.10696597]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[338.62261408]\n",
      " [ 70.38337794]\n",
      " [259.46366868]\n",
      " [259.4343527 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  115.98800167518641 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[2.72100917]\n",
      " [0.43909361]\n",
      " [0.05655473]\n",
      " [0.39019369]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  17\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[3.90521387]\n",
      " [2.12574106]\n",
      " [2.32203325]\n",
      " [2.53104851]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-18.19478613]\n",
      " [ -8.27425894]\n",
      " [-15.97796675]\n",
      " [-15.96895149]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[331.05024245]\n",
      " [ 68.46336092]\n",
      " [255.29542133]\n",
      " [255.0074116 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  113.72705453725683 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[2.86704908]\n",
      " [0.4618303 ]\n",
      " [0.06181062]\n",
      " [0.41005779]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  18\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[4.10952377]\n",
      " [2.23979538]\n",
      " [2.45110109]\n",
      " [2.66777609]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-17.99047623]\n",
      " [ -8.16020462]\n",
      " [-15.84889891]\n",
      " [-15.83222391]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[323.65723483]\n",
      " [ 66.58893945]\n",
      " [251.18759669]\n",
      " [250.65931398]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  111.51163561772104 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[3.01162859]\n",
      " [0.48426535]\n",
      " [0.06724524]\n",
      " [0.42961662]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  19\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[4.31126599]\n",
      " [2.35269264]\n",
      " [2.57932741]\n",
      " [2.80322833]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-17.78873401]\n",
      " [ -8.04730736]\n",
      " [-15.72067259]\n",
      " [-15.69677167]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[316.43905768]\n",
      " [ 64.7591557 ]\n",
      " [247.13954675]\n",
      " [246.38864093]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  109.34080013302578 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[3.15476231]\n",
      " [0.50640469]\n",
      " [0.07285358]\n",
      " [0.44887557]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  20\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[4.51047755]\n",
      " [2.4644427 ]\n",
      " [2.70671227]\n",
      " [2.93741671]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-17.58952245]\n",
      " [ -7.9355573 ]\n",
      " [-15.59328773]\n",
      " [-15.56258329]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[309.39130007]\n",
      " [ 62.97306974]\n",
      " [243.15062224]\n",
      " [242.19399862]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  107.2136238341316 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[3.29646468]\n",
      " [0.52825415]\n",
      " [0.07863074]\n",
      " [0.46783995]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  21\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[4.70719488]\n",
      " [2.57505532]\n",
      " [2.8332559 ]\n",
      " [3.07035263]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-17.39280512]\n",
      " [ -7.82494468]\n",
      " [-15.4667441 ]\n",
      " [-15.42964737]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[302.50967012]\n",
      " [ 61.2297592 ]\n",
      " [239.22017301]\n",
      " [238.07401788]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  105.12920252497169 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[3.43675004]\n",
      " [0.54981943]\n",
      " [0.08457192]\n",
      " [0.48651495]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  22\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[4.9014538 ]\n",
      " [2.68454026]\n",
      " [2.95895869]\n",
      " [3.2020474 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-17.1985462 ]\n",
      " [ -7.71545974]\n",
      " [-15.34104131]\n",
      " [-15.2979526 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[295.78999155]\n",
      " [ 59.52831904]\n",
      " [235.34754835]\n",
      " [234.0273538 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  103.08665159352222 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[3.57563254]\n",
      " [0.5711061 ]\n",
      " [0.09067244]\n",
      " [0.50490566]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  23\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[5.09328955]\n",
      " [2.79290717]\n",
      " [3.08382119]\n",
      " [3.33251223]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-17.00671045]\n",
      " [ -7.60709283]\n",
      " [-15.21617881]\n",
      " [-15.16748777]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[289.22820042]\n",
      " [ 57.86786127]\n",
      " [231.53209743]\n",
      " [230.05268531]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  101.08510555510773 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[3.71312621]\n",
      " [0.59211962]\n",
      " [0.09692772]\n",
      " [0.52301707]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  24\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[5.28273679]\n",
      " [2.90016569]\n",
      " [3.2078441 ]\n",
      " [3.46175825]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-16.81726321]\n",
      " [ -7.49983431]\n",
      " [-15.0921559 ]\n",
      " [-15.03824175]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[282.82034186]\n",
      " [ 56.24751465]\n",
      " [227.77316957]\n",
      " [226.14871478]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  99.12371760757804 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[3.84924495]\n",
      " [0.61286536]\n",
      " [0.10333327]\n",
      " [0.54085407]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  25\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[5.46982962]\n",
      " [3.00632538]\n",
      " [3.33102827]\n",
      " [3.58979653]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-16.63017038]\n",
      " [ -7.39367462]\n",
      " [-14.96897173]\n",
      " [-14.91020347]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[276.56256695]\n",
      " [ 54.66642442]\n",
      " [224.07011457]\n",
      " [222.31416764]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  97.2016591980049 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[3.9840025 ]\n",
      " [0.63334854]\n",
      " [0.10988473]\n",
      " [0.55842147]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  26\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[5.65460156]\n",
      " [3.11139574]\n",
      " [3.45337469]\n",
      " [3.716638  ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-16.44539844]\n",
      " [ -7.28860426]\n",
      " [-14.84662531]\n",
      " [-14.783362  ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[270.4511297 ]\n",
      " [ 53.1237521 ]\n",
      " [220.42228306]\n",
      " [218.54779195]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  95.3181196005589 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[4.11741247]\n",
      " [0.6535743 ]\n",
      " [0.1165778 ]\n",
      " [0.57572398]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  27\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[5.83708562]\n",
      " [3.21538622]\n",
      " [3.57488449]\n",
      " [3.84229356]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-16.26291438]\n",
      " [ -7.18461378]\n",
      " [-14.72511551]\n",
      " [-14.65770644]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[264.48238409]\n",
      " [ 51.61867512]\n",
      " [216.82902674]\n",
      " [214.84835809]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  93.47230550523767 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[4.24948835]\n",
      " [0.67354765]\n",
      " [0.1234083 ]\n",
      " [0.59276619]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  28\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[6.01731424]\n",
      " [3.31830623]\n",
      " [3.69555894]\n",
      " [3.96677399]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-16.08268576]\n",
      " [ -7.08169377]\n",
      " [-14.60444106]\n",
      " [-14.53322601]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[258.65278127]\n",
      " [ 50.15038665]\n",
      " [213.2896987 ]\n",
      " [211.21465831]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  91.66344061712881 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[4.38024347]\n",
      " [0.69327352]\n",
      " [0.13037214]\n",
      " [0.60955265]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  29\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[6.19531934]\n",
      " [3.4201651 ]\n",
      " [3.81539943]\n",
      " [4.09008999]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-15.90468066]\n",
      " [ -6.9798349 ]\n",
      " [-14.48460057]\n",
      " [-14.40991001]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[252.95886674]\n",
      " [ 48.7180953 ]\n",
      " [209.80365369]\n",
      " [207.6455064 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  89.89076526589942 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[4.50969103]\n",
      " [0.71275672]\n",
      " [0.13746532]\n",
      " [0.62608778]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  30\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[6.37113235]\n",
      " [3.5209721 ]\n",
      " [3.93440748]\n",
      " [4.2122522 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-15.72886765]\n",
      " [ -6.8790279 ]\n",
      " [-14.36559252]\n",
      " [-14.2877478 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[247.3972777 ]\n",
      " [ 47.32102487]\n",
      " [206.37024833]\n",
      " [204.13973729]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  88.1535360252164 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[4.63784412]\n",
      " [0.73200196]\n",
      " [0.14468393]\n",
      " [0.64237593]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  31\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[6.54478414]\n",
      " [3.62073646]\n",
      " [4.05258475]\n",
      " [4.33327113]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-15.55521586]\n",
      " [ -6.77926354]\n",
      " [-14.24741525]\n",
      " [-14.16672887]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[241.96474045]\n",
      " [ 45.95841411]\n",
      " [202.98884142]\n",
      " [200.69620676]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  86.45102534180967 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[4.76471568]\n",
      " [0.75101386]\n",
      " [0.15202415]\n",
      " [0.65842137]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  32\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[6.71630513]\n",
      " [3.71946735]\n",
      " [4.16993298]\n",
      " [4.45315726]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-15.38369487]\n",
      " [ -6.68053265]\n",
      " [-14.13006702]\n",
      " [-14.04684274]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[236.65806785]\n",
      " [ 44.62951645]\n",
      " [199.65879411]\n",
      " [197.31379098]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  84.78252117390132 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[4.89031852]\n",
      " [0.76979694]\n",
      " [0.15948225]\n",
      " [0.67422829]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  33\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[6.88572523]\n",
      " [3.81717388]\n",
      " [4.28645405]\n",
      " [4.57192094]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-15.21427477]\n",
      " [ -6.58282612]\n",
      " [-14.01354595]\n",
      " [-13.92807906]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[231.47415692]\n",
      " [ 43.33359977]\n",
      " [196.37947017]\n",
      " [193.99138625]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  83.14732663873137 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.01466534]\n",
      " [0.78835562]\n",
      " [0.16705456]\n",
      " [0.68980078]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  34\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[7.05307385]\n",
      " [3.91386508]\n",
      " [4.40214995]\n",
      " [4.68957247]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-15.04692615]\n",
      " [ -6.48613492]\n",
      " [-13.89785005]\n",
      " [-13.81042753]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[226.40998642]\n",
      " [ 42.06994618]\n",
      " [193.15023615]\n",
      " [190.72790861]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  81.54475966892105 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.13776868]\n",
      " [0.80669425]\n",
      " [0.17473752]\n",
      " [0.70514286]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  35\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[7.21837998]\n",
      " [4.00954996]\n",
      " [4.51702276]\n",
      " [4.80612204]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-14.88162002]\n",
      " [ -6.39045004]\n",
      " [-13.78297724]\n",
      " [-13.69387796]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[221.46261455]\n",
      " [ 40.83785172]\n",
      " [189.97046162]\n",
      " [187.52229353]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  79.97415267742169 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.259641  ]\n",
      " [0.82481705]\n",
      " [0.18252765]\n",
      " [0.72025849]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  36\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[7.38167208]\n",
      " [4.10423744]\n",
      " [4.63107468]\n",
      " [4.92157979]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-14.71832792]\n",
      " [ -6.29576256]\n",
      " [-13.66892532]\n",
      " [-13.57842021]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[216.62917679]\n",
      " [ 39.63662617]\n",
      " [186.83951936]\n",
      " [184.37349553]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  78.43485223080607 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.38029459]\n",
      " [0.84272819]\n",
      " [0.19042152]\n",
      " [0.73515152]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  37\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[7.5429782 ]\n",
      " [4.19793641]\n",
      " [4.744308  ]\n",
      " [5.03595574]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-14.5570218 ]\n",
      " [ -6.20206359]\n",
      " [-13.555692  ]\n",
      " [-13.46404426]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[211.90688362]\n",
      " [ 38.46559283]\n",
      " [183.75678549]\n",
      " [181.28048791]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  76.92621873066686 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.49974164]\n",
      " [0.86043174]\n",
      " [0.19841582]\n",
      " [0.74982575]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  38\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[7.70232593]\n",
      " [4.29065566]\n",
      " [4.85672511]\n",
      " [5.14925986]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-14.39767407]\n",
      " [ -6.10934434]\n",
      " [-13.44327489]\n",
      " [-13.35074014]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[207.29301853]\n",
      " [ 37.32408823]\n",
      " [180.72163969]\n",
      " [178.24226238]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  75.4476261028943 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.61799423]\n",
      " [0.87793168]\n",
      " [0.20650728]\n",
      " [0.76428491]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  39\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[7.85974242]\n",
      " [4.38240397]\n",
      " [4.96832849]\n",
      " [5.26150202]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-14.24025758]\n",
      " [ -6.01759603]\n",
      " [-13.33167151]\n",
      " [-13.23849798]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[202.7849359 ]\n",
      " [ 36.21146196]\n",
      " [177.73346533]\n",
      " [175.25782876]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  73.99846149461231 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.73506428]\n",
      " [0.8952319 ]\n",
      " [0.21469272]\n",
      " [0.77853264]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  40\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[8.01525438]\n",
      " [4.47319003]\n",
      " [5.07912069]\n",
      " [5.37269202]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-14.08474562]\n",
      " [ -5.92680997]\n",
      " [-13.22087931]\n",
      " [-13.12730798]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[198.38005908]\n",
      " [ 35.12707642]\n",
      " [174.79164963]\n",
      " [172.32621469]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  72.57812497855986 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.85096364]\n",
      " [0.91233624]\n",
      " [0.22296903]\n",
      " [0.79257252]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  41\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[8.16888811]\n",
      " [4.56302248]\n",
      " [5.18910438]\n",
      " [5.48283959]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-13.93111189]\n",
      " [ -5.83697752]\n",
      " [-13.11089562]\n",
      " [-13.01716041]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[194.07587843]\n",
      " [ 34.0703066 ]\n",
      " [171.89558383]\n",
      " [169.44646526]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  71.18602926471027 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[5.965704  ]\n",
      " [0.92924842]\n",
      " [0.23133317]\n",
      " [0.80640805]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  42\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[8.32066948]\n",
      " [4.65190989]\n",
      " [5.2982823 ]\n",
      " [5.59195434]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-13.77933052]\n",
      " [ -5.74809011]\n",
      " [-13.0017177 ]\n",
      " [-12.90804566]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[189.86994948]\n",
      " [ 33.04053986]\n",
      " [169.04466325]\n",
      " [166.61764276]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  69.82159941892886 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.07929696]\n",
      " [0.94597212]\n",
      " [0.23978216]\n",
      " [0.82004269]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  43\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[8.47062396]\n",
      " [4.7398608 ]\n",
      " [5.40665724]\n",
      " [5.70004584]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-13.62937604]\n",
      " [ -5.6601392 ]\n",
      " [-12.89334276]\n",
      " [-12.79995416]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[185.75989112]\n",
      " [ 32.03717573]\n",
      " [166.23828749]\n",
      " [163.83882638]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  68.48427258847452 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.19175399]\n",
      " [0.96251092]\n",
      " [0.24831312]\n",
      " [0.83347981]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  44\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[8.61877662]\n",
      " [4.82688367]\n",
      " [5.51423211]\n",
      " [5.80712358]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-13.48122338]\n",
      " [ -5.57311633]\n",
      " [-12.78576789]\n",
      " [-12.69287642]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[181.74338383]\n",
      " [ 31.05962566]\n",
      " [163.4758605 ]\n",
      " [161.10911188]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  67.1734977341575 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.30308645]\n",
      " [0.97886832]\n",
      " [0.25692319]\n",
      " [0.84672272]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  45\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[8.76515212]\n",
      " [4.91298689]\n",
      " [5.62100987]\n",
      " [5.91319694]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-13.33484788]\n",
      " [ -5.48701311]\n",
      " [-12.67899013]\n",
      " [-12.58680306]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[177.81816801]\n",
      " [ 30.10731287]\n",
      " [160.75679074]\n",
      " [158.42761134]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  65.88873536897155 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.41330559]\n",
      " [0.99504777]\n",
      " [0.26560962]\n",
      " [0.85977467]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  46\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[8.90977474]\n",
      " [4.99817882]\n",
      " [5.72699355]\n",
      " [6.01827525]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-13.19022526]\n",
      " [ -5.40182118]\n",
      " [-12.57300645]\n",
      " [-12.48172475]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[173.98204229]\n",
      " [ 29.17967208]\n",
      " [158.08049122]\n",
      " [155.79345284]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  64.62945730302422 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.52242253]\n",
      " [1.01105264]\n",
      " [0.27436969]\n",
      " [0.87263885]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  47\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[9.0526684 ]\n",
      " [5.08246774]\n",
      " [5.83218625]\n",
      " [6.12236775]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-13.0473316 ]\n",
      " [ -5.31753226]\n",
      " [-12.46781375]\n",
      " [-12.37763225]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[170.23286196]\n",
      " [ 28.27614936]\n",
      " [155.44637963]\n",
      " [153.2057802 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  63.39514639459403 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.63044831]\n",
      " [1.02688621]\n",
      " [0.28320075]\n",
      " [0.88531838]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  48\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[9.1938566 ]\n",
      " [5.16586188]\n",
      " [5.93659115]\n",
      " [6.22548361]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-12.9061434 ]\n",
      " [ -5.23413812]\n",
      " [-12.36340885]\n",
      " [-12.27451639]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[166.5685374 ]\n",
      " [ 27.39620189]\n",
      " [152.85387845]\n",
      " [150.66375272]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  62.18529630714953 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.73739383]\n",
      " [1.04255173]\n",
      " [0.29210023]\n",
      " [0.89781632]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  49\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[9.33336252]\n",
      " [5.24836941]\n",
      " [6.04021146]\n",
      " [6.32763191]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-12.76663748]\n",
      " [ -5.15163059]\n",
      " [-12.25978854]\n",
      " [-12.17236809]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[162.98703255]\n",
      " [ 26.53929778]\n",
      " [150.30241498]\n",
      " [148.16654487]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  60.999411272169645 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.84326989]\n",
      " [1.05805235]\n",
      " [0.3010656 ]\n",
      " [0.9101357 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  50\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[9.47120895]\n",
      " [5.32999843]\n",
      " [6.14305049]\n",
      " [6.42882168]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-12.62879105]\n",
      " [ -5.07000157]\n",
      " [-12.15694951]\n",
      " [-12.07117832]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[159.48636346]\n",
      " [ 25.70491587]\n",
      " [147.79142147]\n",
      " [145.71334606]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  59.83700585760943 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[6.94808719]\n",
      " [1.07339116]\n",
      " [0.31009439]\n",
      " [0.92227945]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  51\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[9.60741833]\n",
      " [5.41075702]\n",
      " [6.24511157]\n",
      " [6.52906184]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-12.49258167]\n",
      " [ -4.98924298]\n",
      " [-12.05488843]\n",
      " [-11.97093816]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[156.06459689]\n",
      " [ 24.89254555]\n",
      " [145.32033514]\n",
      " [143.30336035]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  58.6976047418611 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.05185632]\n",
      " [1.0885712 ]\n",
      " [0.31918419]\n",
      " [0.93425047]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  52\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[9.74201275]\n",
      " [5.49065314]\n",
      " [6.3463981 ]\n",
      " [6.62836127]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-12.35798725]\n",
      " [ -4.90934686]\n",
      " [-11.9536019 ]\n",
      " [-11.87163873]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[152.71984889]\n",
      " [ 24.10168655]\n",
      " [142.88859831]\n",
      " [140.9358062 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  57.580742493063696 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.15458775]\n",
      " [1.10359544]\n",
      " [0.32833265]\n",
      " [0.94605161]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  53\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[9.87501397]\n",
      " [5.56969476]\n",
      " [6.44691355]\n",
      " [6.72672874]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-12.22498603]\n",
      " [ -4.83030524]\n",
      " [-11.85308645]\n",
      " [-11.77327126]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[149.45028345]\n",
      " [ 23.33184876]\n",
      " [140.49565838]\n",
      " [138.60991625]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  56.485963353619695 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.25629188]\n",
      " [1.11846678]\n",
      " [0.33753748]\n",
      " [0.95768564]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  54\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[10.0064434 ]\n",
      " [ 5.64788973]\n",
      " [ 6.54666141]\n",
      " [ 6.82417296]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-12.0935566 ]\n",
      " [ -4.75211027]\n",
      " [-11.75333859]\n",
      " [-11.67582704]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[146.25411124]\n",
      " [ 22.58255206]\n",
      " [138.14096795]\n",
      " [136.32493699]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  55.41282102978154 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.35697896]\n",
      " [1.13318806]\n",
      " [0.34679641]\n",
      " [0.9691553 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  55\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[10.13632212]\n",
      " [ 5.72524588]\n",
      " [ 6.64564524]\n",
      " [ 6.92070259]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-11.96367788]\n",
      " [ -4.67475412]\n",
      " [-11.65435476]\n",
      " [-11.57929741]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[143.12958832]\n",
      " [ 21.85332613]\n",
      " [135.82398483]\n",
      " [134.08012862]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  54.36087848617403 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.45665917]\n",
      " [1.14776208]\n",
      " [0.35610728]\n",
      " [0.98046328]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  56\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[10.2646709 ]\n",
      " [ 5.80177097]\n",
      " [ 6.74386864]\n",
      " [ 7.01632617]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-11.8353291 ]\n",
      " [ -4.59822903]\n",
      " [-11.55613136]\n",
      " [-11.48367383]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[140.07501489]\n",
      " [ 21.14371026]\n",
      " [133.54417211]\n",
      " [131.87476471]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  53.32970774512412 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.55534258]\n",
      " [1.16219157]\n",
      " [0.36546792]\n",
      " [0.9916122 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  57\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[10.39151017]\n",
      " [ 5.8774727 ]\n",
      " [ 6.84133524]\n",
      " [ 7.1110522 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-11.70848983]\n",
      " [ -4.5225273 ]\n",
      " [-11.45866476]\n",
      " [-11.3889478 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[137.08873413]\n",
      " [ 20.45325319]\n",
      " [131.30099818]\n",
      " [129.70813203]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  52.31888969067178 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.65303915]\n",
      " [1.17647919]\n",
      " [0.37487625]\n",
      " [1.00260465]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  58\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\insakum46\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:35: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[10.51686005]\n",
      " [ 5.95235872]\n",
      " [ 6.93804873]\n",
      " [ 7.2048891 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-11.58313995]\n",
      " [ -4.44764128]\n",
      " [-11.36195127]\n",
      " [-11.2951109 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[134.16913104]\n",
      " [ 19.78151294]\n",
      " [129.09393676]\n",
      " [127.57953028]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  51.32801387714106 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.74975876]\n",
      " [1.19062756]\n",
      " [0.38433023]\n",
      " [1.01344316]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  59\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[10.64074037]\n",
      " [ 6.02643662]\n",
      " [ 7.03401283]\n",
      " [ 7.29784521]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-11.45925963]\n",
      " [ -4.37356338]\n",
      " [-11.26598717]\n",
      " [-11.20215479]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[131.31463127]\n",
      " [ 19.12805662]\n",
      " [126.92246697]\n",
      " [125.48827188]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  50.35667834215244 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.84551117]\n",
      " [1.20463925]\n",
      " [0.39382787]\n",
      " [1.02413021]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  60\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[10.76317063]\n",
      " [ 6.09971393]\n",
      " [ 7.1292313 ]\n",
      " [ 7.38992881]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-11.33682937]\n",
      " [ -4.30028607]\n",
      " [-11.1707687 ]\n",
      " [-11.11007119]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[128.52370007]\n",
      " [ 18.49246027]\n",
      " [124.78607331]\n",
      " [123.43368174]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  49.404489423962374 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[7.94030606]\n",
      " [1.21851676]\n",
      " [0.4033672 ]\n",
      " [1.03466825]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  61\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[10.88417006]\n",
      " [ 6.17219812]\n",
      " [ 7.22370794]\n",
      " [ 7.48114811]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-11.21582994]\n",
      " [ -4.22780188]\n",
      " [-11.07629206]\n",
      " [-11.01885189]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[125.79484123]\n",
      " [ 17.87430872]\n",
      " [122.68424569]\n",
      " [121.41509703]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  48.471061583018596 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.034153  ]\n",
      " [1.23226256]\n",
      " [0.41294634]\n",
      " [1.04505966]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  62\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.00375757]\n",
      " [ 6.24389661]\n",
      " [ 7.31744659]\n",
      " [ 7.57151122]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-11.09624243]\n",
      " [ -4.15610339]\n",
      " [-10.98255341]\n",
      " [-10.92848878]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[123.12659601]\n",
      " [ 17.27319538]\n",
      " [120.61647948]\n",
      " [119.43186696]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  47.55601722762306 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.12706147]\n",
      " [1.24587904]\n",
      " [0.42256343]\n",
      " [1.0553068 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  63\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.12195181]\n",
      " [ 6.31481676]\n",
      " [ 7.41045109]\n",
      " [ 7.66102622]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.97804819]\n",
      " [ -4.08518324]\n",
      " [-10.88954891]\n",
      " [-10.83897378]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[120.51754215]\n",
      " [ 16.68872212]\n",
      " [118.58227549]\n",
      " [117.48335258]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  46.65898654359779 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.21904085]\n",
      " [1.25936857]\n",
      " [0.43221665]\n",
      " [1.06541197]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  64\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.23877111]\n",
      " [ 6.38496586]\n",
      " [ 7.50272534]\n",
      " [ 7.74970109]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.86122889]\n",
      " [ -4.01503414]\n",
      " [-10.79727466]\n",
      " [-10.75029891]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[117.96629294]\n",
      " [ 16.12049911]\n",
      " [116.58114   ]\n",
      " [115.56892657]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  45.77960732785183 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.31010045]\n",
      " [1.27273346]\n",
      " [0.44190424]\n",
      " [1.07537744]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  65\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.35423357]\n",
      " [ 6.45435118]\n",
      " [ 7.59427327]\n",
      " [ 7.83754376]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.74576643]\n",
      " [ -3.94564882]\n",
      " [-10.70572673]\n",
      " [-10.66245624]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[115.4714962 ]\n",
      " [ 15.56814464]\n",
      " [114.61258476]\n",
      " [113.687973  ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  44.9175248257502 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.40024944]\n",
      " [1.28597596]\n",
      " [0.45162446]\n",
      " [1.08520541]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  66\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.46835697]\n",
      " [ 6.52297988]\n",
      " [ 7.68509882]\n",
      " [ 7.92456208]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.63164303]\n",
      " [ -3.87702012]\n",
      " [-10.61490118]\n",
      " [-10.57543792]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[113.03183342]\n",
      " [ 15.03128498]\n",
      " [112.67612701]\n",
      " [111.83988717]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  44.07239157218915 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.48949695]\n",
      " [1.29909828]\n",
      " [0.46137563]\n",
      " [1.09489807]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  67\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.58115886]\n",
      " [ 6.59085912]\n",
      " [ 7.77520597]\n",
      " [ 8.01076383]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.51884114]\n",
      " [ -3.80914088]\n",
      " [-10.52479403]\n",
      " [-10.48923617]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[110.64601884]\n",
      " [ 14.50955423]\n",
      " [110.77128945]\n",
      " [110.02407537]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  43.2438672362842 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.57785198]\n",
      " [1.3121026 ]\n",
      " [0.47115611]\n",
      " [1.10445757]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  68\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.69265651]\n",
      " [ 6.65799597]\n",
      " [ 7.8645987 ]\n",
      " [ 8.09615673]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.40734349]\n",
      " [ -3.74200403]\n",
      " [-10.4354013 ]\n",
      " [-10.40384327]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[108.31279857]\n",
      " [ 14.0025942 ]\n",
      " [108.89760026]\n",
      " [108.23995473]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  42.43161846958049 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.66532346]\n",
      " [1.32499103]\n",
      " [0.48096428]\n",
      " [1.11388599]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  69\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.80286691]\n",
      " [ 6.72439744]\n",
      " [ 7.95328105]\n",
      " [ 8.18074843]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.29713309]\n",
      " [ -3.67560256]\n",
      " [-10.34671895]\n",
      " [-10.31925157]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[106.03094979]\n",
      " [ 13.51005419]\n",
      " [107.05459311]\n",
      " [106.48695298]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  41.63531875769722 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.75192022]\n",
      " [1.33776565]\n",
      " [0.49079858]\n",
      " [1.12318539]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  70\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[11.91180684]\n",
      " [ 6.79007051]\n",
      " [ 8.04125704]\n",
      " [ 8.2645465 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.18819316]\n",
      " [ -3.60992949]\n",
      " [-10.25874296]\n",
      " [-10.2354535 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[103.79927987]\n",
      " [ 13.03159096]\n",
      " [105.24180711]\n",
      " [104.76450826]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  40.85464827532093 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.83765102]\n",
      " [1.35042851]\n",
      " [0.50065748]\n",
      " [1.1323578 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  71\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.01949279]\n",
      " [ 6.85502208]\n",
      " [ 8.12853074]\n",
      " [ 8.34755847]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-10.08050721]\n",
      " [ -3.54497792]\n",
      " [-10.17146926]\n",
      " [-10.15244153]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[101.61662564]\n",
      " [ 12.56686846]\n",
      " [103.45878686]\n",
      " [103.07206898]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  40.089293744464285 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[8.92252451]\n",
      " [1.36298158]\n",
      " [0.51053949]\n",
      " [1.14140521]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  72\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.12594102]\n",
      " [ 6.91925901]\n",
      " [ 8.21510623]\n",
      " [ 8.42979178]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ -9.97405898]\n",
      " [ -3.48074099]\n",
      " [-10.08489377]\n",
      " [-10.07020822]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 99.48185256]\n",
      " [ 12.11555782]\n",
      " [101.70508239]\n",
      " [101.40909361]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  39.33894829590957 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.00654926]\n",
      " [1.37542683]\n",
      " [0.52044314]\n",
      " [1.15032955]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  73\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.23116755]\n",
      " [ 6.98278811]\n",
      " [ 8.30098759]\n",
      " [ 8.51125381]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.86883245]\n",
      " [-3.41721189]\n",
      " [-9.99901241]\n",
      " [-9.98874619]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[97.39385398]\n",
      " [11.67733709]\n",
      " [99.98024914]\n",
      " [99.77505046]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  38.603311333758576 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.08973377]\n",
      " [1.38776617]\n",
      " [0.53036702]\n",
      " [1.15913274]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  74\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.33518815]\n",
      " [ 7.04561612]\n",
      " [ 8.38617894]\n",
      " [ 8.59195188]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.76481185]\n",
      " [-3.35438388]\n",
      " [-9.91382106]\n",
      " [-9.90804812]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[95.35155043]\n",
      " [11.25189123]\n",
      " [98.283848  ]\n",
      " [98.16941757]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  37.8820884030123 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.17208643]\n",
      " [1.40000146]\n",
      " [0.54030974]\n",
      " [1.16781666]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  75\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.43801838]\n",
      " [ 7.10774972]\n",
      " [ 8.4706844 ]\n",
      " [ 8.67189324]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.66198162]\n",
      " [-3.29225028]\n",
      " [-9.8293156 ]\n",
      " [-9.82810676]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[93.35388889]\n",
      " [10.83891187]\n",
      " [96.61544523]\n",
      " [96.59168248]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  37.17499106010645 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.25361557]\n",
      " [1.41213455]\n",
      " [0.55026994]\n",
      " [1.17638315]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  76\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.53967354]\n",
      " [ 7.16919557]\n",
      " [ 8.55450809]\n",
      " [ 8.75108508]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.56032646]\n",
      " [-3.23080443]\n",
      " [-9.74549191]\n",
      " [-9.74891492]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[91.39984211]\n",
      " [10.43809726]\n",
      " [94.97461249]\n",
      " [95.04134212]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  36.48173674633041 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.33432941]\n",
      " [1.42416722]\n",
      " [0.56024631]\n",
      " [1.18483402]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  77\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.64016872]\n",
      " [ 7.22996024]\n",
      " [ 8.63765418]\n",
      " [ 8.82953452]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.45983128]\n",
      " [-3.17003976]\n",
      " [-9.66234582]\n",
      " [-9.67046548]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[89.48840791]\n",
      " [10.04915208]\n",
      " [93.36092677]\n",
      " [93.51790255]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  35.802048664059626 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.41423612]\n",
      " [1.43610123]\n",
      " [0.57023755]\n",
      " [1.19317104]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  78\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.73951878]\n",
      " [ 7.29005026]\n",
      " [ 8.72012681]\n",
      " [ 8.90724863]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.36048122]\n",
      " [-3.10994974]\n",
      " [-9.57987319]\n",
      " [-9.59275137]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[87.61860858]\n",
      " [ 9.67178737]\n",
      " [91.77397041]\n",
      " [92.02087888]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  35.13565565573322 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.49334376]\n",
      " [1.44793832]\n",
      " [0.58024241]\n",
      " [1.20139595]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  79\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.83773839]\n",
      " [ 7.34947211]\n",
      " [ 8.80193014]\n",
      " [ 8.98423439]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.26226161]\n",
      " [-3.05052789]\n",
      " [-9.49806986]\n",
      " [-9.51576561]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[85.78949019]\n",
      " [ 9.30572038]\n",
      " [90.21333104]\n",
      " [90.54979508]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  34.482292085510196 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.57166032]\n",
      " [1.45968015]\n",
      " [0.59025966]\n",
      " [1.20951047]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  80\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[12.93484195]\n",
      " [ 7.40823222]\n",
      " [ 8.88306836]\n",
      " [ 9.06049875]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.16515805]\n",
      " [-2.99176778]\n",
      " [-9.41693164]\n",
      " [-9.43950125]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[84.00012199]\n",
      " [ 8.95067444]\n",
      " [88.67860157]\n",
      " [89.10418378]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  33.84169772354008 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.64919372]\n",
      " [1.47132839]\n",
      " [0.60028812]\n",
      " [1.21751628]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  81\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.03084371]\n",
      " [ 7.46633695]\n",
      " [ 8.96354563]\n",
      " [ 9.13604858]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-9.06915629]\n",
      " [-2.93366305]\n",
      " [-9.33645437]\n",
      " [-9.36395142]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[82.24959584]\n",
      " [ 8.60637888]\n",
      " [87.16938015]\n",
      " [87.68358619]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  33.21361763278469 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.72595178]\n",
      " [1.48288465]\n",
      " [0.6103266 ]\n",
      " [1.22541503]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  82\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.12575766]\n",
      " [ 7.52379263]\n",
      " [ 9.04336615]\n",
      " [ 9.21089069]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.97424234]\n",
      " [-2.87620737]\n",
      " [-9.25663385]\n",
      " [-9.28910931]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[80.53702557]\n",
      " [ 8.27256886]\n",
      " [85.68527018]\n",
      " [86.28755186]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  32.5978020583303 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.80194226]\n",
      " [1.49435052]\n",
      " [0.62037399]\n",
      " [1.23320834]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  83\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.21959762]\n",
      " [ 7.58060551]\n",
      " [ 9.12253411]\n",
      " [ 9.28503182]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.88040238]\n",
      " [-2.81939449]\n",
      " [-9.17746589]\n",
      " [-9.21496818]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[78.86154646]\n",
      " [ 7.94898529]\n",
      " [84.22588019]\n",
      " [84.91563861]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  31.994006319130687 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.87717284]\n",
      " [1.50572755]\n",
      " [0.63042916]\n",
      " [1.24089779]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  84\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.31237719]\n",
      " [ 7.63678182]\n",
      " [ 9.20105369]\n",
      " [ 9.35847867]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.78762281]\n",
      " [-2.76321818]\n",
      " [-9.09894631]\n",
      " [-9.14152133]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[77.22231466]\n",
      " [ 7.63537473]\n",
      " [82.79082392]\n",
      " [83.56741231]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  31.401990702122767 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[9.95165111]\n",
      " [1.51701725]\n",
      " [0.64049104]\n",
      " [1.24848495]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  85\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.40410978]\n",
      " [ 7.69232771]\n",
      " [ 9.2789291 ]\n",
      " [ 9.43123786]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.69589022]\n",
      " [-2.70767229]\n",
      " [-9.0210709 ]\n",
      " [-9.06876214]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[75.61850667]\n",
      " [ 7.33148924]\n",
      " [81.37972018]\n",
      " [82.24244677]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  30.82152035865921 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.0253846 ]\n",
      " [ 1.52822112]\n",
      " [ 0.65055857]\n",
      " [ 1.25597136]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  86\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.49480861]\n",
      " [ 7.7472493 ]\n",
      " [ 9.35616453]\n",
      " [ 9.50331597]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.60519139]\n",
      " [-2.6527507 ]\n",
      " [-8.94383547]\n",
      " [-8.99668403]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[74.04931881]\n",
      " [ 7.0370863 ]\n",
      " [79.99219291]\n",
      " [80.9403236 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  30.252365203202437 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.09838076]\n",
      " [ 1.53934061]\n",
      " [ 0.66063074]\n",
      " [ 1.26335852]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  87\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.5844867 ]\n",
      " [ 7.80155264]\n",
      " [ 9.43276418]\n",
      " [ 9.5747195 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.5155133 ]\n",
      " [-2.59844736]\n",
      " [-8.86723582]\n",
      " [-8.9252805 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[72.51396671]\n",
      " [ 6.75192869]\n",
      " [78.62787104]\n",
      " [79.66063207]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  29.69429981422723 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.17064695]\n",
      " [ 1.55037715]\n",
      " [ 0.67070653]\n",
      " [ 1.2706479 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  88\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.67315689]\n",
      " [ 7.85524375]\n",
      " [ 9.50873225]\n",
      " [ 9.6454549 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.42684311]\n",
      " [-2.54475625]\n",
      " [-8.79126775]\n",
      " [-8.8545451 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[71.01168482]\n",
      " [ 6.47578439]\n",
      " [77.28638857]\n",
      " [78.40296892]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  29.14710333727951 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.24219048]\n",
      " [ 1.56133214]\n",
      " [ 0.68078497]\n",
      " [ 1.27784097]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  89\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.76083182]\n",
      " [ 7.90832858]\n",
      " [ 9.58407295]\n",
      " [ 9.71552857]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.33916818]\n",
      " [-2.49167142]\n",
      " [-8.71592705]\n",
      " [-8.78447143]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[69.54172591]\n",
      " [ 6.20842649]\n",
      " [75.96738442]\n",
      " [77.1669383 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  28.6105593901411 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.31301857]\n",
      " [ 1.57220695]\n",
      " [ 0.69086511]\n",
      " [ 1.28493914]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  90\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.84752397]\n",
      " [ 7.96081303]\n",
      " [ 9.65879045]\n",
      " [ 9.78494684]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.25247603]\n",
      " [-2.43918697]\n",
      " [-8.64120955]\n",
      " [-8.71505316]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[68.10336065]\n",
      " [ 5.94963305]\n",
      " [74.67050246]\n",
      " [75.95215159]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  28.08445597005083 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.38313839]\n",
      " [ 1.58300292]\n",
      " [ 0.70094603]\n",
      " [ 1.29194382]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  91\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[13.93324562]\n",
      " [ 8.01270298]\n",
      " [ 9.73288897]\n",
      " [ 9.85371598]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.16675438]\n",
      " [-2.38729702]\n",
      " [-8.56711103]\n",
      " [-8.64628402]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[66.69587709]\n",
      " [ 5.69918706]\n",
      " [73.39539147]\n",
      " [74.75822727]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  27.568585362934236 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.452557  ]\n",
      " [ 1.59372136]\n",
      " [ 0.71102682]\n",
      " [ 1.29885639]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  92\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.01800889]\n",
      " [ 8.06400422]\n",
      " [ 9.80637268]\n",
      " [ 9.92184223]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.08199111]\n",
      " [-2.33599578]\n",
      " [-8.49362732]\n",
      " [-8.57815777]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[65.31858029]\n",
      " [ 5.45687629]\n",
      " [72.14170506]\n",
      " [73.5847908 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  27.062744054594937 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.52128143]\n",
      " [ 1.60436356]\n",
      " [ 0.72110661]\n",
      " [ 1.3056782 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  93\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.10182572]\n",
      " [ 8.11472251]\n",
      " [ 9.87924578]\n",
      " [ 9.98933172]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.99817428]\n",
      " [-2.28527749]\n",
      " [-8.42075422]\n",
      " [-8.51066828]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[63.97079181]\n",
      " [ 5.2224932 ]\n",
      " [70.90910165]\n",
      " [72.43147449]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  26.566732643822377 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.58931862]\n",
      " [ 1.61493078]\n",
      " [ 0.73118453]\n",
      " [ 1.31241057]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  94\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.18470788]\n",
      " [ 8.16486356]\n",
      " [ 9.95151245]\n",
      " [10.05619059]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.91529212]\n",
      " [-2.23513644]\n",
      " [-8.34848755]\n",
      " [-8.44380941]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[62.65184936]\n",
      " [ 4.99583489]\n",
      " [69.69724442]\n",
      " [71.29791738]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  26.080355757371304 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.65667543]\n",
      " [ 1.62542425]\n",
      " [ 0.74125975]\n",
      " [ 1.31905481]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  95\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.26666697]\n",
      " [ 8.21443304]\n",
      " [10.02317686]\n",
      " [10.12242487]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.83333303]\n",
      " [-2.18556696]\n",
      " [-8.27682314]\n",
      " [-8.37757513]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[61.36110637]\n",
      " [ 4.77670295]\n",
      " [68.5058013 ]\n",
      " [70.18376511]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  25.60342196676998 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.72335868]\n",
      " [ 1.63584518]\n",
      " [ 0.75133147]\n",
      " [ 1.3256122 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  96\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.34771443]\n",
      " [ 8.26343654]\n",
      " [10.09424319]\n",
      " [10.18804056]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.75228557]\n",
      " [-2.13656346]\n",
      " [-8.20575681]\n",
      " [-8.31195944]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[60.09793155]\n",
      " [ 4.5649034 ]\n",
      " [67.33444489]\n",
      " [69.08866981]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  25.135743706914884 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.78937509]\n",
      " [ 1.64619477]\n",
      " [ 0.76139888]\n",
      " [ 1.332084  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  97\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.42786154]\n",
      " [ 8.31187965]\n",
      " [10.16471559]\n",
      " [10.25304359]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.67213846]\n",
      " [-2.08812035]\n",
      " [-8.13528441]\n",
      " [-8.24695641]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[58.86170859]\n",
      " [ 4.36024662]\n",
      " [66.18285241]\n",
      " [68.01228995]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  24.677137196411035 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.85473134]\n",
      " [ 1.65647415]\n",
      " [ 0.77146122]\n",
      " [ 1.33847144]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  98\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.50711941]\n",
      " [ 8.35976786]\n",
      " [10.23459823]\n",
      " [10.31743987]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.59288059]\n",
      " [-2.04023214]\n",
      " [-8.06540177]\n",
      " [-8.18256013]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[57.6518357 ]\n",
      " [ 4.1625472 ]\n",
      " [65.05070569]\n",
      " [66.95429028]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  24.22742235961769 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.91943403]\n",
      " [ 1.66668449]\n",
      " [ 0.78151774]\n",
      " [ 1.34477574]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  99\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.585499  ]\n",
      " [ 8.40710665]\n",
      " [10.30389525]\n",
      " [10.38123521]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.514501  ]\n",
      " [-1.99289335]\n",
      " [-7.99610475]\n",
      " [-8.11876479]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[56.4677253 ]\n",
      " [ 3.97162392]\n",
      " [63.93769112]\n",
      " [65.91434166]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  23.786422750360728 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[10.98348969]\n",
      " [ 1.67682687]\n",
      " [ 0.79156771]\n",
      " [ 1.3509981 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  100\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.66301112]\n",
      " [ 8.45390143]\n",
      " [10.3726108 ]\n",
      " [10.4444354 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.43698888]\n",
      " [-1.94609857]\n",
      " [-7.9273892 ]\n",
      " [-8.0555646 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[55.30880363]\n",
      " [ 3.78729964]\n",
      " [62.84349956]\n",
      " [64.89212098]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  23.353965477273483 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.04690479]\n",
      " [ 1.68690241]\n",
      " [ 0.80161042]\n",
      " [ 1.35713969]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  101\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.73966642]\n",
      " [ 8.50015759]\n",
      " [10.44074899]\n",
      " [10.50704616]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.36033358]\n",
      " [-1.89984241]\n",
      " [-7.85925101]\n",
      " [-7.99295384]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[54.17451044]\n",
      " [ 3.60940119]\n",
      " [61.76782637]\n",
      " [63.88731104]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  22.9298811307292 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.10968574]\n",
      " [ 1.69691215]\n",
      " [ 0.81164517]\n",
      " [ 1.36320165]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  102\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.8154754 ]\n",
      " [ 8.54588044]\n",
      " [10.50831396]\n",
      " [10.56907317]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.2845246 ]\n",
      " [-1.85411956]\n",
      " [-7.79168604]\n",
      " [-7.93092683]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[53.06429861]\n",
      " [ 3.43775935]\n",
      " [60.71037129]\n",
      " [62.89960044]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  22.51400371132879 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.17183889]\n",
      " [ 1.70685716]\n",
      " [ 0.8216713 ]\n",
      " [ 1.36918512]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  103\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.89044843]\n",
      " [ 8.59107526]\n",
      " [10.57530982]\n",
      " [10.63052203]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.20955157]\n",
      " [-1.80892474]\n",
      " [-7.72469018]\n",
      " [-7.86947797]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[51.97763385]\n",
      " [ 3.2722087 ]\n",
      " [59.67083844]\n",
      " [61.92868348]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  22.10617055990891 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.2333705 ]\n",
      " [ 1.71673845]\n",
      " [ 0.83168814]\n",
      " [ 1.37509122]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  104\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[14.96459571]\n",
      " [ 8.6357473 ]\n",
      " [10.64174065]\n",
      " [10.69139833]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.13540429]\n",
      " [-1.7642527 ]\n",
      " [-7.65825935]\n",
      " [-7.80860167]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[50.91399438]\n",
      " [ 3.1125876 ]\n",
      " [58.64893627]\n",
      " [60.97426006]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  21.706222289035917 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.29428679]\n",
      " [ 1.72655702]\n",
      " [ 0.84169507]\n",
      " [ 1.38092103]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  105\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.03792731]\n",
      " [ 8.67990172]\n",
      " [10.70761055]\n",
      " [10.75170757]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-7.06207269]\n",
      " [-1.72009828]\n",
      " [-7.59238945]\n",
      " [-7.74829243]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[49.87287062]\n",
      " [ 2.95873808]\n",
      " [57.64437749]\n",
      " [60.03603554]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  21.31400271595212 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.35459392]\n",
      " [ 1.73631387]\n",
      " [ 0.85169146]\n",
      " [ 1.38667564]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  106\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.11045317]\n",
      " [ 8.72354369]\n",
      " [10.77292361]\n",
      " [10.81145523]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.98954683]\n",
      " [-1.67645631]\n",
      " [-7.52707639]\n",
      " [-7.68854477]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[48.85376485]\n",
      " [ 2.81050577]\n",
      " [56.65687905]\n",
      " [59.11372071]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  20.929358796941965 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.41429798]\n",
      " [ 1.74600995]\n",
      " [ 0.8616767 ]\n",
      " [ 1.39235608]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  107\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.18218308]\n",
      " [ 8.76667828]\n",
      " [10.83768387]\n",
      " [10.87064671]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.91781692]\n",
      " [-1.63332172]\n",
      " [-7.46231613]\n",
      " [-7.62935329]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[47.85619098]\n",
      " [ 2.66773983]\n",
      " [55.68616208]\n",
      " [58.20703162]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  20.552140563086073 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.473405  ]\n",
      " [ 1.75564621]\n",
      " [ 0.87165022]\n",
      " [ 1.39796342]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  108\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.25312668]\n",
      " [ 8.80931056]\n",
      " [10.90189539]\n",
      " [10.92928738]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.84687332]\n",
      " [-1.59068944]\n",
      " [-7.39810461]\n",
      " [-7.57071262]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[46.87967421]\n",
      " [ 2.53029289]\n",
      " [54.73195184]\n",
      " [57.31568952]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  20.182201057372076 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.53192095]\n",
      " [ 1.76522356]\n",
      " [ 0.88161144]\n",
      " [ 1.40349865]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  109\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.32329352]\n",
      " [ 8.85144553]\n",
      " [10.96556221]\n",
      " [10.98738256]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.77670648]\n",
      " [-1.54855447]\n",
      " [-7.33443779]\n",
      " [-7.51261744]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[45.92375078]\n",
      " [ 2.39802095]\n",
      " [53.79397769]\n",
      " [56.43942077]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  19.819396273132202 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.58985174]\n",
      " [ 1.77474293]\n",
      " [ 0.89155981]\n",
      " [ 1.40896279]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  110\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.39269296]\n",
      " [ 8.89308815]\n",
      " [11.02868836]\n",
      " [11.04493751]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.70730704]\n",
      " [-1.50691185]\n",
      " [-7.27131164]\n",
      " [-7.45506249]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[44.98796767]\n",
      " [ 2.27078333]\n",
      " [52.87197304]\n",
      " [55.57795671]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  19.463585093777702 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.64720323]\n",
      " [ 1.78420518]\n",
      " [ 0.90149479]\n",
      " [ 1.41435682]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  111\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.46133429]\n",
      " [ 8.93424334]\n",
      " [11.09127783]\n",
      " [11.10195745]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.63866571]\n",
      " [-1.46575666]\n",
      " [-7.20872217]\n",
      " [-7.39804255]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[44.07188239]\n",
      " [ 2.14844259]\n",
      " [51.96567526]\n",
      " [54.73103362]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  19.114629233801576 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.7039812 ]\n",
      " [ 1.7936112 ]\n",
      " [ 0.91141586]\n",
      " [ 1.41968171]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  112\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.52922663]\n",
      " [ 8.97491597]\n",
      " [11.15333464]\n",
      " [11.15844754]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.57077337]\n",
      " [-1.42508403]\n",
      " [-7.14666536]\n",
      " [-7.34155246]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[43.17506265]\n",
      " [ 2.0308645 ]\n",
      " [51.07482572]\n",
      " [53.89839258]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  18.772393181021307 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.76019138]\n",
      " [ 1.80296183]\n",
      " [ 0.92132251]\n",
      " [ 1.42493841]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  113\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.596379  ]\n",
      " [ 9.01511087]\n",
      " [11.21486276]\n",
      " [11.2144129 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.503621  ]\n",
      " [-1.38488913]\n",
      " [-7.08513724]\n",
      " [-7.2855871 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[42.29708615]\n",
      " [ 1.91791789]\n",
      " [50.19916966]\n",
      " [53.07977942]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  18.436744140034136 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.81583947]\n",
      " [ 1.8122579 ]\n",
      " [ 0.93121424]\n",
      " [ 1.43012785]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  114\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.66280027]\n",
      " [ 9.05483284]\n",
      " [11.27586616]\n",
      " [11.2698586 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.43719973]\n",
      " [-1.34516716]\n",
      " [-7.02413384]\n",
      " [-7.2301414 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[41.43754034]\n",
      " [ 1.80947469]\n",
      " [49.33845619]\n",
      " [52.2749446 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  18.107551976858225 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.87093107]\n",
      " [ 1.82150024]\n",
      " [ 0.94109057]\n",
      " [ 1.43525096]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  115\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.72849922]\n",
      " [ 9.09408661]\n",
      " [11.33634879]\n",
      " [11.32478968]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.37150078]\n",
      " [-1.30591339]\n",
      " [-6.96365121]\n",
      " [-7.17521032]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[40.59602216]\n",
      " [ 1.70540978]\n",
      " [48.49243823]\n",
      " [51.48364315]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  17.784689164733365 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.92547176]\n",
      " [ 1.83068964]\n",
      " [ 0.95095105]\n",
      " [ 1.44030864]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  116\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.79348449]\n",
      " [ 9.13287689]\n",
      " [11.39631457]\n",
      " [11.3792111 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.30651551]\n",
      " [-1.26712311]\n",
      " [-6.90368543]\n",
      " [-7.1207889 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[39.77213784]\n",
      " [ 1.60560098]\n",
      " [47.66087246]\n",
      " [50.70563457]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  17.46803073105585 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[11.97946705]\n",
      " [ 1.83982689]\n",
      " [ 0.96079522]\n",
      " [ 1.44530178]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  117\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.85776461]\n",
      " [ 9.17120833]\n",
      " [11.45576744]\n",
      " [11.43312779]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.24223539]\n",
      " [-1.22879167]\n",
      " [-6.84423256]\n",
      " [-7.06687221]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[38.96550263]\n",
      " [ 1.50992896]\n",
      " [46.84351928]\n",
      " [49.94068277]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  17.157454205422532 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.03292238]\n",
      " [ 1.84891276]\n",
      " [ 0.97062263]\n",
      " [ 1.45023125]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  118\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.92134799]\n",
      " [ 9.20908556]\n",
      " [11.5147113 ]\n",
      " [11.48654465]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.17865201]\n",
      " [-1.19091444]\n",
      " [-6.7852887 ]\n",
      " [-7.01345535]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[38.17574062]\n",
      " [ 1.4182772 ]\n",
      " [46.04014277]\n",
      " [49.18855596]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  16.85283956875979 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.08584315]\n",
      " [ 1.85794799]\n",
      " [ 0.98043287]\n",
      " [ 1.45509791]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  119\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[15.98424293]\n",
      " [ 9.24651315]\n",
      " [11.57315002]\n",
      " [11.5394665 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.11575707]\n",
      " [-1.15348685]\n",
      " [-6.72684998]\n",
      " [-6.9605335 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[37.40248449]\n",
      " [ 1.33053191]\n",
      " [45.25051064]\n",
      " [48.44902658]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  16.5540692035136 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.13823472]\n",
      " [ 1.86693333]\n",
      " [ 0.99022551]\n",
      " [ 1.45990261]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  120\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.04645762]\n",
      " [ 9.28349564]\n",
      " [11.63108748]\n",
      " [11.59189814]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-6.05354238]\n",
      " [-1.11650436]\n",
      " [-6.66891252]\n",
      " [-6.90810186]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[36.64537534]\n",
      " [ 1.246582  ]\n",
      " [44.47439417]\n",
      " [47.72187125]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  16.261027844877553 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.19010237]\n",
      " [ 1.8758695 ]\n",
      " [ 1.00000017]\n",
      " [ 1.46464618]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  121\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.10800013]\n",
      " [ 9.32003751]\n",
      " [11.68852753]\n",
      " [11.64384433]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.99199987]\n",
      " [-1.07996249]\n",
      " [-6.61147247]\n",
      " [-6.85615567]] \n",
      "\n",
      "sq_error = error **2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35.90406246]\n",
      " [ 1.16631899]\n",
      " [43.71156818]\n",
      " [47.00687063]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  15.973602533036223 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.24145135]\n",
      " [ 1.8847572 ]\n",
      " [ 1.00975645]\n",
      " [ 1.46932943]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  122\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.16887843]\n",
      " [ 9.35614322]\n",
      " [11.74547401]\n",
      " [11.69530975]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.93112157]\n",
      " [-1.04385678]\n",
      " [-6.55452599]\n",
      " [-6.80469025]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[35.17820313]\n",
      " [ 1.08963698]\n",
      " [42.96181099]\n",
      " [46.30380943]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  15.691682566401742 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.29228684]\n",
      " [ 1.89359713]\n",
      " [ 1.01949397]\n",
      " [ 1.47395317]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  123\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.22910037]\n",
      " [ 9.39181718]\n",
      " [11.80193072]\n",
      " [11.74629907]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.87089963]\n",
      " [-1.00818282]\n",
      " [-6.49806928]\n",
      " [-6.75370093]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[34.46746245]\n",
      " [ 1.0164326 ]\n",
      " [42.22490435]\n",
      " [45.61247625]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  15.415159455822021 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.34261397]\n",
      " [ 1.90238998]\n",
      " [ 1.02921236]\n",
      " [ 1.47851819]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  124\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.28867372]\n",
      " [ 9.42706377]\n",
      " [11.85790147]\n",
      " [11.79681691]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.81132628]\n",
      " [-0.97293623]\n",
      " [-6.44209853]\n",
      " [-6.70318309]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[33.77151312]\n",
      " [ 0.94660491]\n",
      " [41.50063344]\n",
      " [44.93266358]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  15.143926879739492 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.39243783]\n",
      " [ 1.91113639]\n",
      " [ 1.03891128]\n",
      " [ 1.48302526]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  125\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.34760613]\n",
      " [ 9.46188731]\n",
      " [11.91339004]\n",
      " [11.84686783]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.75239387]\n",
      " [-0.93811269]\n",
      " [-6.38660996]\n",
      " [-6.65313217]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[33.09003528]\n",
      " [ 0.88005541]\n",
      " [40.78878675]\n",
      " [44.26416767]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  14.877880640279878 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.44176345]\n",
      " [ 1.91983703]\n",
      " [ 1.04859039]\n",
      " [ 1.48747515]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  126\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.40590513]\n",
      " [ 9.49629211]\n",
      " [11.96840019]\n",
      " [11.89645637]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.69409487]\n",
      " [-0.90370789]\n",
      " [-6.33159981]\n",
      " [-6.60354363]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[32.42271635]\n",
      " [ 0.81668795]\n",
      " [40.08915614]\n",
      " [43.60678852]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  14.616918620250779 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.49059582]\n",
      " [ 1.92849254]\n",
      " [ 1.05824934]\n",
      " [ 1.49186862]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  127\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.46357819]\n",
      " [ 9.5302824 ]\n",
      " [12.02293566]\n",
      " [11.945587  ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.63642181]\n",
      " [-0.8697176 ]\n",
      " [-6.27706434]\n",
      " [-6.554413  ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[31.76925079]\n",
      " [ 0.7564087 ]\n",
      " [39.40153671]\n",
      " [42.96032974]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  14.360940741030515 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.53893986]\n",
      " [ 1.93710355]\n",
      " [ 1.06788781]\n",
      " [ 1.49620639]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  128\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.52063265]\n",
      " [ 9.56386242]\n",
      " [12.07700018]\n",
      " [11.99426418]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.57936735]\n",
      " [-0.83613758]\n",
      " [-6.22299982]\n",
      " [-6.50573582]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[31.12933999]\n",
      " [ 0.69912606]\n",
      " [38.72572677]\n",
      " [42.32459855]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  14.109848921328044 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.58680046]\n",
      " [ 1.94567065]\n",
      " [ 1.07750551]\n",
      " [ 1.5004892 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  129\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.57707577]\n",
      " [ 9.59703632]\n",
      " [12.13059745]\n",
      " [12.0424923 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.52292423]\n",
      " [-0.80296368]\n",
      " [-6.16940255]\n",
      " [-6.4575077 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[30.5026921 ]\n",
      " [ 0.64475067]\n",
      " [38.06152785]\n",
      " [41.69940567]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  13.863547036795094 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.63418245]\n",
      " [ 1.95419447]\n",
      " [ 1.08710212]\n",
      " [ 1.50471777]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  130\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.63291469]\n",
      " [ 9.62980825]\n",
      " [12.18373115]\n",
      " [12.09027573]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.46708531]\n",
      " [-0.77019175]\n",
      " [-6.11626885]\n",
      " [-6.40972427]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[29.88902184]\n",
      " [ 0.59319533]\n",
      " [37.4087446 ]\n",
      " [41.08456528]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  13.621940880472362 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.68109063]\n",
      " [ 1.96267559]\n",
      " [ 1.09667735]\n",
      " [ 1.50889279]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  131\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.68815647]\n",
      " [ 9.66218231]\n",
      " [12.23640496]\n",
      " [12.13761877]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.41184353]\n",
      " [-0.73781769]\n",
      " [-6.06359504]\n",
      " [-6.36238123]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[29.28805035]\n",
      " [ 0.54437494]\n",
      " [36.76718476]\n",
      " [40.47989494]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  13.384938124051782 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.72752972]\n",
      " [ 1.97111458]\n",
      " [ 1.10623092]\n",
      " [ 1.51301496]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  132\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.7428081 ]\n",
      " [ 9.69416256]\n",
      " [12.28862252]\n",
      " [12.18452571]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.3571919 ]\n",
      " [-0.70583744]\n",
      " [-6.01137748]\n",
      " [-6.31547429]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[28.69950506]\n",
      " [ 0.49820649]\n",
      " [36.13665915]\n",
      " [39.88521554]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  13.152448279937456 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.77350443]\n",
      " [ 1.97951201]\n",
      " [ 1.11576256]\n",
      " [ 1.51708496]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  133\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.79687644]\n",
      " [ 9.72575302]\n",
      " [12.34038746]\n",
      " [12.23100078]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.30312356]\n",
      " [-0.67424698]\n",
      " [-5.95961254]\n",
      " [-6.26899922]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[28.12311952]\n",
      " [ 0.45460899]\n",
      " [35.51698157]\n",
      " [39.30035123]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  12.924382664088059 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.81901938]\n",
      " [ 1.98786843]\n",
      " [ 1.12527201]\n",
      " [ 1.52110347]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  134\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.85036827]\n",
      " [ 9.75695768]\n",
      " [12.39170339]\n",
      " [12.27704818]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.24963173]\n",
      " [-0.64304232]\n",
      " [-5.90829661]\n",
      " [-6.22295182]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[27.55863327]\n",
      " [ 0.41350342]\n",
      " [34.90796882]\n",
      " [38.72512937]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  12.700654359624142 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.86407919]\n",
      " [ 1.9961844 ]\n",
      " [ 1.13475901]\n",
      " [ 1.52507113]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  135\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.9032903 ]\n",
      " [ 9.78778049]\n",
      " [12.44257389]\n",
      " [12.32267206]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.1967097 ]\n",
      " [-0.61221951]\n",
      " [-5.85742611]\n",
      " [-6.17732794]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[27.00579167]\n",
      " [ 0.37481272]\n",
      " [34.30944062]\n",
      " [38.15938043]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  12.481178181184017 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.9086884 ]\n",
      " [ 2.00446044]\n",
      " [ 1.14422332]\n",
      " [ 1.5289886 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  136\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[16.95564914]\n",
      " [ 9.81822536]\n",
      " [12.49300253]\n",
      " [12.36787655]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.14435086]\n",
      " [-0.58177464]\n",
      " [-5.80699747]\n",
      " [-6.13212345]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[26.46434579]\n",
      " [ 0.33846173]\n",
      " [33.72121958]\n",
      " [37.60293802]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  12.265870640012142 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.95285151]\n",
      " [ 2.01269707]\n",
      " [ 1.15366469]\n",
      " [ 1.53285652]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  137\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.0074513 ]\n",
      " [ 9.84829617]\n",
      " [12.54299286]\n",
      " [12.41266571]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.0925487 ]\n",
      " [-0.55170383]\n",
      " [-5.75700714]\n",
      " [-6.08733429]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[25.93405227]\n",
      " [ 0.30437711]\n",
      " [33.14313115]\n",
      " [37.05563874]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  12.054649909764606 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[12.996573  ]\n",
      " [ 2.02089481]\n",
      " [ 1.16308291]\n",
      " [ 1.53667552]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  138\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.05870322]\n",
      " [ 9.87799676]\n",
      " [12.59254841]\n",
      " [12.45704359]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.04129678]\n",
      " [-0.52200324]\n",
      " [-5.70745159]\n",
      " [-6.04295641]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[25.41467319]\n",
      " [ 0.27248738]\n",
      " [32.57500361]\n",
      " [36.51732216]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  11.847435793016402 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.03985727]\n",
      " [ 2.02905416]\n",
      " [ 1.17247775]\n",
      " [ 1.54044621]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  139\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.10941127]\n",
      " [ 9.90733093]\n",
      " [12.64167269]\n",
      " [12.50101419]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.99058873]\n",
      " [-0.49266907]\n",
      " [-5.65832731]\n",
      " [-5.99898581]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[24.90597592]\n",
      " [ 0.24272281]\n",
      " [32.01666798]\n",
      " [35.9878308 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  11.64414968845561 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.08270869]\n",
      " [ 2.03717561]\n",
      " [ 1.18184899]\n",
      " [ 1.5441692 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  140\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.1595817 ]\n",
      " [ 9.93630245]\n",
      " [12.69036917]\n",
      " [12.54458146]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.9404183 ]\n",
      " [-0.46369755]\n",
      " [-5.60963083]\n",
      " [-5.95541854]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[24.40773301]\n",
      " [ 0.21501542]\n",
      " [31.46795803]\n",
      " [35.46701001]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  11.444714558749865 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.12513161]\n",
      " [ 2.04525964]\n",
      " [ 1.19119644]\n",
      " [ 1.54784509]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  141\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.20922071]\n",
      " [ 9.96491506]\n",
      " [12.73864133]\n",
      " [12.58774933]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.89077929]\n",
      " [-0.43508494]\n",
      " [-5.56135867]\n",
      " [-5.91225067]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[23.91972209]\n",
      " [ 0.18929891]\n",
      " [30.92871023]\n",
      " [34.95470797]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  11.249054899071085 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.16713029]\n",
      " [ 2.05330672]\n",
      " [ 1.2005199 ]\n",
      " [ 1.55147447]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  142\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.25833441]\n",
      " [ 9.99317245]\n",
      " [12.78649262]\n",
      " [12.63052169]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.84166559]\n",
      " [-0.40682755]\n",
      " [-5.51350738]\n",
      " [-5.86947831]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[23.44172572]\n",
      " [ 0.16550866]\n",
      " [30.39876367]\n",
      " [34.45077561]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  11.05709670626436 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.20870899]\n",
      " [ 2.06131732]\n",
      " [ 1.20981917]\n",
      " [ 1.55505793]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  143\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.30692882]\n",
      " [10.02107829]\n",
      " [12.83392645]\n",
      " [12.67290239]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.79307118]\n",
      " [-0.37892171]\n",
      " [-5.46607355]\n",
      " [-5.82709761]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[22.97353129]\n",
      " [ 0.14358166]\n",
      " [29.87796007]\n",
      " [33.95506657]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  10.868767448647468 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.2498719 ]\n",
      " [ 2.06929189]\n",
      " [ 1.21909408]\n",
      " [ 1.55859603]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  144\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.35500992]\n",
      " [10.04863621]\n",
      " [12.88094623]\n",
      " [12.71489523]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.74499008]\n",
      " [-0.35136379]\n",
      " [-5.41905377]\n",
      " [-5.78510477]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[22.51493089]\n",
      " [ 0.12345651]\n",
      " [29.36614374]\n",
      " [33.46743715]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  10.683996036427754 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.29062318]\n",
      " [ 2.07723087]\n",
      " [ 1.22834445]\n",
      " [ 1.56208933]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  145\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.40258356]\n",
      " [10.0758498 ]\n",
      " [12.92755535]\n",
      " [12.756504  ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.69741644]\n",
      " [-0.3241502 ]\n",
      " [-5.37244465]\n",
      " [-5.743496  ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[22.06572122]\n",
      " [ 0.10507335]\n",
      " [28.86316151]\n",
      " [32.98774626]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  10.50271279272338 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.33096695]\n",
      " [ 2.08513471]\n",
      " [ 1.23757011]\n",
      " [ 1.56553839]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  146\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.44965555]\n",
      " [10.10272264]\n",
      " [12.97375717]\n",
      " [12.79773244]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.65034445]\n",
      " [-0.29727736]\n",
      " [-5.32624283]\n",
      " [-5.70226756]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[21.62570349]\n",
      " [ 0.08837383]\n",
      " [28.36886272]\n",
      " [32.51585536]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  10.324849425176183 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.37090728]\n",
      " [ 2.09300382]\n",
      " [ 1.2467709 ]\n",
      " [ 1.56894375]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  147\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.49623162]\n",
      " [10.12925823]\n",
      " [13.01955502]\n",
      " [12.83858424]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.60376838]\n",
      " [-0.27074177]\n",
      " [-5.28044498]\n",
      " [-5.66141576]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[21.19468328]\n",
      " [ 0.07330111]\n",
      " [27.88309916]\n",
      " [32.05162845]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  10.150338998143773 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.41044821]\n",
      " [ 2.10083864]\n",
      " [ 1.25594666]\n",
      " [ 1.57230595]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  148\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.54231742]\n",
      " [10.15546009]\n",
      " [13.06495224]\n",
      " [12.87906307]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.55768258]\n",
      " [-0.24453991]\n",
      " [-5.23504776]\n",
      " [-5.62093693]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[20.77247046]\n",
      " [ 0.05979977]\n",
      " [27.40572506]\n",
      " [31.59493196]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  9.979115905458658 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.44959372]\n",
      " [ 2.10863956]\n",
      " [ 1.26509726]\n",
      " [ 1.57562552]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  149\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.58791854]\n",
      " [10.18133166]\n",
      " [13.10995212]\n",
      " [12.91917257]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.51208146]\n",
      " [-0.21866834]\n",
      " [-5.19004788]\n",
      " [-5.58082743]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[20.35887911]\n",
      " [ 0.04781584]\n",
      " [26.93659704]\n",
      " [31.14563476]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  9.81111584374262 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.48834779]\n",
      " [ 2.11640699]\n",
      " [ 1.27422253]\n",
      " [ 1.57890297]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  150\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.63304048]\n",
      " [10.20687639]\n",
      " [13.15455793]\n",
      " [12.95891634]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.46695952]\n",
      " [-0.19312361]\n",
      " [-5.14544207]\n",
      " [-5.54108366]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[19.95372737]\n",
      " [ 0.03729673]\n",
      " [26.47557408]\n",
      " [30.70360811]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  9.646275786264537 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.52671431]\n",
      " [ 2.12414133]\n",
      " [ 1.28332236]\n",
      " [ 1.58213883]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  151\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.67768868]\n",
      " [10.23209767]\n",
      " [13.19877294]\n",
      " [12.99829794]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.42231132]\n",
      " [-0.16790233]\n",
      " [-5.10122706]\n",
      " [-5.50170206]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.95568374e+01]\n",
      " [2.81911921e-02]\n",
      " [2.60225175e+01]\n",
      " [3.02687256e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  9.484533957330525 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.56469717]\n",
      " [ 2.13184296]\n",
      " [ 1.2923966 ]\n",
      " [ 1.58533358]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  152\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.72186852]\n",
      " [10.25699886]\n",
      " [13.24260039]\n",
      " [13.03732089]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.37813148]\n",
      " [-0.14300114]\n",
      " [-5.05739961]\n",
      " [-5.46267911]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.91680353e+01]\n",
      " [2.04493257e-02]\n",
      " [2.55772908e+01]\n",
      " [2.98408630e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  9.325829807195076 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.60230019]\n",
      " [ 2.13951227]\n",
      " [ 1.30144514]\n",
      " [ 1.58848774]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  153\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.76558529]\n",
      " [10.2815833 ]\n",
      " [13.28604348]\n",
      " [13.0759887 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.33441471]\n",
      " [-0.1184167 ]\n",
      " [-5.01395652]\n",
      " [-5.4240113 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.87871509e+01]\n",
      " [1.40225154e-02]\n",
      " [2.51397599e+01]\n",
      " [2.94198986e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  9.170103987482406 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.63952719]\n",
      " [ 2.14714962]\n",
      " [ 1.31046786]\n",
      " [ 1.59160178]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  154\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.80884424]\n",
      " [10.30585428]\n",
      " [13.32910542]\n",
      " [13.11430482]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.29115576]\n",
      " [-0.09414572]\n",
      " [-4.97089458]\n",
      " [-5.38569518]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.84140177e+01]\n",
      " [8.86341647e-03]\n",
      " [2.47097929e+01]\n",
      " [2.90057126e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  9.017298327107381 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.67638192]\n",
      " [ 2.15475538]\n",
      " [ 1.31946464]\n",
      " [ 1.5946762 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  155\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.85165053]\n",
      " [10.32981508]\n",
      " [13.37178938]\n",
      " [13.15227268]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.24834947]\n",
      " [-0.07018492]\n",
      " [-4.92821062]\n",
      " [-5.34772732]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.80484732e+01]\n",
      " [4.92592295e-03]\n",
      " [2.42872599e+01]\n",
      " [2.85981875e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  8.867355808685593 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.7128681 ]\n",
      " [ 2.1623299 ]\n",
      " [ 1.32843538]\n",
      " [ 1.59771146]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  156\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.89400928]\n",
      " [10.35346894]\n",
      " [13.41409851]\n",
      " [13.18989568]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.20599072]\n",
      " [-0.04653106]\n",
      " [-4.88590149]\n",
      " [-5.31010432]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.76903580e+01]\n",
      " [2.16513999e-03]\n",
      " [2.38720334e+01]\n",
      " [2.81972079e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  8.720220545422455 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.74898942]\n",
      " [ 2.16987355]\n",
      " [ 1.33737997]\n",
      " [ 1.60070803]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  157\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.93592551]\n",
      " [10.37681905]\n",
      " [13.45603594]\n",
      " [13.22717718]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.16407449]\n",
      " [-0.02318095]\n",
      " [-4.84396406]\n",
      " [-5.27282282]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.73395164e+01]\n",
      " [5.37356312e-04]\n",
      " [2.34639878e+01]\n",
      " [2.78026605e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  8.57583775847127 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.78474953]\n",
      " [ 2.17738666]\n",
      " [ 1.34629832]\n",
      " [ 1.60366638]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  158\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[17.97740421]\n",
      " [10.39986861]\n",
      " [13.49760478]\n",
      " [13.26412051]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.12259579e+00]\n",
      " [-1.31389660e-04]\n",
      " [-4.80239522e+00]\n",
      " [-5.23587949e+00]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.69957961e+01]\n",
      " [1.72632428e-08]\n",
      " [2.30629999e+01]\n",
      " [2.74144341e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  8.434153754750607 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.82015203]\n",
      " [ 2.18486956]\n",
      " [ 1.35519034]\n",
      " [ 1.60658694]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  159\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.01845029]\n",
      " [10.42262075]\n",
      " [13.53880812]\n",
      " [13.30072896]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.08154971]\n",
      " [ 0.02262075]\n",
      " [-4.76119188]\n",
      " [-5.19927104]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.66590481e+01]\n",
      " [5.11698532e-04]\n",
      " [2.26689481e+01]\n",
      " [2.70324194e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  8.295115905211457 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.85520051]\n",
      " [ 2.1923226 ]\n",
      " [ 1.36405593]\n",
      " [ 1.60947018]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  160\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.0590686 ]\n",
      " [10.4450786 ]\n",
      " [13.57964903]\n",
      " [13.3370058 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.0409314 ]\n",
      " [ 0.0450786 ]\n",
      " [-4.72035097]\n",
      " [-5.1629942 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.63291265e+01]\n",
      " [2.03208033e-03]\n",
      " [2.22817133e+01]\n",
      " [2.66565091e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  8.158672623544806 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.8898985 ]\n",
      " [ 2.19974609]\n",
      " [ 1.37289503]\n",
      " [ 1.61231654]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  161\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.09926395]\n",
      " [10.46724524]\n",
      " [13.62013056]\n",
      " [13.37295427]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-4.00073605]\n",
      " [ 0.06724524]\n",
      " [-4.67986944]\n",
      " [-5.12704573]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.60058890e+01]\n",
      " [4.52192216e-03]\n",
      " [2.19011779e+01]\n",
      " [2.62865979e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  8.02477334532049 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.92424952]\n",
      " [ 2.20714036]\n",
      " [ 1.38170754]\n",
      " [ 1.61512643]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  162\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.13904105]\n",
      " [10.48912372]\n",
      " [13.66025574]\n",
      " [13.40857756]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.96095895]\n",
      " [ 0.08912372]\n",
      " [-4.63974426]\n",
      " [-5.09142244]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.56891958e+01]\n",
      " [7.94303805e-03]\n",
      " [2.15272268e+01]\n",
      " [2.59225824e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  7.893368507548489 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.95825702]\n",
      " [ 2.21450571]\n",
      " [ 1.3904934 ]\n",
      " [ 1.6179003 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  163\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.1784046 ]\n",
      " [10.51071708]\n",
      " [13.70002756]\n",
      " [13.44387886]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.9215954 ]\n",
      " [ 0.11071708]\n",
      " [-4.59997244]\n",
      " [-5.05612114]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.53789105e+01]\n",
      " [1.22582724e-02]\n",
      " [2.11597464e+01]\n",
      " [2.55643610e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  7.7644095286538715 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[13.99192445]\n",
      " [ 2.22184245]\n",
      " [ 1.39925254]\n",
      " [ 1.62063856]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  164\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.21735919]\n",
      " [10.53202832]\n",
      " [13.73944902]\n",
      " [13.47886129]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.88264081]\n",
      " [ 0.13202832]\n",
      " [-4.56055098]\n",
      " [-5.02113871]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.50748997e+01]\n",
      " [1.74314761e-02]\n",
      " [2.07986253e+01]\n",
      " [2.52118339e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  7.637848788856765 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.02525521]\n",
      " [ 2.22915088]\n",
      " [ 1.4079849 ]\n",
      " [ 1.62334163]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  165\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.2559094 ]\n",
      " [10.55306039]\n",
      " [13.77852307]\n",
      " [13.51352798]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.8440906 ]\n",
      " [ 0.15306039]\n",
      " [-4.52147693]\n",
      " [-4.98647202]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.47770326e+01]\n",
      " [2.34274835e-02]\n",
      " [2.04437536e+01]\n",
      " [2.48649032e+01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  7.5136396109491965 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.05825266]\n",
      " [ 2.2364313 ]\n",
      " [ 1.41669041]\n",
      " [ 1.62600991]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  166\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.29405972]\n",
      " [10.57381625]\n",
      " [13.81725267]\n",
      " [13.54788199]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.80594028]\n",
      " [ 0.17381625]\n",
      " [-4.48274733]\n",
      " [-4.95211801]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[14.48518145]\n",
      " [ 0.03021209]\n",
      " [20.09502365]\n",
      " [24.52347274]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  7.391736241460398 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.09092013]\n",
      " [ 2.24368399]\n",
      " [ 1.42536902]\n",
      " [ 1.62864381]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  167\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.3318146 ]\n",
      " [10.59429881]\n",
      " [13.85564072]\n",
      " [13.58192639]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.7681854 ]\n",
      " [ 0.19429881]\n",
      " [-4.44435928]\n",
      " [-4.91807361]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[14.19922124]\n",
      " [ 0.03775203]\n",
      " [19.75232937]\n",
      " [24.18744801]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  7.272093832202722 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.12326093]\n",
      " [ 2.25090925]\n",
      " [ 1.43402068]\n",
      " [ 1.63124373]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  168\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.36917843]\n",
      " [10.61451095]\n",
      " [13.89369014]\n",
      " [13.61566419]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.73082157]\n",
      " [ 0.21451095]\n",
      " [-4.40630986]\n",
      " [-4.88433581]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[13.91902959]\n",
      " [ 0.04601495]\n",
      " [19.41556654]\n",
      " [23.85673629]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  7.154668422190218 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.15527832]\n",
      " [ 2.25810733]\n",
      " [ 1.44264535]\n",
      " [ 1.63381005]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  169\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.40615555]\n",
      " [10.63445553]\n",
      " [13.93140381]\n",
      " [13.64909838]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.69384445]\n",
      " [ 0.23445553]\n",
      " [-4.36859619]\n",
      " [-4.85090162]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[13.64448679]\n",
      " [ 0.0549694 ]\n",
      " [19.08463268]\n",
      " [23.53124649]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  7.03941691992235 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.18697554]\n",
      " [ 2.26527853]\n",
      " [ 1.45124297]\n",
      " [ 1.63634316]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  170\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.44275025]\n",
      " [10.65413538]\n",
      " [13.96878458]\n",
      " [13.68223193]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.65724975]\n",
      " [ 0.25413538]\n",
      " [-4.33121542]\n",
      " [-4.81776807]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[13.3754757 ]\n",
      " [ 0.06458479]\n",
      " [18.75942704]\n",
      " [23.21088915]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.926297086025141 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.21835578]\n",
      " [ 2.2724231 ]\n",
      " [ 1.45981351]\n",
      " [ 1.63884345]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  171\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.47896676]\n",
      " [10.67355331]\n",
      " [14.00583529]\n",
      " [13.71506777]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.62103324]\n",
      " [ 0.27355331]\n",
      " [-4.29416471]\n",
      " [-4.78493223]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[13.1118817 ]\n",
      " [ 0.07483141]\n",
      " [18.43985058]\n",
      " [22.89557644]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.815267516242621 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.24942222]\n",
      " [ 2.27954131]\n",
      " [ 1.46835694]\n",
      " [ 1.64131127]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  172\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.51480926]\n",
      " [10.69271207]\n",
      " [14.04255876]\n",
      " [13.7476088 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.58519074]\n",
      " [ 0.29271207]\n",
      " [-4.25744124]\n",
      " [-4.7523912 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[12.85359263]\n",
      " [ 0.08568036]\n",
      " [18.12580591]\n",
      " [22.5852221 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.706287624771186 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.280178  ]\n",
      " [ 2.28663341]\n",
      " [ 1.47687321]\n",
      " [ 1.64374702]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  173\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.55028188]\n",
      " [10.71161443]\n",
      " [14.07895779]\n",
      " [13.7798579 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.54971812]\n",
      " [ 0.31161443]\n",
      " [-4.22104221]\n",
      " [-4.7201421 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[12.60049875]\n",
      " [ 0.09710355]\n",
      " [17.81719732]\n",
      " [22.2797414 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.599317627930008 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.31062622]\n",
      " [ 2.29369966]\n",
      " [ 1.48536231]\n",
      " [ 1.64615104]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  174\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.58538869]\n",
      " [10.73026311]\n",
      " [14.11503516]\n",
      " [13.81181793]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.51461131]\n",
      " [ 0.33026311]\n",
      " [-4.18496484]\n",
      " [-4.68818207]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[12.35249265]\n",
      " [ 0.10907372]\n",
      " [17.5139307 ]\n",
      " [21.97905115]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.494318528160436 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.34076996]\n",
      " [ 2.30074031]\n",
      " [ 1.4938242 ]\n",
      " [ 1.64852369]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  175\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.62013373]\n",
      " [10.74866079]\n",
      " [14.15079363]\n",
      " [13.84349169]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.47986627]\n",
      " [ 0.34866079]\n",
      " [-4.14920637]\n",
      " [-4.65650831]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[12.10946925]\n",
      " [ 0.12156435]\n",
      " [17.21591354]\n",
      " [21.68306964]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.39125209834781 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.37061226]\n",
      " [ 2.3077556 ]\n",
      " [ 1.50225887]\n",
      " [ 1.65086534]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  176\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.65452098]\n",
      " [10.76681016]\n",
      " [14.18623592]\n",
      " [13.87488199]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.44547902]\n",
      " [ 0.36681016]\n",
      " [-4.11376408]\n",
      " [-4.62511801]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[11.8713257 ]\n",
      " [ 0.13454969]\n",
      " [16.92305491]\n",
      " [21.39171664]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.290080866458961 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.40015614]\n",
      " [ 2.31474577]\n",
      " [ 1.51066629]\n",
      " [ 1.65317633]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  177\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.68855436]\n",
      " [10.78471384]\n",
      " [14.22136476]\n",
      " [13.90599158]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.41144564]\n",
      " [ 0.38471384]\n",
      " [-4.07863524]\n",
      " [-4.59400842]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[11.63796134]\n",
      " [ 0.14800474]\n",
      " [16.6352654 ]\n",
      " [21.10491333]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.19076810048901 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.42940458]\n",
      " [ 2.32171105]\n",
      " [ 1.51904644]\n",
      " [ 1.65545699]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  178\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.72223777]\n",
      " [10.80237446]\n",
      " [14.25618285]\n",
      " [13.93682322]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.37776223]\n",
      " [ 0.40237446]\n",
      " [-4.04381715]\n",
      " [-4.56317678]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[11.40927767]\n",
      " [ 0.16190521]\n",
      " [16.35245714]\n",
      " [20.82258233]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  6.093277793711065 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.45836053]\n",
      " [ 2.32865167]\n",
      " [ 1.52739933]\n",
      " [ 1.65770768]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  179\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.75557504]\n",
      " [10.81979461]\n",
      " [14.29069286]\n",
      " [13.96737961]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.34442496]\n",
      " [ 0.41979461]\n",
      " [-4.00930714]\n",
      " [-4.53262039]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[11.18517831]\n",
      " [ 0.17622752]\n",
      " [16.07454375]\n",
      " [20.54464762]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.9975746502227345 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.48702692]\n",
      " [ 2.33556786]\n",
      " [ 1.53572493]\n",
      " [ 1.65992873]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  180\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.78856996]\n",
      " [10.83697686]\n",
      " [14.32489744]\n",
      " [13.99766343]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.31143004]\n",
      " [ 0.43697686]\n",
      " [-3.97510256]\n",
      " [-4.50233657]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[10.9655689 ]\n",
      " [ 0.19094878]\n",
      " [15.80144033]\n",
      " [20.27103456]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.90362407078333 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.51540666]\n",
      " [ 2.34245983]\n",
      " [ 1.54402324]\n",
      " [ 1.66212046]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  181\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.82122628]\n",
      " [10.85392374]\n",
      " [14.35879924]\n",
      " [14.02767736]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.27877372]\n",
      " [ 0.45392374]\n",
      " [-3.94120076]\n",
      " [-4.47232264]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[10.75035711]\n",
      " [ 0.20604677]\n",
      " [15.53306341]\n",
      " [20.00166982]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.811392138935748 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.54350259]\n",
      " [ 2.34932782]\n",
      " [ 1.55229425]\n",
      " [ 1.6642832 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  182\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.85354769]\n",
      " [10.87063778]\n",
      " [14.39240087]\n",
      " [14.05742401]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.24645231]\n",
      " [ 0.47063778]\n",
      " [-3.90759913]\n",
      " [-4.44257599]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[10.53945258]\n",
      " [ 0.22149992]\n",
      " [15.26933096]\n",
      " [19.73648141]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.72084560740742 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.57131756]\n",
      " [ 2.35617202]\n",
      " [ 1.56053796]\n",
      " [ 1.66641727]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  183\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.88553786]\n",
      " [10.88712146]\n",
      " [14.42570493]\n",
      " [14.08690601]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.21446214]\n",
      " [ 0.48712146]\n",
      " [-3.87429507]\n",
      " [-4.41309399]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[10.33276684]\n",
      " [ 0.23728732]\n",
      " [15.01016233]\n",
      " [19.47539859]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.631951884784407 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.59885439]\n",
      " [ 2.36299265]\n",
      " [ 1.56875439]\n",
      " [ 1.66852298]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  184\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.91720039]\n",
      " [10.90337725]\n",
      " [14.45871398]\n",
      " [14.11612592]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.18279961]\n",
      " [ 0.50337725]\n",
      " [-3.84128602]\n",
      " [-4.38387408]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[10.13021334]\n",
      " [ 0.25338866]\n",
      " [14.75547827]\n",
      " [19.21835192]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.544679022453298 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.62611584]\n",
      " [ 2.36978992]\n",
      " [ 1.57694352]\n",
      " [ 1.67060066]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  185\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.94853886]\n",
      " [10.9194076 ]\n",
      " [14.4914306 ]\n",
      " [14.14508632]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.15146114]\n",
      " [ 0.5194076 ]\n",
      " [-3.8085694 ]\n",
      " [-4.35491368]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 9.93170733]\n",
      " [ 0.26978425]\n",
      " [14.50520087]\n",
      " [18.96527317]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.458995701805246 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.65310469]\n",
      " [ 2.37656402]\n",
      " [ 1.58510536]\n",
      " [ 1.6726506 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  186\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[18.97955678]\n",
      " [10.93521491]\n",
      " [14.52385732]\n",
      " [14.17378973]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.12044322]\n",
      " [ 0.53521491]\n",
      " [-3.77614268]\n",
      " [-4.32621027]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 9.73716587]\n",
      " [ 0.28645501]\n",
      " [14.25925357]\n",
      " [18.71609533]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.3748712216969725 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.67982364]\n",
      " [ 2.38331516]\n",
      " [ 1.59323993]\n",
      " [ 1.67467311]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  187\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.01025765]\n",
      " [10.9508016 ]\n",
      " [14.55599665]\n",
      " [14.20223865]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.08974235]\n",
      " [ 0.5508016 ]\n",
      " [-3.74400335]\n",
      " [-4.29776135]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 9.54650778]\n",
      " [ 0.3033824 ]\n",
      " [14.0175611 ]\n",
      " [18.4707526 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.292275486163438 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.7062754 ]\n",
      " [ 2.39004352]\n",
      " [ 1.60134723]\n",
      " [ 1.67666849]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  188\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.0406449 ]\n",
      " [10.96617003]\n",
      " [14.58785109]\n",
      " [14.23043558]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.0593551 ]\n",
      " [ 0.56617003]\n",
      " [-3.71214891]\n",
      " [-4.26956442]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 9.3596536 ]\n",
      " [ 0.3205485 ]\n",
      " [13.7800495 ]\n",
      " [18.22918033]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.211178992377017 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.73246265]\n",
      " [ 2.39674931]\n",
      " [ 1.60942729]\n",
      " [ 1.67863704]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  189\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.07072194]\n",
      " [10.98132255]\n",
      " [14.61942313]\n",
      " [14.25838297]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.02927806]\n",
      " [ 0.58132255]\n",
      " [-3.68057687]\n",
      " [-4.24161703]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 9.17652554]\n",
      " [ 0.3379359 ]\n",
      " [13.54664607]\n",
      " [17.99131504]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.131552818848313 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.75838802]\n",
      " [ 2.4034327 ]\n",
      " [ 1.61748011]\n",
      " [ 1.68057903]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  190\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.10049213]\n",
      " [10.99626147]\n",
      " [14.65071523]\n",
      " [14.28608325]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.99950787]\n",
      " [ 0.59626147]\n",
      " [-3.64928477]\n",
      " [-4.21391675]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 8.99704745]\n",
      " [ 0.35552775]\n",
      " [13.31727935]\n",
      " [17.75709436]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  5.05336861386351 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.78405414]\n",
      " [ 2.41009388]\n",
      " [ 1.62550571]\n",
      " [ 1.68249478]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  191\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.12995879]\n",
      " [11.01098912]\n",
      " [14.68172982]\n",
      " [14.31353884]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.97004121]\n",
      " [ 0.61098912]\n",
      " [-3.61827018]\n",
      " [-4.18646116]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 8.8211448 ]\n",
      " [ 0.37330771]\n",
      " [13.09187912]\n",
      " [17.52645704]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.976598584153624 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.8094636 ]\n",
      " [ 2.41673304]\n",
      " [ 1.63350412]\n",
      " [ 1.68438454]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  192\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.15912519]\n",
      " [11.02550776]\n",
      " [14.71246932]\n",
      " [14.34075212]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.94087481]\n",
      " [ 0.62550776]\n",
      " [-3.58753068]\n",
      " [-4.15924788]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 8.64874462]\n",
      " [ 0.39125996]\n",
      " [12.87037637]\n",
      " [17.29934292]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.901215483790855 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.83461896]\n",
      " [ 2.42335034]\n",
      " [ 1.64147535]\n",
      " [ 1.68624862]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  193\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.18799459]\n",
      " [11.03981966]\n",
      " [14.74293615]\n",
      " [14.36772546]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.91200541]\n",
      " [ 0.63981966]\n",
      " [-3.55706385]\n",
      " [-4.13227454]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 8.47977549]\n",
      " [ 0.40936919]\n",
      " [12.65270326]\n",
      " [17.07569289]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.827192603307475 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.85952277]\n",
      " [ 2.42994597]\n",
      " [ 1.64941943]\n",
      " [ 1.68808727]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  194\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.21657019]\n",
      " [11.05392704]\n",
      " [14.77313268]\n",
      " [14.39446119]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.88342981]\n",
      " [ 0.65392704]\n",
      " [-3.52686732]\n",
      " [-4.10553881]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 8.31416746]\n",
      " [ 0.42762057]\n",
      " [12.43879313]\n",
      " [16.85544891]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.754503759032698 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.88417755]\n",
      " [ 2.43652009]\n",
      " [ 1.65733639]\n",
      " [ 1.68990078]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  195\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.24485515]\n",
      " [11.06783212]\n",
      " [14.80306127]\n",
      " [14.42096164]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.85514485]\n",
      " [ 0.66783212]\n",
      " [-3.49693873]\n",
      " [-4.07903836]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 8.15185209]\n",
      " [ 0.44599974]\n",
      " [12.22858046]\n",
      " [16.63855397]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.683123282643163 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.90858577]\n",
      " [ 2.44307288]\n",
      " [ 1.66522626]\n",
      " [ 1.69168942]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  196\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.27285261]\n",
      " [11.0815371 ]\n",
      " [14.83272429]\n",
      " [14.44722909]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.82714739]\n",
      " [ 0.6815371 ]\n",
      " [-3.46727571]\n",
      " [-4.05277091]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 7.99276236]\n",
      " [ 0.46449281]\n",
      " [12.02200088]\n",
      " [16.42495204]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.613026010922674 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.93274991]\n",
      " [ 2.44960449]\n",
      " [ 1.67308907]\n",
      " [ 1.69345344]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  197\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.30056566]\n",
      " [11.09504413]\n",
      " [14.86212404]\n",
      " [14.47326582]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.79943434]\n",
      " [ 0.69504413]\n",
      " [-3.43787596]\n",
      " [-4.02673418]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 7.83683265]\n",
      " [ 0.48308634]\n",
      " [11.8189911 ]\n",
      " [16.21458812]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.544187275726953 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.95667241]\n",
      " [ 2.4561151 ]\n",
      " [ 1.68092484]\n",
      " [ 1.69519312]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  198\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.32799734]\n",
      " [11.10835537]\n",
      " [14.89126285]\n",
      " [14.49907409]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.77200266]\n",
      " [ 0.70835537]\n",
      " [-3.40873715]\n",
      " [-4.00092591]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 7.68399873]\n",
      " [ 0.50176733]\n",
      " [11.61948895]\n",
      " [16.00740815]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.4765828941492884 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[14.98035569]\n",
      " [ 2.46260485]\n",
      " [ 1.68873362]\n",
      " [ 1.6969087 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  199\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.3551507 ]\n",
      " [11.12147295]\n",
      " [14.92014301]\n",
      " [14.52465611]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.7448493 ]\n",
      " [ 0.72147295]\n",
      " [-3.37985699]\n",
      " [-3.97534389]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 7.5341977 ]\n",
      " [ 0.52052322]\n",
      " [11.42343331]\n",
      " [15.80335905]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.41018915888297 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.00380213]\n",
      " [ 2.46907392]\n",
      " [ 1.69651543]\n",
      " [ 1.69860045]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  200\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.3820287 ]\n",
      " [11.13439897]\n",
      " [14.94876678]\n",
      " [14.55001409]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.7179713 ]\n",
      " [ 0.73439897]\n",
      " [-3.35123322]\n",
      " [-3.94998591]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 7.387368  ]\n",
      " [ 0.53934184]\n",
      " [11.23076413]\n",
      " [15.60238866]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.3449828287765735 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.02701411]\n",
      " [ 2.47552244]\n",
      " [ 1.70427032]\n",
      " [ 1.70026861]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  201\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.4086343 ]\n",
      " [11.14713551]\n",
      " [14.97713642]\n",
      " [14.57515022]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.6913657 ]\n",
      " [ 0.74713551]\n",
      " [-3.32286358]\n",
      " [-3.92484978]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 7.24344933]\n",
      " [ 0.55821147]\n",
      " [11.0414224 ]\n",
      " [15.40444576]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.28094111957815 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.04999397]\n",
      " [ 2.48195058]\n",
      " [ 1.71199833]\n",
      " [ 1.70191344]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  202\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.43497042]\n",
      " [11.15968464]\n",
      " [15.00525417]\n",
      " [14.60006666]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.66502958]\n",
      " [ 0.75968464]\n",
      " [-3.29474583]\n",
      " [-3.89993334]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 7.10238267]\n",
      " [ 0.57712075]\n",
      " [10.85535011]\n",
      " [15.20948003]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.218041694864569 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.07274403]\n",
      " [ 2.48835847]\n",
      " [ 1.71969949]\n",
      " [ 1.70353518]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  203\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.46103993]\n",
      " [11.17204839]\n",
      " [15.03312224]\n",
      " [14.62476555]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.63896007]\n",
      " [ 0.77204839]\n",
      " [-3.26687776]\n",
      " [-3.87523445]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 6.96411023]\n",
      " [ 0.59605872]\n",
      " [10.67249029]\n",
      " [15.01744201]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.1562626571522 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.09526659]\n",
      " [ 2.49474627]\n",
      " [ 1.72737385]\n",
      " [ 1.70513407]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  204\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.4868457 ]\n",
      " [11.18422881]\n",
      " [15.06074284]\n",
      " [14.64924901]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.6131543 ]\n",
      " [ 0.78422881]\n",
      " [-3.23925716]\n",
      " [-3.85075099]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 6.82857541]\n",
      " [ 0.61501482]\n",
      " [10.49278693]\n",
      " [14.82828315]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.095582539185314 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.11756392]\n",
      " [ 2.50111413]\n",
      " [ 1.73502145]\n",
      " [ 1.70671036]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  205\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.51239052]\n",
      " [11.19622788]\n",
      " [15.08811815]\n",
      " [14.67351914]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.58760948]\n",
      " [ 0.79622788]\n",
      " [-3.21188185]\n",
      " [-3.82648086]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 6.6957228 ]\n",
      " [ 0.63397883]\n",
      " [10.31618499]\n",
      " [14.64195574]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  4.035980295398612 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.13963829]\n",
      " [ 2.50746217]\n",
      " [ 1.74264234]\n",
      " [ 1.70826427]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  206\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.53767719]\n",
      " [11.20804758]\n",
      " [15.11525034]\n",
      " [14.69757802]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.56232281]\n",
      " [ 0.80804758]\n",
      " [-3.18474966]\n",
      " [-3.80242198]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 6.56549816]\n",
      " [ 0.6529409 ]\n",
      " [10.14263039]\n",
      " [14.4584129 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.9774352935503687 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.1614919 ]\n",
      " [ 2.51379054]\n",
      " [ 1.75023656]\n",
      " [ 1.70979605]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  207\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.56270846]\n",
      " [11.21968989]\n",
      " [15.14214155]\n",
      " [14.72142771]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.53729154]\n",
      " [ 0.81968989]\n",
      " [-3.15785845]\n",
      " [-3.77857229]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 6.43784836]\n",
      " [ 0.67189152]\n",
      " [ 9.97207   ]\n",
      " [14.27760858]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.919927306522734 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.18312698]\n",
      " [ 2.52009938]\n",
      " [ 1.75780417]\n",
      " [ 1.71130591]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  208\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.58748704]\n",
      " [11.23115675]\n",
      " [15.16879391]\n",
      " [14.74507023]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.51251296]\n",
      " [ 0.83115675]\n",
      " [-3.13120609]\n",
      " [-3.75492977]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 6.31272136]\n",
      " [ 0.69082154]\n",
      " [ 9.80445158]\n",
      " [14.09949755]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.8634365042858376 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.20454571]\n",
      " [ 2.52638882]\n",
      " [ 1.7653452 ]\n",
      " [ 1.7127941 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  209\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.61201562]\n",
      " [11.24245007]\n",
      " [15.19520953]\n",
      " [14.76850762]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.48798438]\n",
      " [ 0.84245007]\n",
      " [-3.10479047]\n",
      " [-3.73149238]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 6.19006625]\n",
      " [ 0.70972212]\n",
      " [ 9.63972384]\n",
      " [13.92403536]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.807943446022392 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.22575026]\n",
      " [ 2.532659  ]\n",
      " [ 1.77285971]\n",
      " [ 1.71426083]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  210\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.63629687]\n",
      " [11.25357177]\n",
      " [15.22139052]\n",
      " [14.79174187]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.46370313]\n",
      " [ 0.85357177]\n",
      " [-3.07860948]\n",
      " [-3.70825813]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 6.06983313]\n",
      " [ 0.72858477]\n",
      " [ 9.47783634]\n",
      " [13.75117835]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.753429072409546 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.24674275]\n",
      " [ 2.53891003]\n",
      " [ 1.78034776]\n",
      " [ 1.71570633]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  211\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.66033339]\n",
      " [11.26452373]\n",
      " [15.24733894]\n",
      " [14.81477496]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.43966661]\n",
      " [ 0.86452373]\n",
      " [-3.05266106]\n",
      " [-3.68522504]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.95197316]\n",
      " [ 0.74740127]\n",
      " [ 9.31873954]\n",
      " [13.58088362]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.699874698054828 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.26752533]\n",
      " [ 2.54514205]\n",
      " [ 1.78780939]\n",
      " [ 1.71713081]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  212\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.6841278 ]\n",
      " [11.27530781]\n",
      " [15.27305686]\n",
      " [14.83760884]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.4158722 ]\n",
      " [ 0.87530781]\n",
      " [-3.02694314]\n",
      " [-3.66239116]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.8364385 ]\n",
      " [ 0.76616376]\n",
      " [ 9.16238475]\n",
      " [13.41310903]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.647262004083133 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.28810007]\n",
      " [ 2.55135518]\n",
      " [ 1.79524467]\n",
      " [ 1.71853449]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  213\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.70768265]\n",
      " [11.28592586]\n",
      " [15.29854633]\n",
      " [14.86024545]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.39231735]\n",
      " [ 0.88592586]\n",
      " [-3.00145367]\n",
      " [-3.63975455]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.72318231]\n",
      " [ 0.78486463]\n",
      " [ 9.00872414]\n",
      " [13.24781317]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.595573030871562 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.30846907]\n",
      " [ 2.55754956]\n",
      " [ 1.80265364]\n",
      " [ 1.71991759]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  214\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.73100048]\n",
      " [11.29637972]\n",
      " [15.32380936]\n",
      " [14.88268672]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.36899952]\n",
      " [ 0.89637972]\n",
      " [-2.97619064]\n",
      " [-3.61731328]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.61215871]\n",
      " [ 0.8034966 ]\n",
      " [ 8.8577107 ]\n",
      " [13.08495535]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.544790170929322 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.32863438]\n",
      " [ 2.56372529]\n",
      " [ 1.81003636]\n",
      " [ 1.72128031]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  215\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.75408381]\n",
      " [11.30667119]\n",
      " [15.34884798]\n",
      " [14.90493455]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.34591619]\n",
      " [ 0.90667119]\n",
      " [-2.95115202]\n",
      " [-3.59506545]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.50332278]\n",
      " [ 0.82205265]\n",
      " [ 8.70929824]\n",
      " [12.92449562]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.4948961619196455 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.34859804]\n",
      " [ 2.56988249]\n",
      " [ 1.81739289]\n",
      " [ 1.72262287]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  216\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.7769351 ]\n",
      " [11.31680207]\n",
      " [15.37366417]\n",
      " [14.92699081]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.3230649 ]\n",
      " [ 0.91680207]\n",
      " [-2.92633583]\n",
      " [-3.57300919]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.39663053]\n",
      " [ 0.84052604]\n",
      " [ 8.56344138]\n",
      " [12.76639468]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.4458740798209124 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.36836206]\n",
      " [ 2.57602129]\n",
      " [ 1.82472328]\n",
      " [ 1.72394547]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  217\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.79955681]\n",
      " [11.32677413]\n",
      " [15.39825991]\n",
      " [14.94885737]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.30044319]\n",
      " [ 0.92677413]\n",
      " [-2.90174009]\n",
      " [-3.55114263]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.29203887]\n",
      " [ 0.8589103 ]\n",
      " [ 8.42009553]\n",
      " [12.61061396]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.3977073322241713 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.38792844]\n",
      " [ 2.5821418 ]\n",
      " [ 1.83202761]\n",
      " [ 1.72524831]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  218\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.82195136]\n",
      " [11.33658914]\n",
      " [15.42263717]\n",
      " [14.97053608]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.27804864]\n",
      " [ 0.93658914]\n",
      " [-2.87736283]\n",
      " [-3.52946392]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.1895056 ]\n",
      " [ 0.87719921]\n",
      " [ 8.27921686]\n",
      " [12.45711555]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.350379651764309 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.40729915]\n",
      " [ 2.58824413]\n",
      " [ 1.83930592]\n",
      " [ 1.7265316 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  219\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.84412115]\n",
      " [11.34624881]\n",
      " [15.44679788]\n",
      " [14.99202877]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.25587885]\n",
      " [ 0.94624881]\n",
      " [-2.85320212]\n",
      " [-3.50797123]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 5.08898938]\n",
      " [ 0.89538682]\n",
      " [ 8.14076233]\n",
      " [12.30586218]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.3038750896822338 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.42647616]\n",
      " [ 2.5943284 ]\n",
      " [ 1.84655828]\n",
      " [ 1.72779554]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  220\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.86606854]\n",
      " [11.35575489]\n",
      " [15.47074398]\n",
      " [15.01333723]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.23393146]\n",
      " [ 0.95575489]\n",
      " [-2.82925602]\n",
      " [-3.48666277]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.99044975]\n",
      " [ 0.91346742]\n",
      " [ 8.00468964]\n",
      " [12.15681727]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.258178009515328 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.4454614 ]\n",
      " [ 2.60039471]\n",
      " [ 1.85378475]\n",
      " [ 1.72904031]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  221\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.88779588]\n",
      " [11.36510908]\n",
      " [15.49447737]\n",
      " [15.03446327]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.21220412]\n",
      " [ 0.96510908]\n",
      " [-2.80552263]\n",
      " [-3.46553673]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.89384707]\n",
      " [ 0.93143553]\n",
      " [ 7.87095722]\n",
      " [12.00994484]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.213273080913723 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.46425679]\n",
      " [ 2.60644317]\n",
      " [ 1.86098539]\n",
      " [ 1.73026612]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  222\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.90930548]\n",
      " [11.37431305]\n",
      " [15.51799996]\n",
      " [15.05540865]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.19069452]\n",
      " [ 0.97431305]\n",
      " [-2.78200004]\n",
      " [-3.44459135]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.79914249]\n",
      " [ 0.94928592]\n",
      " [ 7.73952422]\n",
      " [11.86520955]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.169145273579815 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.48286422]\n",
      " [ 2.61247389]\n",
      " [ 1.86816028]\n",
      " [ 1.73147315]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  223\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.93059962]\n",
      " [11.38336849]\n",
      " [15.54131362]\n",
      " [15.07617514]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.16940038]\n",
      " [ 0.98336849]\n",
      " [-2.75868638]\n",
      " [-3.42382486]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.70629801]\n",
      " [ 0.96701359]\n",
      " [ 7.61035054]\n",
      " [11.72257668]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.1257798513284794 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.50128558]\n",
      " [ 2.61848697]\n",
      " [ 1.87530947]\n",
      " [ 1.7326616 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  224\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.95168057]\n",
      " [11.39227704]\n",
      " [15.56442022]\n",
      " [15.09676447]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.14831943]\n",
      " [ 0.99227704]\n",
      " [-2.73557978]\n",
      " [-3.40323553]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.61527636]\n",
      " [ 0.98461373]\n",
      " [ 7.48339674]\n",
      " [11.5820121 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.0831623662656904 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.51952272]\n",
      " [ 2.62448252]\n",
      " [ 1.88243302]\n",
      " [ 1.73383165]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  225\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.97255057]\n",
      " [11.40104035]\n",
      " [15.5873216 ]\n",
      " [15.11717835]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.12744943]\n",
      " [ 1.00104035]\n",
      " [-2.7126784 ]\n",
      " [-3.38282165]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.52604107]\n",
      " [ 1.00208178]\n",
      " [ 7.35862408]\n",
      " [11.4434823 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.041278653083083 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.53757749]\n",
      " [ 2.63046063]\n",
      " [ 1.88953101]\n",
      " [ 1.73498349]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  226\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[19.99321183]\n",
      " [11.40966003]\n",
      " [15.61001961]\n",
      " [15.13741851]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.10678817]\n",
      " [ 1.00966003]\n",
      " [-2.68998039]\n",
      " [-3.36258149]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.4385564 ]\n",
      " [ 1.01941337]\n",
      " [ 7.23599451]\n",
      " [11.30695431]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  3.000114823466144 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.55545172]\n",
      " [ 2.63642141]\n",
      " [ 1.8966035 ]\n",
      " [ 1.7361173 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  227\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.01366653]\n",
      " [11.41813768]\n",
      " [15.63251605]\n",
      " [15.15748661]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.08633347]\n",
      " [ 1.01813768]\n",
      " [-2.66748395]\n",
      " [-3.34251339]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.35278736]\n",
      " [ 1.03660434]\n",
      " [ 7.11547062]\n",
      " [11.17239576]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.959657260613774 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.5731472 ]\n",
      " [ 2.64236495]\n",
      " [ 1.90365057]\n",
      " [ 1.73723326]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  228\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.03391683]\n",
      " [11.4264749 ]\n",
      " [15.65481273]\n",
      " [15.17738434]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.06608317]\n",
      " [ 1.0264749 ]\n",
      " [-2.64518727]\n",
      " [-3.32261566]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.26869965]\n",
      " [ 1.05365072]\n",
      " [ 6.99701569]\n",
      " [11.03977484]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.919892613866984 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.59066573]\n",
      " [ 2.64829135]\n",
      " [ 1.91067227]\n",
      " [ 1.73833155]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  229\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.05396488]\n",
      " [11.43467326]\n",
      " [15.67691144]\n",
      " [15.19711334]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.04603512]\n",
      " [ 1.03467326]\n",
      " [-2.62308856]\n",
      " [-3.30288666]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.18625971]\n",
      " [ 1.07054874]\n",
      " [ 6.88059361]\n",
      " [10.90906028]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.8808077934445153 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.60800907]\n",
      " [ 2.65420071]\n",
      " [ 1.91766868]\n",
      " [ 1.73941235]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  230\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.07381279]\n",
      " [11.4427343 ]\n",
      " [15.69881394]\n",
      " [15.21667526]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.02618721]\n",
      " [ 1.0427343 ]\n",
      " [-2.60118606]\n",
      " [-3.28332474]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.10543462]\n",
      " [ 1.08729482]\n",
      " [ 6.76616892]\n",
      " [10.78022136]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.84238996528325 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.62517898]\n",
      " [ 2.66009312]\n",
      " [ 1.92463986]\n",
      " [ 1.74047583]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  231\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.09346264]\n",
      " [11.45065957]\n",
      " [15.720522  ]\n",
      " [15.23607171]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.00653736]\n",
      " [ 1.05065957]\n",
      " [-2.579478  ]\n",
      " [-3.26392829]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 4.02619218]\n",
      " [ 1.10388554]\n",
      " [ 6.65370676]\n",
      " [10.65322788]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.8046265459813515 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.64217719]\n",
      " [ 2.66596867]\n",
      " [ 1.9315859 ]\n",
      " [ 1.74152216]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  232\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.1129165 ]\n",
      " [11.4584506 ]\n",
      " [15.74203735]\n",
      " [15.2553043 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.9870835 ]\n",
      " [ 1.0584506 ]\n",
      " [-2.55796265]\n",
      " [-3.2446957 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 3.94850082]\n",
      " [ 1.12031768]\n",
      " [ 6.54317291]\n",
      " [10.52805017]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.76750519784201 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.65900542]\n",
      " [ 2.67182745]\n",
      " [ 1.93850685]\n",
      " [ 1.74255151]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  233\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.13217643]\n",
      " [11.4661089 ]\n",
      " [15.76336173]\n",
      " [15.27437462]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.96782357]\n",
      " [ 1.0661089 ]\n",
      " [-2.53663827]\n",
      " [-3.22562538]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 3.87232962]\n",
      " [ 1.13658818]\n",
      " [ 6.43453373]\n",
      " [10.40465906]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.7310138240158186 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.67566536]\n",
      " [ 2.67766956]\n",
      " [ 1.94540279]\n",
      " [ 1.74356405]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  234\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.15124442]\n",
      " [11.47363595]\n",
      " [15.78449684]\n",
      " [15.29328425]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.94875558]\n",
      " [ 1.07363595]\n",
      " [-2.51550316]\n",
      " [-3.20671575]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 3.7976483 ]\n",
      " [ 1.15269415]\n",
      " [ 6.32775616]\n",
      " [10.28302591]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.6951405637398222 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.69215871]\n",
      " [ 2.68349507]\n",
      " [ 1.95227379]\n",
      " [ 1.74455996]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  235\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.1701225 ]\n",
      " [11.48103323]\n",
      " [15.80544438]\n",
      " [15.31203473]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.9298775 ]\n",
      " [ 1.08103323]\n",
      " [-2.49455562]\n",
      " [-3.18796527]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 3.72442718]\n",
      " [ 1.16863285]\n",
      " [ 6.22280774]\n",
      " [10.16312254]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.659873787671251 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.70848712]\n",
      " [ 2.68930409]\n",
      " [ 1.95911993]\n",
      " [ 1.74553938]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  236\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.18881262]\n",
      " [11.48830221]\n",
      " [15.82620604]\n",
      " [15.33062762]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.91118738]\n",
      " [ 1.08830221]\n",
      " [-2.47379396]\n",
      " [-3.16937238]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[ 3.6526372 ]\n",
      " [ 1.18440171]\n",
      " [ 6.11965657]\n",
      " [10.04492127]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.6252020933140656 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.72465225]\n",
      " [ 2.69509668]\n",
      " [ 1.96594128]\n",
      " [ 1.7465025 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  237\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.20731675]\n",
      " [11.49544434]\n",
      " [15.84678348]\n",
      " [15.34906444]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.89268325]\n",
      " [ 1.09544434]\n",
      " [-2.45321652]\n",
      " [-3.15093556]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.58224989]\n",
      " [1.19999831]\n",
      " [6.0182713 ]\n",
      " [9.92839491]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.591114300536508 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.74065573]\n",
      " [ 2.70087294]\n",
      " [ 1.97273791]\n",
      " [ 1.74744946]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  238\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.22563681]\n",
      " [11.50246105]\n",
      " [15.86717836]\n",
      " [15.3673467 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.87436319]\n",
      " [ 1.10246105]\n",
      " [-2.43282164]\n",
      " [-3.1326533 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.51323735]\n",
      " [1.21542037]\n",
      " [5.91862115]\n",
      " [9.81351671]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.5575994471777452 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.75649917]\n",
      " [ 2.70663295]\n",
      " [ 1.97950989]\n",
      " [ 1.74838042]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  239\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.24377473]\n",
      " [11.50935376]\n",
      " [15.88739231]\n",
      " [15.3854759 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.85622527]\n",
      " [ 1.10935376]\n",
      " [-2.41260769]\n",
      " [-3.1145241 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.44557226]\n",
      " [1.23066576]\n",
      " [5.82067586]\n",
      " [9.7002604 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.524646784741896 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.77218418]\n",
      " [ 2.71237679]\n",
      " [ 1.9862573 ]\n",
      " [ 1.74929555]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  240\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.26173238]\n",
      " [11.51612387]\n",
      " [15.90742697]\n",
      " [15.40345351]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.83826762]\n",
      " [ 1.11612387]\n",
      " [-2.39257303]\n",
      " [-3.09654649]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.37922786]\n",
      " [1.24573248]\n",
      " [5.7244057 ]\n",
      " [9.58860015]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.4922457741776616 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.78771234]\n",
      " [ 2.71810455]\n",
      " [ 1.99298021]\n",
      " [ 1.750195  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  241\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.27951163]\n",
      " [11.52277277]\n",
      " [15.92728394]\n",
      " [15.42128102]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.82048837]\n",
      " [ 1.12277277]\n",
      " [-2.37271606]\n",
      " [-3.07871898]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.31417791]\n",
      " [1.26061869]\n",
      " [5.62978149]\n",
      " [9.47851057]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.4603860817418433 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.80308522]\n",
      " [ 2.72381629]\n",
      " [ 1.99967871]\n",
      " [ 1.75107893]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  242\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.29711434]\n",
      " [11.52930184]\n",
      " [15.94696483]\n",
      " [15.43895986]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.80288566]\n",
      " [ 1.12930184]\n",
      " [-2.35303517]\n",
      " [-3.06104014]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.25039672]\n",
      " [1.27532264]\n",
      " [5.53677453]\n",
      " [9.36996672]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.429057574945102 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.81830436]\n",
      " [ 2.72951211]\n",
      " [ 2.00635286]\n",
      " [ 1.75194748]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  243\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.31454232]\n",
      " [11.53571244]\n",
      " [15.96647121]\n",
      " [15.45649149]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.78545768]\n",
      " [ 1.13571244]\n",
      " [-2.33352879]\n",
      " [-3.04350851]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.18785912]\n",
      " [1.28984274]\n",
      " [5.44535663]\n",
      " [9.26294407]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.3982503185782766 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.83337132]\n",
      " [ 2.73519207]\n",
      " [ 2.01300274]\n",
      " [ 1.75280081]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  244\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.3317974 ]\n",
      " [11.54200591]\n",
      " [15.98580465]\n",
      " [15.47387731]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.7682026 ]\n",
      " [ 1.14200591]\n",
      " [-2.31419535]\n",
      " [-3.02612269]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.12654044]\n",
      " [1.30417751]\n",
      " [5.3555001 ]\n",
      " [9.15741852]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.3679545708176915 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.84828761]\n",
      " [ 2.74085625]\n",
      " [ 2.01962843]\n",
      " [ 1.75363906]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  245\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.34888135]\n",
      " [11.54818361]\n",
      " [16.00496672]\n",
      " [15.49111875]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.75111865]\n",
      " [ 1.14818361]\n",
      " [-2.29503328]\n",
      " [-3.00888125]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.06641654]\n",
      " [1.31832559]\n",
      " [5.26717774]\n",
      " [9.05336637]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.3381607794078025 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.86305473]\n",
      " [ 2.74650474]\n",
      " [ 2.02623   ]\n",
      " [ 1.75446238]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  246\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.36579594]\n",
      " [11.55424683]\n",
      " [16.02395896]\n",
      " [15.5082172 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.73420406]\n",
      " [ 1.15424683]\n",
      " [-2.27604104]\n",
      " [-2.9917828 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.00746373]\n",
      " [1.33228574]\n",
      " [5.18036281]\n",
      " [8.95076434]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.3088595779197654 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.87767418]\n",
      " [ 2.75213759]\n",
      " [ 2.03280753]\n",
      " [ 1.75527093]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  247\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.38254292]\n",
      " [11.56019689]\n",
      " [16.04278289]\n",
      " [15.52517403]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.71745708]\n",
      " [ 1.16019689]\n",
      " [-2.25721711]\n",
      " [-2.97482597]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.94965882]\n",
      " [1.34605682]\n",
      " [5.09502907]\n",
      " [8.84958954]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.2800417820842505 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.89214744]\n",
      " [ 2.75775489]\n",
      " [ 2.0393611 ]\n",
      " [ 1.75606484]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  248\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.39912402]\n",
      " [11.56603508]\n",
      " [16.06144004]\n",
      " [15.54199063]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.70087598]\n",
      " [ 1.16603508]\n",
      " [-2.23855996]\n",
      " [-2.95800937]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.8929791 ]\n",
      " [1.35963782]\n",
      " [5.01115071]\n",
      " [8.74981946]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.251698386197147 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.90647597]\n",
      " [ 2.76335671]\n",
      " [ 2.04589078]\n",
      " [ 1.75684425]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  249\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.41554095]\n",
      " [11.57176269]\n",
      " [16.07993189]\n",
      " [15.55866833]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.68445905]\n",
      " [ 1.17176269]\n",
      " [-2.22006811]\n",
      " [-2.94133167]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.83740228]\n",
      " [1.37302781]\n",
      " [4.92870239]\n",
      " [8.65143199]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.2238205595966534 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.92066121]\n",
      " [ 2.76894312]\n",
      " [ 2.05239666]\n",
      " [ 1.75760931]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  250\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.4317954 ]\n",
      " [11.57738098]\n",
      " [16.09825996]\n",
      " [15.57520849]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.6682046 ]\n",
      " [ 1.17738098]\n",
      " [-2.20174004]\n",
      " [-2.92479151]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.78290658]\n",
      " [1.38622597]\n",
      " [4.84765921]\n",
      " [8.55440539]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.1963996432103032 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.9347046 ]\n",
      " [ 2.77451419]\n",
      " [ 2.05887881]\n",
      " [ 1.75836016]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  251\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.44788905]\n",
      " [11.5828912 ]\n",
      " [16.11642571]\n",
      " [15.59161243]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.65211095]\n",
      " [ 1.1828912 ]\n",
      " [-2.18357429]\n",
      " [-2.90838757]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.7294706 ]\n",
      " [1.39923159]\n",
      " [4.7679967 ]\n",
      " [8.45871828]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.1694271461706043 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.94860755]\n",
      " [ 2.78006998]\n",
      " [ 2.0653373 ]\n",
      " [ 1.75909693]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  252\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.46382354]\n",
      " [11.5882946 ]\n",
      " [16.1344306 ]\n",
      " [15.60788146]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.63617646]\n",
      " [ 1.1882946 ]\n",
      " [-2.1655694 ]\n",
      " [-2.89211854]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.67707341]\n",
      " [1.41204405]\n",
      " [4.68969083]\n",
      " [8.36434965]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.1428947424978166 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.96237147]\n",
      " [ 2.78561057]\n",
      " [ 2.07177223]\n",
      " [ 1.75981976]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  253\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.47960052]\n",
      " [11.5935924 ]\n",
      " [16.15227609]\n",
      " [15.62401689]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.62039948]\n",
      " [ 1.1935924 ]\n",
      " [-2.14772391]\n",
      " [-2.87598311]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.62569448]\n",
      " [1.42466282]\n",
      " [4.612718  ]\n",
      " [8.27127884]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.116794267848623 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.97599776]\n",
      " [ 2.79113602]\n",
      " [ 2.07818366]\n",
      " [ 1.76052879]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  254\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.4952216 ]\n",
      " [11.59878582]\n",
      " [16.16996362]\n",
      " [15.64002001]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.6047784 ]\n",
      " [ 1.19878582]\n",
      " [-2.13003638]\n",
      " [-2.85997999]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.57531372]\n",
      " [1.43708744]\n",
      " [4.537055  ]\n",
      " [8.17948557]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.0911177163293453 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[15.98948778]\n",
      " [ 2.79664641]\n",
      " [ 2.08457167]\n",
      " [ 1.76122415]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  255\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.51068838]\n",
      " [11.60387606]\n",
      " [16.1874946 ]\n",
      " [15.65589208]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.58931162]\n",
      " [ 1.20387606]\n",
      " [-2.1125054 ]\n",
      " [-2.84410792]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.52591143]\n",
      " [1.44931757]\n",
      " [4.46267904]\n",
      " [8.08894985]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.065857237372411 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.0028429 ]\n",
      " [ 2.80214178]\n",
      " [ 2.09093635]\n",
      " [ 1.76190597]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  256\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.52600245]\n",
      " [11.60886432]\n",
      " [16.20487047]\n",
      " [15.67163438]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.57399755]\n",
      " [ 1.20886432]\n",
      " [-2.09512953]\n",
      " [-2.82836562]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.47746829]\n",
      " [1.46135294]\n",
      " [4.38956775]\n",
      " [7.99965208]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.041005132674776 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.01606447]\n",
      " [ 2.80762222]\n",
      " [ 2.09727778]\n",
      " [ 1.76257438]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  257\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.54116537]\n",
      " [11.61375177]\n",
      " [16.22209261]\n",
      " [15.68724815]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.55883463]\n",
      " [ 1.21375177]\n",
      " [-2.07790739]\n",
      " [-2.81275185]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.4299654 ]\n",
      " [1.47319335]\n",
      " [4.31769912]\n",
      " [7.91157296]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  2.016553853197163 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.02915383]\n",
      " [ 2.81308778]\n",
      " [ 2.10359602]\n",
      " [ 1.76322951]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  258\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.55617869]\n",
      " [11.61853957]\n",
      " [16.23916242]\n",
      " [15.70273464]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.54382131]\n",
      " [ 1.21853957]\n",
      " [-2.06083758]\n",
      " [-2.79726536]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.38338422]\n",
      " [1.48483869]\n",
      " [4.24705154]\n",
      " [7.82469352]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.992495996222801 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.04211229]\n",
      " [ 2.81853853]\n",
      " [ 2.10989116]\n",
      " [ 1.7638715 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  259\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.57104395]\n",
      " [11.62322889]\n",
      " [16.25608127]\n",
      " [15.71809506]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.52895605]\n",
      " [ 1.22322889]\n",
      " [-2.04391873]\n",
      " [-2.78190494]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.33770659]\n",
      " [1.49628892]\n",
      " [4.17760378]\n",
      " [7.73899512]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.968824302474539 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.05494117]\n",
      " [ 2.82397453]\n",
      " [ 2.11616329]\n",
      " [ 1.76450047]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  260\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.58576266]\n",
      " [11.62782087]\n",
      " [16.27285052]\n",
      " [15.73333063]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.51423734]\n",
      " [ 1.22782087]\n",
      " [-2.02714948]\n",
      " [-2.76666937]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.29291472]\n",
      " [1.50754408]\n",
      " [4.109335  ]\n",
      " [7.65445943]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.945531653289148 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.06764176]\n",
      " [ 2.82939583]\n",
      " [ 2.12241248]\n",
      " [ 1.76511653]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  261\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.60033632]\n",
      " [11.63231663]\n",
      " [16.28947154]\n",
      " [15.74844255]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.49966368]\n",
      " [ 1.23231663]\n",
      " [-2.01052846]\n",
      " [-2.75155745]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.24899116]\n",
      " [1.51860427]\n",
      " [4.0422247 ]\n",
      " [7.57106842]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.9226110678476793 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.08021534]\n",
      " [ 2.83480251]\n",
      " [ 2.1286388 ]\n",
      " [ 1.76571983]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  262\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.61476641]\n",
      " [11.63671729]\n",
      " [16.30594565]\n",
      " [15.76343201]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.48523359]\n",
      " [ 1.23671729]\n",
      " [-1.99405435]\n",
      " [-2.73656799]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.20591882]\n",
      " [1.52946966]\n",
      " [3.97625275]\n",
      " [7.48880437]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.900055700460752 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.09266319]\n",
      " [ 2.84019462]\n",
      " [ 2.13484235]\n",
      " [ 1.76631048]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  263\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.6290544 ]\n",
      " [11.64102397]\n",
      " [16.32227419]\n",
      " [15.77830019]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.4709456 ]\n",
      " [ 1.24102397]\n",
      " [-1.97772581]\n",
      " [-2.72169981]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.16368097]\n",
      " [1.54014049]\n",
      " [3.91139937]\n",
      " [7.40764987]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.8778588379077006 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.10498655]\n",
      " [ 2.84557222]\n",
      " [ 2.1410232 ]\n",
      " [ 1.76688859]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  264\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.64320174]\n",
      " [11.64523775]\n",
      " [16.33845848]\n",
      " [15.79304825]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.45679826]\n",
      " [ 1.24523775]\n",
      " [-1.96154152]\n",
      " [-2.70695175]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.12226118]\n",
      " [1.55061707]\n",
      " [3.84764515]\n",
      " [7.32758778]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.8560138968284503 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.11718669]\n",
      " [ 2.85093537]\n",
      " [ 2.14718142]\n",
      " [ 1.76745431]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  265\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.65720986]\n",
      " [11.64935973]\n",
      " [16.35449981]\n",
      " [15.80767735]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.44279014]\n",
      " [ 1.24935973]\n",
      " [-1.94550019]\n",
      " [-2.69232265]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.08164338]\n",
      " [1.56089974]\n",
      " [3.78497099]\n",
      " [7.24860126]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.8345144211671647 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.12926482]\n",
      " [ 2.85628413]\n",
      " [ 2.15331711]\n",
      " [ 1.76800773]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  266\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.67108019]\n",
      " [11.65339098]\n",
      " [16.37039949]\n",
      " [15.82218863]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.42891981]\n",
      " [ 1.25339098]\n",
      " [-1.92960051]\n",
      " [-2.67781137]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.04181182]\n",
      " [1.57098894]\n",
      " [3.72335813]\n",
      " [7.17067374]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.8133540796665253 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.14122217]\n",
      " [ 2.86161855]\n",
      " [ 2.15943034]\n",
      " [ 1.76854898]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  267\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.68481413]\n",
      " [11.65733255]\n",
      " [16.38615879]\n",
      " [15.83658322]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.41518587]\n",
      " [ 1.25733255]\n",
      " [-1.91384121]\n",
      " [-2.66341678]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.00275104]\n",
      " [1.58088515]\n",
      " [3.66278817]\n",
      " [7.09378895]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.792526663411731 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.15305995]\n",
      " [ 2.86693869]\n",
      " [ 2.16552119]\n",
      " [ 1.76907818]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  268\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.69841307]\n",
      " [11.6611855 ]\n",
      " [16.40177899]\n",
      " [15.85086224]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.40158693]\n",
      " [ 1.2611855 ]\n",
      " [-1.89822101]\n",
      " [-2.64913776]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.96444591]\n",
      " [1.59058888]\n",
      " [3.603243  ]\n",
      " [7.01793088]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.772026083423146 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.16477935]\n",
      " [ 2.87224461]\n",
      " [ 2.17158973]\n",
      " [ 1.76959544]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  269\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.71187839]\n",
      " [11.66495088]\n",
      " [16.41726134]\n",
      " [15.8650268 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.38812161]\n",
      " [ 1.26495088]\n",
      " [-1.88273866]\n",
      " [-2.6349732 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.92688161]\n",
      " [1.60010072]\n",
      " [3.54470485]\n",
      " [6.94308377]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.7518463682966994 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.17638156]\n",
      " [ 2.87753636]\n",
      " [ 2.17763606]\n",
      " [ 1.77010088]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  270\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.72521144]\n",
      " [11.6686297 ]\n",
      " [16.4326071 ]\n",
      " [15.87907799]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.37478856]\n",
      " [ 1.2686297 ]\n",
      " [-1.8673929 ]\n",
      " [-2.62092201]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.89004359]\n",
      " [1.60942131]\n",
      " [3.48715624]\n",
      " [6.86923216]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.7319816618910346 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.18786774]\n",
      " [ 2.88281399]\n",
      " [ 2.18366025]\n",
      " [ 1.77059461]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  271\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.73841357]\n",
      " [11.67222299]\n",
      " [16.4478175 ]\n",
      " [15.89301691]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.36158643]\n",
      " [ 1.27222299]\n",
      " [-1.8521825 ]\n",
      " [-2.60698309]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.85391761]\n",
      " [1.61855134]\n",
      " [3.43058001]\n",
      " [6.79636081]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.7124262210604817 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.19923907]\n",
      " [ 2.88807757]\n",
      " [ 2.18966238]\n",
      " [ 1.77107675]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  272\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.75148611]\n",
      " [11.67573176]\n",
      " [16.46289376]\n",
      " [15.90684463]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.34851389]\n",
      " [ 1.27573176]\n",
      " [-1.83710624]\n",
      " [-2.59315537]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.81848972]\n",
      " [1.62749152]\n",
      " [3.37495932]\n",
      " [6.72445476]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.6931744134329947 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.21049668]\n",
      " [ 2.89332714]\n",
      " [ 2.19564253]\n",
      " [ 1.77154739]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  273\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.76443038]\n",
      " [11.679157  ]\n",
      " [16.47783711]\n",
      " [15.92056222]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.33556962]\n",
      " [ 1.279157  ]\n",
      " [-1.82216289]\n",
      " [-2.57943778]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.78374622]\n",
      " [1.63624263]\n",
      " [3.32027759]\n",
      " [6.65349928]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.6742207152320674 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.22164171]\n",
      " [ 2.89856275]\n",
      " [ 2.20160078]\n",
      " [ 1.77200666]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  274\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.77724767]\n",
      " [11.6824997 ]\n",
      " [16.49264874]\n",
      " [15.93417072]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.32275233]\n",
      " [ 1.2824997 ]\n",
      " [-1.80735126]\n",
      " [-2.56582928]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.74967372]\n",
      " [1.64480548]\n",
      " [3.26651856]\n",
      " [6.58347991]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.6555597091418361 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.23267529]\n",
      " [ 2.90378446]\n",
      " [ 2.20753722]\n",
      " [ 1.77245467]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  275\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.78993929]\n",
      " [11.68576084]\n",
      " [16.50732986]\n",
      " [15.94767118]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.31006071]\n",
      " [ 1.28576084]\n",
      " [-1.79267014]\n",
      " [-2.55232882]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.71625907]\n",
      " [1.65318094]\n",
      " [3.21366624]\n",
      " [6.5143824 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.6371860822144555 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.24359854]\n",
      " [ 2.90899232]\n",
      " [ 2.21345191]\n",
      " [ 1.77289151]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  276\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.80250649]\n",
      " [11.68894139]\n",
      " [16.52188163]\n",
      " [15.96106464]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.29749351]\n",
      " [ 1.28894139]\n",
      " [-1.77811837]\n",
      " [-2.53893536]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.6834894 ]\n",
      " [1.6613699 ]\n",
      " [3.16170493]\n",
      " [6.44619277]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.6190946238189499 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.25441255]\n",
      " [ 2.91418638]\n",
      " [ 2.21934494]\n",
      " [ 1.7733173 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  277\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.81495055]\n",
      " [11.6920423 ]\n",
      " [16.53630524]\n",
      " [15.97435212]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.28504945]\n",
      " [ 1.2920423 ]\n",
      " [-1.76369476]\n",
      " [-2.52564788]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.65135208]\n",
      " [1.66937329]\n",
      " [3.11061919]\n",
      " [6.37889723]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.6012802236306622 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.26511843]\n",
      " [ 2.91936669]\n",
      " [ 2.2252164 ]\n",
      " [ 1.77373214]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  278\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.82727272]\n",
      " [11.69506451]\n",
      " [16.55060185]\n",
      " [15.98753463]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.27272728]\n",
      " [ 1.29506451]\n",
      " [-1.74939815]\n",
      " [-2.51246537]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.61983474]\n",
      " [1.67719209]\n",
      " [3.06039388]\n",
      " [6.31248225]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.583737869660553 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.27571724]\n",
      " [ 2.9245333 ]\n",
      " [ 2.23106636]\n",
      " [ 1.77413614]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  279\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.83947422]\n",
      " [11.69800898]\n",
      " [16.56477261]\n",
      " [16.00061317]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.26052578]\n",
      " [ 1.29800898]\n",
      " [-1.73522739]\n",
      " [-2.49938683]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.58892525]\n",
      " [1.6848273 ]\n",
      " [3.0110141 ]\n",
      " [6.24693452]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.5664626463234876 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.28621007]\n",
      " [ 2.92968627]\n",
      " [ 2.2368949 ]\n",
      " [ 1.7745294 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  280\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.85155627]\n",
      " [11.70087661]\n",
      " [16.57881866]\n",
      " [16.01358874]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.24844373]\n",
      " [ 1.30087661]\n",
      " [-1.72118134]\n",
      " [-2.48641126]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.55861174]\n",
      " [1.69227996]\n",
      " [2.96246522]\n",
      " [6.18224094]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.5494497325448116 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.29659797]\n",
      " [ 2.93482563]\n",
      " [ 2.2427021 ]\n",
      " [ 1.77491203]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  281\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.86352009]\n",
      " [11.70366834]\n",
      " [16.59274112]\n",
      " [16.02646233]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.23647991]\n",
      " [ 1.30366834]\n",
      " [-1.70725888]\n",
      " [-2.47353767]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.52888256]\n",
      " [1.69955114]\n",
      " [2.91473288]\n",
      " [6.11838863]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.5326943999043983 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.30688199]\n",
      " [ 2.93995143]\n",
      " [ 2.24848804]\n",
      " [ 1.77528412]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  282\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.87536688]\n",
      " [11.70638506]\n",
      " [16.60654113]\n",
      " [16.03923489]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.22463312]\n",
      " [ 1.30638506]\n",
      " [-1.69345887]\n",
      " [-2.46076511]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.49972629]\n",
      " [1.70664193]\n",
      " [2.86780295]\n",
      " [6.05536492]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.5161920108174314 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.31706317]\n",
      " [ 2.94506373]\n",
      " [ 2.2542528 ]\n",
      " [ 1.77564577]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  283\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.8870978 ]\n",
      " [11.70902768]\n",
      " [16.62021979]\n",
      " [16.0519074 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.2129022 ]\n",
      " [ 1.30902768]\n",
      " [-1.67978021]\n",
      " [-2.4480926 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.47113174]\n",
      " [1.71355348]\n",
      " [2.82166155]\n",
      " [5.99315736]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.4999380167512102 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.32714254]\n",
      " [ 2.95016258]\n",
      " [ 2.25999646]\n",
      " [ 1.7759971 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  284\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.89871405]\n",
      " [11.71159709]\n",
      " [16.6337782 ]\n",
      " [16.06448082]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.20128595]\n",
      " [ 1.31159709]\n",
      " [-1.6662218 ]\n",
      " [-2.43551918]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.44308795]\n",
      " [1.72028693]\n",
      " [2.77629508]\n",
      " [5.9317537 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.4839279564772672 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.33712111]\n",
      " [ 2.95524801]\n",
      " [ 2.2657191 ]\n",
      " [ 1.77633818]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  285\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.91021676]\n",
      " [11.71409416]\n",
      " [16.64721746]\n",
      " [16.07695607]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.18978324]\n",
      " [ 1.31409416]\n",
      " [-1.65278254]\n",
      " [-2.42304393]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.41558416]\n",
      " [1.72684347]\n",
      " [2.73169013]\n",
      " [5.87114187]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.4681574543580407 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.3469999 ]\n",
      " [ 2.96032008]\n",
      " [ 2.27142079]\n",
      " [ 1.77666913]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  286\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.92160709]\n",
      " [11.71651977]\n",
      " [16.66053864]\n",
      " [16.08933411]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.17839291]\n",
      " [ 1.31651977]\n",
      " [-1.63946136]\n",
      " [-2.41066589]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.38860985]\n",
      " [1.73322431]\n",
      " [2.68783355]\n",
      " [5.81131004]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.4526222186674835 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.3567799 ]\n",
      " [ 2.96537883]\n",
      " [ 2.27710163]\n",
      " [ 1.77699004]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  287\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.93288617]\n",
      " [11.71887478]\n",
      " [16.67374282]\n",
      " [16.10161585]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.16711383]\n",
      " [ 1.31887478]\n",
      " [-1.62625718]\n",
      " [-2.39838415]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.36215469]\n",
      " [1.73943067]\n",
      " [2.64471242]\n",
      " [5.75224653]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.4373180399449106 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.3664621 ]\n",
      " [ 2.9704243 ]\n",
      " [ 2.28276168]\n",
      " [ 1.777301  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  288\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.94405512]\n",
      " [11.72116003]\n",
      " [16.68683105]\n",
      " [16.11380221]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.15594488]\n",
      " [ 1.32116003]\n",
      " [-1.61316895]\n",
      " [-2.38619779]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.33620856]\n",
      " [1.74546382]\n",
      " [2.60231405]\n",
      " [5.69393988]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.422240789381395 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.37604748]\n",
      " [ 2.97545655]\n",
      " [ 2.28840103]\n",
      " [ 1.77760211]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  289\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.95511506]\n",
      " [11.72337637]\n",
      " [16.6998044 ]\n",
      " [16.1258941 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.14488494]\n",
      " [ 1.32337637]\n",
      " [-1.6001956 ]\n",
      " [-2.3741059 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.31076153]\n",
      " [1.75132503]\n",
      " [2.56062596]\n",
      " [5.63637882]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.4073864172381128 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.38553701]\n",
      " [ 2.98047561]\n",
      " [ 2.29401975]\n",
      " [ 1.77789347]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  290\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.96606707]\n",
      " [11.72552465]\n",
      " [16.7126639 ]\n",
      " [16.13789242]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.13393293]\n",
      " [ 1.32552465]\n",
      " [-1.5873361 ]\n",
      " [-2.36210758]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.28580388]\n",
      " [1.75701559]\n",
      " [2.5196359 ]\n",
      " [5.57955223]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.3927509512959406 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.39493164]\n",
      " [ 2.98548153]\n",
      " [ 2.29961793]\n",
      " [ 1.77817516]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  291\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.97691225]\n",
      " [11.72760567]\n",
      " [16.72541058]\n",
      " [16.14979805]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.12308775]\n",
      " [ 1.32760567]\n",
      " [-1.57458942]\n",
      " [-2.35020195]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.26132609]\n",
      " [1.76253682]\n",
      " [2.47933184]\n",
      " [5.52344922]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.378330495335773 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.40423232]\n",
      " [ 2.99047436]\n",
      " [ 2.30519564]\n",
      " [ 1.77844729]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  292\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.98765167]\n",
      " [11.72962027]\n",
      " [16.73804547]\n",
      " [16.16161187]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.11234833]\n",
      " [ 1.32962027]\n",
      " [-1.56195453]\n",
      " [-2.33838813]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.2373188 ]\n",
      " [1.76789005]\n",
      " [2.43970194]\n",
      " [5.46805903]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.3641212276488512 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.41344   ]\n",
      " [ 2.99545413]\n",
      " [ 2.31075296]\n",
      " [ 1.77870993]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  293\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[20.9982864 ]\n",
      " [11.73156924]\n",
      " [16.75056959]\n",
      " [16.17333477]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.1017136 ]\n",
      " [ 1.33156924]\n",
      " [-1.54943041]\n",
      " [-2.32666523]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.21377286]\n",
      " [1.77307664]\n",
      " [2.40073459]\n",
      " [5.41337111]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.3501193995766063 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.4225556 ]\n",
      " [ 3.0004209 ]\n",
      " [ 2.31628997]\n",
      " [ 1.77896319]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  294\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.00881748]\n",
      " [11.73345339]\n",
      " [16.76298394]\n",
      " [16.18496759]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.09118252]\n",
      " [ 1.33345339]\n",
      " [-1.53701606]\n",
      " [-2.31503241]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.19067929]\n",
      " [1.77809794]\n",
      " [2.36241837]\n",
      " [5.35937508]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.3363213340793108 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.43158004]\n",
      " [ 3.00537469]\n",
      " [ 2.32180675]\n",
      " [ 1.77920714]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  295\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.01924596]\n",
      " [11.73527351]\n",
      " [16.77528951]\n",
      " [16.19651119]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.08075404]\n",
      " [ 1.33527351]\n",
      " [-1.52471049]\n",
      " [-2.30348881]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.16802929]\n",
      " [1.78295534]\n",
      " [2.32474207]\n",
      " [5.3060607 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.3227234243330936 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.44051424]\n",
      " [ 3.01031556]\n",
      " [ 2.32730337]\n",
      " [ 1.77944189]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  296\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.02957287]\n",
      " [11.73703038]\n",
      " [16.7874873 ]\n",
      " [16.20796642]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.07042713]\n",
      " [ 1.33703038]\n",
      " [-1.5125127 ]\n",
      " [-2.29203358]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.14581424]\n",
      " [1.78765023]\n",
      " [2.28769467]\n",
      " [5.25341792]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.309322132354659 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.4493591 ]\n",
      " [ 3.01524355]\n",
      " [ 2.33277992]\n",
      " [ 1.77966752]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  297\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.03979923]\n",
      " [11.73872477]\n",
      " [16.79957828]\n",
      " [16.21933412]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.06020077]\n",
      " [ 1.33872477]\n",
      " [-1.50042172]\n",
      " [-2.28066588]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.12402568]\n",
      " [1.79218402]\n",
      " [2.25126534]\n",
      " [5.20143686]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.2961139876532144 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.45811551]\n",
      " [ 3.0201587 ]\n",
      " [ 2.33823646]\n",
      " [ 1.77988411]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  298\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.04992604]\n",
      " [11.74035747]\n",
      " [16.81156342]\n",
      " [16.23061511]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.05007396]\n",
      " [ 1.34035747]\n",
      " [-1.48843658]\n",
      " [-2.26938489]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.10265532]\n",
      " [1.79655813]\n",
      " [2.21544346]\n",
      " [5.15010778]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.283095585909039 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.46678435]\n",
      " [ 3.02506104]\n",
      " [ 2.34367309]\n",
      " [ 1.78009175]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  299\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.05995431]\n",
      " [11.74192921]\n",
      " [16.82344368]\n",
      " [16.24181022]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.04004569]\n",
      " [ 1.34192921]\n",
      " [-1.47655632]\n",
      " [-2.25818978]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.08169504]\n",
      " [1.800774  ]\n",
      " [2.18021856]\n",
      " [5.0994211 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.270263587678171 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.47536651]\n",
      " [ 3.02995063]\n",
      " [ 2.34908987]\n",
      " [ 1.78029053]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  300\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.06988502]\n",
      " [11.74344075]\n",
      " [16.83522002]\n",
      " [16.25292025]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.03011498]\n",
      " [ 1.34344075]\n",
      " [-1.46477998]\n",
      " [-2.24707975]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.06113687]\n",
      " [1.80483306]\n",
      " [2.14558039]\n",
      " [5.04936741]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.2576147171227015 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.48386285]\n",
      " [ 3.03482749]\n",
      " [ 2.35448688]\n",
      " [ 1.78048053]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  301\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.07971915]\n",
      " [11.74489285]\n",
      " [16.84689338]\n",
      " [16.26394601]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.02028085]\n",
      " [ 1.34489285]\n",
      " [-1.45310662]\n",
      " [-2.23605399]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.04097302]\n",
      " [1.80873677]\n",
      " [2.11151886]\n",
      " [4.99993744]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.2451457607661607 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.49227422]\n",
      " [ 3.03969167]\n",
      " [ 2.35986421]\n",
      " [ 1.78066184]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  302\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.08945767]\n",
      " [11.74628622]\n",
      " [16.85846469]\n",
      " [16.2748883 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.01054233]\n",
      " [ 1.34628622]\n",
      " [-1.44153531]\n",
      " [-2.2251117 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.02119581]\n",
      " [1.81248658]\n",
      " [2.07802406]\n",
      " [4.95112208]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.232853566273493 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.50060147]\n",
      " [ 3.04454322]\n",
      " [ 2.36522192]\n",
      " [ 1.78083454]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  303\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.09910153]\n",
      " [11.74762159]\n",
      " [16.86993487]\n",
      " [16.2857479 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.00089847]\n",
      " [ 1.34762159]\n",
      " [-1.43006513]\n",
      " [-2.2142521 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.00179775]\n",
      " [1.81608396]\n",
      " [2.04508627]\n",
      " [4.90291235]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.220735041255147 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.50884546]\n",
      " [ 3.04938216]\n",
      " [ 2.3705601 ]\n",
      " [ 1.78099871]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  304\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.10865168]\n",
      " [11.7488997 ]\n",
      " [16.88130486]\n",
      " [16.2965256 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.99134832]\n",
      " [ 1.3488997 ]\n",
      " [-1.41869514]\n",
      " [-2.2034744 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.98277149]\n",
      " [1.8195304 ]\n",
      " [2.0126959 ]\n",
      " [4.85529943]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.2087871520947822 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.51700701]\n",
      " [ 3.05420854]\n",
      " [ 2.37587882]\n",
      " [ 1.78115444]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  305\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.11810906]\n",
      " [11.75012124]\n",
      " [16.89257555]\n",
      " [16.30722217]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.98189094]\n",
      " [ 1.35012124]\n",
      " [-1.40742445]\n",
      " [-2.19277783]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.96410981]\n",
      " [1.82282736]\n",
      " [1.98084357]\n",
      " [4.80827463]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.1970069228001585 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.52508694]\n",
      " [ 3.05902239]\n",
      " [ 2.38117815]\n",
      " [ 1.7813018 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  306\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.1274746 ]\n",
      " [11.75128692]\n",
      " [16.90374786]\n",
      " [16.31783836]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.9725254 ]\n",
      " [ 1.35128692]\n",
      " [-1.39625214]\n",
      " [-2.18216164]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.94580566]\n",
      " [1.82597635]\n",
      " [1.94952005]\n",
      " [4.76182941]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.1853914338766895 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.53308607]\n",
      " [ 3.06382377]\n",
      " [ 2.38645818]\n",
      " [ 1.78144087]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  307\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.13674921]\n",
      " [11.75239745]\n",
      " [16.91482266]\n",
      " [16.32837495]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.96325079]\n",
      " [ 1.35239745]\n",
      " [-1.38517734]\n",
      " [-2.17162505]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.92785208]\n",
      " [1.82897885]\n",
      " [1.91871627]\n",
      " [4.71595537]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.1739378212232565 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.54100521]\n",
      " [ 3.06861269]\n",
      " [ 2.39171897]\n",
      " [ 1.78157174]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.1459338 ]\n",
      " [11.7534535 ]\n",
      " [16.92580085]\n",
      " [16.33883267]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.9540662 ]\n",
      " [ 1.3534535 ]\n",
      " [-1.37419915]\n",
      " [-2.16116733]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.91024231]\n",
      " [1.83183637]\n",
      " [1.8884233 ]\n",
      " [4.67064422]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.1626432750498763 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.54884515]\n",
      " [ 3.0733892 ]\n",
      " [ 2.39696061]\n",
      " [ 1.78169449]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  309\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.15502928]\n",
      " [11.75445576]\n",
      " [16.9366833 ]\n",
      " [16.34921227]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.94497072]\n",
      " [ 1.35445576]\n",
      " [-1.3633167 ]\n",
      " [-2.15078773]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.89296967]\n",
      " [1.83455039]\n",
      " [1.85863241]\n",
      " [4.62588784]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.151505038816649 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.5566067 ]\n",
      " [ 3.07815335]\n",
      " [ 2.40218318]\n",
      " [ 1.78180918]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  310\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.16403652]\n",
      " [11.7554049 ]\n",
      " [16.94747089]\n",
      " [16.35951449]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.93596348]\n",
      " [ 1.3554049 ]\n",
      " [-1.35252911]\n",
      " [-2.14048551]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.87602763]\n",
      " [1.83712244]\n",
      " [1.82933499]\n",
      " [4.58167821]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.1405204081937508 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.56429063]\n",
      " [ 3.08290515]\n",
      " [ 2.40738673]\n",
      " [ 1.78191591]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  311\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.17295642]\n",
      " [11.75630159]\n",
      " [16.95816448]\n",
      " [16.36974005]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.92704358]\n",
      " [ 1.35630159]\n",
      " [-1.34183552]\n",
      " [-2.13025995]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.85940981]\n",
      " [1.83955401]\n",
      " [1.80052258]\n",
      " [4.53800744]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.129686730041902 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.57189773]\n",
      " [ 3.08764466]\n",
      " [ 2.41257136]\n",
      " [ 1.78201474]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  312\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.18178983]\n",
      " [11.7571465 ]\n",
      " [16.96876491]\n",
      " [16.37988967]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.91821017]\n",
      " [ 1.3571465 ]\n",
      " [-1.33123509]\n",
      " [-2.12011033]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.84310991]\n",
      " [1.84184663]\n",
      " [1.77218688]\n",
      " [4.49486779]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.1190014014129832 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.57942875]\n",
      " [ 3.09237191]\n",
      " [ 2.41773713]\n",
      " [ 1.78210576]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  313\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.19053763]\n",
      " [11.75794027]\n",
      " [16.97927303]\n",
      " [16.38996407]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.90946237]\n",
      " [ 1.35794027]\n",
      " [-1.32072697]\n",
      " [-2.11003593]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.8271218 ]\n",
      " [1.84400179]\n",
      " [1.74431973]\n",
      " [4.45225163]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.1084618685703758 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.58688446]\n",
      " [ 3.09708693]\n",
      " [ 2.42288412]\n",
      " [ 1.78218903]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  314\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.19920067]\n",
      " [11.75868356]\n",
      " [16.98968968]\n",
      " [16.39996395]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.90079933]\n",
      " [ 1.35868356]\n",
      " [-1.31031032]\n",
      " [-2.10003605]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.81143944]\n",
      " [1.84602101]\n",
      " [1.71691313]\n",
      " [4.41015143]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.098065626028641 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.59426562]\n",
      " [ 3.10178976]\n",
      " [ 2.42801241]\n",
      " [ 1.78226463]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  315\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.20777978]\n",
      " [11.75937699]\n",
      " [17.0000157 ]\n",
      " [16.40989   ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.89222022]\n",
      " [ 1.35937699]\n",
      " [-1.2999843 ]\n",
      " [-2.09011   ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.79605691]\n",
      " [1.84790581]\n",
      " [1.68995919]\n",
      " [4.36855981]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.087810215612154 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.60157296]\n",
      " [ 3.10648044]\n",
      " [ 2.43312207]\n",
      " [ 1.78233264]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  316\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.21627582]\n",
      " [11.76002121]\n",
      " [17.0102519 ]\n",
      " [16.41974292]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.88372418]\n",
      " [ 1.36002121]\n",
      " [-1.2897481 ]\n",
      " [-2.08025708]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.78096843]\n",
      " [1.8496577 ]\n",
      " [1.66345017]\n",
      " [4.3274695 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.0776932255322935 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.60880723]\n",
      " [ 3.11115901]\n",
      " [ 2.43821317]\n",
      " [ 1.78239313]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  317\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.22468959]\n",
      " [11.76061684]\n",
      " [17.0203991 ]\n",
      " [16.4295234 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.87531041]\n",
      " [ 1.36061684]\n",
      " [-1.2796009 ]\n",
      " [-2.0704766 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.76616831]\n",
      " [1.85127819]\n",
      " [1.63737847]\n",
      " [4.28687334]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.0677122894828812 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.61596916]\n",
      " [ 3.11582549]\n",
      " [ 2.44328579]\n",
      " [ 1.78244617]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  318\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.23302193]\n",
      " [11.7611645 ]\n",
      " [17.0304581 ]\n",
      " [16.43923211]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.86697807]\n",
      " [ 1.3611645 ]\n",
      " [-1.2695419 ]\n",
      " [-2.06076789]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.75165098]\n",
      " [1.85276879]\n",
      " [1.61173663]\n",
      " [4.24676428]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.0578650857534284 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.62305947]\n",
      " [ 3.12047992]\n",
      " [ 2.44833999]\n",
      " [ 1.78249184]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  319\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.24127364]\n",
      " [11.7616648 ]\n",
      " [17.04042971]\n",
      " [16.44886973]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.85872636]\n",
      " [ 1.3616648 ]\n",
      " [-1.25957029]\n",
      " [-2.05113027]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.73741097]\n",
      " [1.85413102]\n",
      " [1.58651731]\n",
      " [4.20713539]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.0481493363598955 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.63007887]\n",
      " [ 3.12512234]\n",
      " [ 2.45337587]\n",
      " [ 1.7825302 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  320\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.24944552]\n",
      " [11.76211835]\n",
      " [17.05031472]\n",
      " [16.45843691]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.85055448]\n",
      " [ 1.36211835]\n",
      " [-1.24968528]\n",
      " [-2.04156309]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.72344293]\n",
      " [1.85536639]\n",
      " [1.56171329]\n",
      " [4.16797984]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.038562806192592 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.63702809]\n",
      " [ 3.12975278]\n",
      " [ 2.45839347]\n",
      " [ 1.78256133]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  321\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.25753836]\n",
      " [11.76252574]\n",
      " [17.06011392]\n",
      " [16.46793432]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.84246164]\n",
      " [ 1.36252574]\n",
      " [-1.23988608]\n",
      " [-2.03206568]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.70974161]\n",
      " [1.85647639]\n",
      " [1.53731749]\n",
      " [4.12929093]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.029103302180892 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.6439078 ]\n",
      " [ 3.13437128]\n",
      " [ 2.46339289]\n",
      " [ 1.78258529]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  322\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.26555296]\n",
      " [11.76288757]\n",
      " [17.06982808]\n",
      " [16.4773626 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.83444704]\n",
      " [ 1.36288757]\n",
      " [-1.23017192]\n",
      " [-2.0226374 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.69630187]\n",
      " [1.85746254]\n",
      " [1.51332294]\n",
      " [4.09106203]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.0197686724744144 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.65071873]\n",
      " [ 3.13897787]\n",
      " [ 2.4683742 ]\n",
      " [ 1.78260217]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  323\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.27349008]\n",
      " [11.76320443]\n",
      " [17.07945798]\n",
      " [16.48672241]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.82650992]\n",
      " [ 1.36320443]\n",
      " [-1.22054202]\n",
      " [-2.01327759]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.68311865]\n",
      " [1.85832633]\n",
      " [1.48972282]\n",
      " [4.05328665]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.0105568056403444 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.65746154]\n",
      " [ 3.14357258]\n",
      " [ 2.47333745]\n",
      " [ 1.78261201]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  324\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.2813505 ]\n",
      " [11.7634769 ]\n",
      " [17.08900438]\n",
      " [16.49601438]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.8186495 ]\n",
      " [ 1.3634769 ]\n",
      " [-1.21099562]\n",
      " [-2.00398562]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.670187  ]\n",
      " [1.85906926]\n",
      " [1.46651039]\n",
      " [4.01595838]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  1.0014656298766016 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.66413692]\n",
      " [ 3.14815545]\n",
      " [ 2.47828274]\n",
      " [ 1.7826149 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  325\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.28913498]\n",
      " [11.76370555]\n",
      " [17.09846803]\n",
      " [16.50523913]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.81086502]\n",
      " [ 1.36370555]\n",
      " [-1.20153197]\n",
      " [-1.99476087]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.65750208]\n",
      " [1.85969283]\n",
      " [1.44367906]\n",
      " [3.97907092]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.992493112240491 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.67074555]\n",
      " [ 3.15272651]\n",
      " [ 2.48321012]\n",
      " [ 1.7826109 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  326\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.29684427]\n",
      " [11.76389095]\n",
      " [17.1078497 ]\n",
      " [16.5143973 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.80315573]\n",
      " [ 1.36389095]\n",
      " [-1.1921503 ]\n",
      " [-1.9856027 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.64505913]\n",
      " [1.86019852]\n",
      " [1.42122234]\n",
      " [3.94261806]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9836372578925938 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.6772881 ]\n",
      " [ 3.1572858 ]\n",
      " [ 2.48811968]\n",
      " [ 1.78260008]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  327\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.30447911]\n",
      " [11.76403366]\n",
      " [17.11715011]\n",
      " [16.52348951]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.79552089]\n",
      " [ 1.36403366]\n",
      " [-1.18284989]\n",
      " [-1.97651049]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.63285349]\n",
      " [1.86058783]\n",
      " [1.39913386]\n",
      " [3.9065937 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9748961093555351 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.68376522]\n",
      " [ 3.16183334]\n",
      " [ 2.49301148]\n",
      " [ 1.78258251]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  328\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.31204025]\n",
      " [11.76413424]\n",
      " [17.12637002]\n",
      " [16.53251637]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.78795975]\n",
      " [ 1.36413424]\n",
      " [-1.17362998]\n",
      " [-1.96748363]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.62088057]\n",
      " [1.86086222]\n",
      " [1.37740734]\n",
      " [3.87099183]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9662677457873701 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.69017757]\n",
      " [ 3.16636917]\n",
      " [ 2.49788559]\n",
      " [ 1.78255824]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  329\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.31952841]\n",
      " [11.76419324]\n",
      " [17.13551014]\n",
      " [16.54147848]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.78047159]\n",
      " [ 1.36419324]\n",
      " [-1.16448986]\n",
      " [-1.95852152]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.60913591]\n",
      " [1.86102318]\n",
      " [1.35603664]\n",
      " [3.83580653]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9577502822692967 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.69652579]\n",
      " [ 3.17089333]\n",
      " [ 2.50274209]\n",
      " [ 1.78252735]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  330\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.32694431]\n",
      " [11.76421119]\n",
      " [17.1445712 ]\n",
      " [16.55037645]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.77305569]\n",
      " [ 1.36421119]\n",
      " [-1.1554288 ]\n",
      " [-1.94962355]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.5976151 ]\n",
      " [1.86107218]\n",
      " [1.33501571]\n",
      " [3.80103197]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9493418691073896 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.70281053]\n",
      " [ 3.17540584]\n",
      " [ 2.50758104]\n",
      " [ 1.78248991]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  331\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.33428868]\n",
      " [11.76418865]\n",
      " [17.15355392]\n",
      " [16.55921088]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.76571132]\n",
      " [ 1.36418865]\n",
      " [-1.14644608]\n",
      " [-1.94078912]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.58631382]\n",
      " [1.86101067]\n",
      " [1.31433861]\n",
      " [3.76666243]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9410406911480982 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.70903243]\n",
      " [ 3.17990674]\n",
      " [ 2.51240253]\n",
      " [ 1.78244597]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  332\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.34156222]\n",
      " [11.76412614]\n",
      " [17.16245901]\n",
      " [16.56798234]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.75843778]\n",
      " [ 1.36412614]\n",
      " [-1.13754099]\n",
      " [-1.93201766]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.57522787]\n",
      " [1.86084012]\n",
      " [1.29399949]\n",
      " [3.73269225]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9328449671072337 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.7151921 ]\n",
      " [ 3.18439606]\n",
      " [ 2.51720661]\n",
      " [ 1.78239559]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  333\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.34876563]\n",
      " [11.76402419]\n",
      " [17.17128718]\n",
      " [16.57669142]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.75123437]\n",
      " [ 1.36402419]\n",
      " [-1.12871282]\n",
      " [-1.92330858]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.56435308]\n",
      " [1.86056198]\n",
      " [1.27399264]\n",
      " [3.69911589]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9247529489121618 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.72129018]\n",
      " [ 3.18887382]\n",
      " [ 2.52199335]\n",
      " [ 1.78233885]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  334\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.3558996 ]\n",
      " [11.76388331]\n",
      " [17.18003911]\n",
      " [16.58533871]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.7441004 ]\n",
      " [ 1.36388331]\n",
      " [-1.11996089]\n",
      " [-1.91466129]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.55368541]\n",
      " [1.86017769]\n",
      " [1.25431239]\n",
      " [3.66592787]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9167629210569692 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.72732728]\n",
      " [ 3.19334007]\n",
      " [ 2.52676284]\n",
      " [ 1.78227581]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  335\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.36296482]\n",
      " [11.76370404]\n",
      " [17.1887155 ]\n",
      " [16.59392476]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.73703518]\n",
      " [ 1.36370404]\n",
      " [-1.1112845 ]\n",
      " [-1.90607524]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.54322086]\n",
      " [1.8596887 ]\n",
      " [1.23495323]\n",
      " [3.63312281]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9088731999703079 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.73330401]\n",
      " [ 3.19779484]\n",
      " [ 2.53151513]\n",
      " [ 1.78220652]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  336\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.36996197]\n",
      " [11.76348686]\n",
      " [17.19731704]\n",
      " [16.60245016]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.73003803]\n",
      " [ 1.36348686]\n",
      " [-1.10268296]\n",
      " [-1.89754984]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.53295553]\n",
      " [1.85909642]\n",
      " [1.21590971]\n",
      " [3.60069541]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.9010821333957026 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.73922097]\n",
      " [ 3.20223815]\n",
      " [ 2.53625029]\n",
      " [ 1.78213105]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  337\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.37689172]\n",
      " [11.7632323 ]\n",
      " [17.2058444 ]\n",
      " [16.61091545]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.72310828]\n",
      " [ 1.3632323 ]\n",
      " [-1.0941556 ]\n",
      " [-1.88908455]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.52288559]\n",
      " [1.8584023 ]\n",
      " [1.19717647]\n",
      " [3.56864044]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8933880997840555 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.74507876]\n",
      " [ 3.20667004]\n",
      " [ 2.5409684 ]\n",
      " [ 1.78204946]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  338\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.38375474]\n",
      " [11.76294084]\n",
      " [17.21429826]\n",
      " [16.61932119]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.71624526]\n",
      " [ 1.36294084]\n",
      " [-1.08570174]\n",
      " [-1.88067881]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.51300728]\n",
      " [1.85760774]\n",
      " [1.17874827]\n",
      " [3.53695278]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8857895076981053 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.75087797]\n",
      " [ 3.21109053]\n",
      " [ 2.54566953]\n",
      " [ 1.78196181]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  339\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.39055168]\n",
      " [11.76261299]\n",
      " [17.22267927]\n",
      " [16.62766794]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.70944832]\n",
      " [ 1.36261299]\n",
      " [-1.07732073]\n",
      " [-1.87233206]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.50331692]\n",
      " [1.85671415]\n",
      " [1.16061995]\n",
      " [3.50562735]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8782847952286132 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.75661919]\n",
      " [ 3.21549966]\n",
      " [ 2.55035374]\n",
      " [ 1.78186816]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  340\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.3972832 ]\n",
      " [11.76224922]\n",
      " [17.23098811]\n",
      " [16.63595623]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.7027168 ]\n",
      " [ 1.36224922]\n",
      " [-1.06901189]\n",
      " [-1.86404377]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.4938109 ]\n",
      " [1.85572293]\n",
      " [1.14278642]\n",
      " [3.47465919]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8708724294220385 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.762303  ]\n",
      " [ 3.21989746]\n",
      " [ 2.5550211 ]\n",
      " [ 1.78176857]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  341\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.40394995]\n",
      " [11.76185002]\n",
      " [17.23922542]\n",
      " [16.6441866 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.69605005]\n",
      " [ 1.36185002]\n",
      " [-1.06077458]\n",
      " [-1.8558134 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.48448567]\n",
      " [1.85463549]\n",
      " [1.1252427 ]\n",
      " [3.44404338]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8635509057194835 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.76792997]\n",
      " [ 3.22428396]\n",
      " [ 2.55967167]\n",
      " [ 1.7816631 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  342\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.41055255]\n",
      " [11.76141588]\n",
      " [17.24739186]\n",
      " [16.65235959]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.68944745]\n",
      " [ 1.36141588]\n",
      " [-1.05260814]\n",
      " [-1.84764041]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.47533778]\n",
      " [1.85345319]\n",
      " [1.10798391]\n",
      " [3.4137751 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8563187474066569 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.77350067]\n",
      " [ 3.22865919]\n",
      " [ 2.56430554]\n",
      " [ 1.7815518 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  343\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.41709165]\n",
      " [11.76094725]\n",
      " [17.25548805]\n",
      " [16.66047572]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.68290835]\n",
      " [ 1.36094725]\n",
      " [-1.04451195]\n",
      " [-1.83952428]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.46636381]\n",
      " [1.85217743]\n",
      " [1.09100521]\n",
      " [3.38384959]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8491745050746897 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.77901566]\n",
      " [ 3.23302318]\n",
      " [ 2.56892276]\n",
      " [ 1.78143474]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  344\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.42356788]\n",
      " [11.76044462]\n",
      " [17.26351465]\n",
      " [16.66853551]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.67643212]\n",
      " [ 1.36044462]\n",
      " [-1.03648535]\n",
      " [-1.83146449]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.45756042]\n",
      " [1.85080956]\n",
      " [1.07430189]\n",
      " [3.35426218]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8421167560915293 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.78447551]\n",
      " [ 3.23737595]\n",
      " [ 2.5735234 ]\n",
      " [ 1.78131197]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  345\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.42998183]\n",
      " [11.75990843]\n",
      " [17.27147227]\n",
      " [16.67653948]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.67001817]\n",
      " [ 1.35990843]\n",
      " [-1.02852773]\n",
      " [-1.82346052]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.44892434]\n",
      " [1.84935095]\n",
      " [1.05786929]\n",
      " [3.32500825]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.83514410408375 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.78988075]\n",
      " [ 3.24171755]\n",
      " [ 2.57810753]\n",
      " [ 1.78118355]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  346\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.43633415]\n",
      " [11.75933916]\n",
      " [17.27936155]\n",
      " [16.68448815]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.66366585]\n",
      " [ 1.35933916]\n",
      " [-1.02063845]\n",
      " [-1.81551185]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.44045237]\n",
      " [1.84780294]\n",
      " [1.04170285]\n",
      " [3.29608327]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8282551784285404 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.79523194]\n",
      " [ 3.24604799]\n",
      " [ 2.58267522]\n",
      " [ 1.78104954]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  347\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.44262542]\n",
      " [11.75873724]\n",
      " [17.2871831 ]\n",
      " [16.69238202]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.65737458]\n",
      " [ 1.35873724]\n",
      " [-1.0128169 ]\n",
      " [-1.80761798]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.43214134]\n",
      " [1.84616688]\n",
      " [1.02579808]\n",
      " [3.26748276]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8214486337556977 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.80052962]\n",
      " [ 3.25036732]\n",
      " [ 2.58722653]\n",
      " [ 1.78090999]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  348\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.44885625]\n",
      " [11.75810313]\n",
      " [17.29493753]\n",
      " [16.70022159]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.65114375]\n",
      " [ 1.35810313]\n",
      " [-1.00506247]\n",
      " [-1.79977841]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.42398819]\n",
      " [1.84444411]\n",
      " [1.01015057]\n",
      " [3.23920233]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8147231494593963 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.80577433]\n",
      " [ 3.25467554]\n",
      " [ 2.59176153]\n",
      " [ 1.78076496]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  349\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.45502723]\n",
      " [11.75743727]\n",
      " [17.30262545]\n",
      " [16.70800736]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.64497277]\n",
      " [ 1.35743727]\n",
      " [-0.99737455]\n",
      " [-1.79199264]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.41598987]\n",
      " [1.84263594]\n",
      " [0.99475599]\n",
      " [3.21123764]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8080774292195636 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.81096658]\n",
      " [ 3.25897271]\n",
      " [ 2.59628029]\n",
      " [ 1.7806145 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  350\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.46113896]\n",
      " [11.75674009]\n",
      " [17.31024747]\n",
      " [16.71573981]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.63886104]\n",
      " [ 1.35674009]\n",
      " [-0.98975253]\n",
      " [-1.78426019]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.40814343]\n",
      " [1.84074368]\n",
      " [0.97961007]\n",
      " [3.18358442]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.8015102005326646 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.81610692]\n",
      " [ 3.26325884]\n",
      " [ 2.60078286]\n",
      " [ 1.78045866]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  351\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.46719202]\n",
      " [11.75601204]\n",
      " [17.31780417]\n",
      " [16.72341944]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.63280798]\n",
      " [ 1.35601204]\n",
      " [-0.98219583]\n",
      " [-1.77658056]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.40044594]\n",
      " [1.83876865]\n",
      " [0.96470864]\n",
      " [3.15623848]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7950202142517003 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.82119585]\n",
      " [ 3.26753396]\n",
      " [ 2.60526933]\n",
      " [ 1.78029751]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  352\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.47318697]\n",
      " [11.75525353]\n",
      " [17.32529616]\n",
      " [16.73104673]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.62681303]\n",
      " [ 1.35525353]\n",
      " [-0.97470384]\n",
      " [-1.76895327]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.39289457]\n",
      " [1.83671214]\n",
      " [0.95004758]\n",
      " [3.12919567]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7886062441352604 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.82623389]\n",
      " [ 3.27179811]\n",
      " [ 2.60973974]\n",
      " [ 1.78013109]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  353\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.4791244 ]\n",
      " [11.754465  ]\n",
      " [17.33272401]\n",
      " [16.73862216]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.6208756 ]\n",
      " [ 1.354465  ]\n",
      " [-0.96727599]\n",
      " [-1.76137784]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.38548651]\n",
      " [1.83457543]\n",
      " [0.93562285]\n",
      " [3.10245191]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7822670864054158 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.83122155]\n",
      " [ 3.27605131]\n",
      " [ 2.61419417]\n",
      " [ 1.77995946]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  354\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.48500487]\n",
      " [11.75364685]\n",
      " [17.3400883 ]\n",
      " [16.74614619]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.61499513]\n",
      " [ 1.35364685]\n",
      " [-0.9599117 ]\n",
      " [-1.75385381]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.37821901]\n",
      " [1.83235979]\n",
      " [0.92143047]\n",
      " [3.0760032 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7760015593143271 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.83615934]\n",
      " [ 3.28029359]\n",
      " [ 2.61863269]\n",
      " [ 1.77978268]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  355\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.49082893]\n",
      " [11.75279951]\n",
      " [17.34738961]\n",
      " [16.75361929]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.60917107]\n",
      " [ 1.35279951]\n",
      " [-0.95261039]\n",
      " [-1.74638071]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.37108939]\n",
      " [1.8300665 ]\n",
      " [0.90746655]\n",
      " [3.04984558]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7698085027193226 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.84104774]\n",
      " [ 3.28452498]\n",
      " [ 2.62305535]\n",
      " [ 1.77960078]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  356\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.49659715]\n",
      " [11.75192338]\n",
      " [17.35462851]\n",
      " [16.76104193]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.60340285]\n",
      " [ 1.35192338]\n",
      " [-0.94537149]\n",
      " [-1.73895807]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.364095  ]\n",
      " [1.82769681]\n",
      " [0.89372726]\n",
      " [3.02397515]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7636867776663654 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.84588727]\n",
      " [ 3.2887455 ]\n",
      " [ 2.62746222]\n",
      " [ 1.77941383]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  357\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.50231007]\n",
      " [11.75101886]\n",
      " [17.36180556]\n",
      " [16.76841457]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.59768993]\n",
      " [ 1.35101886]\n",
      " [-0.93819444]\n",
      " [-1.73158543]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.35723326]\n",
      " [1.82525197]\n",
      " [0.88020881]\n",
      " [2.99838809]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7576352659816795 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.85067839]\n",
      " [ 3.29295519]\n",
      " [ 2.63185337]\n",
      " [ 1.77922188]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  358\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.50796822]\n",
      " [11.75008637]\n",
      " [17.36892132]\n",
      " [16.77573766]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.59203178]\n",
      " [ 1.35008637]\n",
      " [-0.93107868]\n",
      " [-1.72426234]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.35050162]\n",
      " [1.8227332 ]\n",
      " [0.86690751]\n",
      " [2.97308062]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7516528698713861 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.85542161]\n",
      " [ 3.29715407]\n",
      " [ 2.63622885]\n",
      " [ 1.77902497]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  359\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.51357216]\n",
      " [11.74912629]\n",
      " [17.37597634]\n",
      " [16.78301165]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.58642784]\n",
      " [ 1.34912629]\n",
      " [-0.92402366]\n",
      " [-1.71698835]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.34389761]\n",
      " [1.82014175]\n",
      " [0.85381973]\n",
      " [2.94804901]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7457385115290247 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.86011739]\n",
      " [ 3.30134217]\n",
      " [ 2.64058874]\n",
      " [ 1.77882317]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  360\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.51912241]\n",
      " [11.74813902]\n",
      " [17.38297117]\n",
      " [16.79023698]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.58087759]\n",
      " [ 1.34813902]\n",
      " [-0.91702883]\n",
      " [-1.70976302]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.33741878]\n",
      " [1.81747881]\n",
      " [0.84094187]\n",
      " [2.9232896 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7398911327507509 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.86476622]\n",
      " [ 3.30551952]\n",
      " [ 2.64493309]\n",
      " [ 1.77861651]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  361\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.52461949]\n",
      " [11.74712494]\n",
      " [17.38990636]\n",
      " [16.79741409]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.57538051]\n",
      " [ 1.34712494]\n",
      " [-0.91009364]\n",
      " [-1.70258591]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.33106273]\n",
      " [1.8147456 ]\n",
      " [0.82827044]\n",
      " [2.89879879]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7341096945581054 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.86936856]\n",
      " [ 3.30968615]\n",
      " [ 2.64926198]\n",
      " [ 1.77840505]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  362\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.53006393]\n",
      " [11.74608444]\n",
      " [17.39678244]\n",
      " [16.80454342]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.56993607]\n",
      " [ 1.34608444]\n",
      " [-0.90321756]\n",
      " [-1.69545658]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.32482712]\n",
      " [1.81194331]\n",
      " [0.81580196]\n",
      " [2.87457302]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7283931768281852 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.87392487]\n",
      " [ 3.31384208]\n",
      " [ 2.65357545]\n",
      " [ 1.77818884]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  363\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.53545624]\n",
      " [11.74501789]\n",
      " [17.40359995]\n",
      " [16.8116254 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.56454376]\n",
      " [ 1.34501789]\n",
      " [-0.89640005]\n",
      " [-1.6883746 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.31870965]\n",
      " [1.80907313]\n",
      " [0.80353306]\n",
      " [2.85060878]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7227405779310516 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.87843562]\n",
      " [ 3.31798734]\n",
      " [ 2.65787358]\n",
      " [ 1.77796793]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  364\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.54079694]\n",
      " [11.74392568]\n",
      " [17.41035941]\n",
      " [16.81866046]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.55920306]\n",
      " [ 1.34392568]\n",
      " [-0.88964059]\n",
      " [-1.68133954]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.31270806]\n",
      " [1.80613623]\n",
      " [0.79146038]\n",
      " [2.82690264]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7171509143742769 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.88290127]\n",
      " [ 3.32212195]\n",
      " [ 2.66215642]\n",
      " [ 1.77774236]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  365\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.54608653]\n",
      " [11.74280817]\n",
      " [17.41706135]\n",
      " [16.82564902]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.55391347]\n",
      " [ 1.34280817]\n",
      " [-0.88293865]\n",
      " [-1.67435098]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.30682014]\n",
      " [1.80313377]\n",
      " [0.77958066]\n",
      " [2.80345119]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7116232204544366 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.88732225]\n",
      " [ 3.32624595]\n",
      " [ 2.66642405]\n",
      " [ 1.77751219]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  366\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.5513255 ]\n",
      " [11.74166572]\n",
      " [17.42370628]\n",
      " [16.83259151]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.5486745 ]\n",
      " [ 1.34166572]\n",
      " [-0.87629372]\n",
      " [-1.66740849]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.30104371]\n",
      " [1.80006691]\n",
      " [0.76789068]\n",
      " [2.78025109]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7061565479154785 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.89169903]\n",
      " [ 3.33035937]\n",
      " [ 2.67067651]\n",
      " [ 1.77727745]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  367\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.55651436]\n",
      " [11.74049871]\n",
      " [17.43029473]\n",
      " [16.83948832]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.54348564]\n",
      " [ 1.34049871]\n",
      " [-0.86970527]\n",
      " [-1.66051168]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.29537664]\n",
      " [1.79693679]\n",
      " [0.75638725]\n",
      " [2.75729903]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.7007499656137268 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.89603204]\n",
      " [ 3.33446222]\n",
      " [ 2.67491388]\n",
      " [ 1.77703821]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  368\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.56165359]\n",
      " [11.73930749]\n",
      " [17.4368272 ]\n",
      " [16.84633988]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.53834641]\n",
      " [ 1.33930749]\n",
      " [-0.8631728 ]\n",
      " [-1.65366012]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.28981686]\n",
      " [1.79374455]\n",
      " [0.74506728]\n",
      " [2.73459179]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.695402559189522 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.90032172]\n",
      " [ 3.33855454]\n",
      " [ 2.67913621]\n",
      " [ 1.7767945 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  369\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.56674368]\n",
      " [11.73809241]\n",
      " [17.44330419]\n",
      " [16.85314659]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.53325632]\n",
      " [ 1.33809241]\n",
      " [-0.85669581]\n",
      " [-1.64685341]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.2843623 ]\n",
      " [1.7904913 ]\n",
      " [0.73392771]\n",
      " [2.71212614]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6901134307452406 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.9045685 ]\n",
      " [ 3.34263634]\n",
      " [ 2.68334356]\n",
      " [ 1.77654638]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  370\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.57178512]\n",
      " [11.73685383]\n",
      " [17.44972621]\n",
      " [16.85990886]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.52821488]\n",
      " [ 1.33685383]\n",
      " [-0.85027379]\n",
      " [-1.64009114]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.27901096]\n",
      " [1.78717815]\n",
      " [0.72296552]\n",
      " [2.68989895]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.684881698529671 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.90877282]\n",
      " [ 3.34670767]\n",
      " [ 2.687536  ]\n",
      " [ 1.77629388]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  371\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.57677836]\n",
      " [11.73559209]\n",
      " [17.45609374]\n",
      " [16.86662708]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.52322164]\n",
      " [ 1.33559209]\n",
      " [-0.84390626]\n",
      " [-1.63337292]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.27376088]\n",
      " [1.78380622]\n",
      " [0.71217777]\n",
      " [2.66790711]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6797064966285357 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.91293509]\n",
      " [ 3.35076855]\n",
      " [ 2.69171358]\n",
      " [ 1.77603705]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  372\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.5817239 ]\n",
      " [11.73430753]\n",
      " [17.46240729]\n",
      " [16.87330164]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.5182761 ]\n",
      " [ 1.33430753]\n",
      " [-0.83759271]\n",
      " [-1.62669836]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.26861012]\n",
      " [1.78037658]\n",
      " [0.70156155]\n",
      " [2.64614756]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6745869746611095 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.91705574]\n",
      " [ 3.35481899]\n",
      " [ 2.69587637]\n",
      " [ 1.77577595]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  373\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.58662219]\n",
      " [11.73300049]\n",
      " [17.46866734]\n",
      " [16.87993294]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.51337781]\n",
      " [ 1.33300049]\n",
      " [-0.83133266]\n",
      " [-1.62006706]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.26355678]\n",
      " [1.77689032]\n",
      " [0.691114  ]\n",
      " [2.62461728]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6695222974827519 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.92113518]\n",
      " [ 3.35885903]\n",
      " [ 2.70002443]\n",
      " [ 1.77551061]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  374\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.59147368]\n",
      " [11.73167132]\n",
      " [17.47487436]\n",
      " [16.88652136]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.50852632]\n",
      " [ 1.33167132]\n",
      " [-0.82512564]\n",
      " [-1.61347864]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.25859901]\n",
      " [1.77334851]\n",
      " [0.68083233]\n",
      " [2.60331331]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6645116448932883 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.92517383]\n",
      " [ 3.3628887 ]\n",
      " [ 2.70415781]\n",
      " [ 1.77524109]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  375\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.59627885]\n",
      " [11.73032034]\n",
      " [17.48102883]\n",
      " [16.89306729]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.50372115]\n",
      " [ 1.33032034]\n",
      " [-0.81897117]\n",
      " [-1.60693271]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.25373499]\n",
      " [1.7697522 ]\n",
      " [0.67071377]\n",
      " [2.58223273]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6595542113510923 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.92917209]\n",
      " [ 3.36690802]\n",
      " [ 2.70827658]\n",
      " [ 1.77496741]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  376\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.60103815]\n",
      " [11.72894787]\n",
      " [17.48713124]\n",
      " [16.89957111]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.49896185]\n",
      " [ 1.32894787]\n",
      " [-0.81286876]\n",
      " [-1.60042889]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.24896293]\n",
      " [1.76610245]\n",
      " [0.66075562]\n",
      " [2.56137264]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6546492056927719 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.93313037]\n",
      " [ 3.37091701]\n",
      " [ 2.71238079]\n",
      " [ 1.77468963]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  377\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.60575201]\n",
      " [11.72755425]\n",
      " [17.49318204]\n",
      " [16.90603318]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.49424799]\n",
      " [ 1.32755425]\n",
      " [-0.80681796]\n",
      " [-1.59396682]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.24428108]\n",
      " [1.76240029]\n",
      " [0.65095522]\n",
      " [2.54073022]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6497958508583208 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.93704907]\n",
      " [ 3.37491571]\n",
      " [ 2.71647051]\n",
      " [ 1.7744078 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  378\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.61042088]\n",
      " [11.72613979]\n",
      " [17.4991817 ]\n",
      " [16.91245389]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.48957912]\n",
      " [ 1.32613979]\n",
      " [-0.8008183 ]\n",
      " [-1.58754611]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.23968771]\n",
      " [1.75864675]\n",
      " [0.64130994]\n",
      " [2.52030267]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6449933836216875 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.94092858]\n",
      " [ 3.37890413]\n",
      " [ 2.72054579]\n",
      " [ 1.77412195]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  379\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.61504521]\n",
      " [11.72470481]\n",
      " [17.50513069]\n",
      " [16.91883359]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.48495479]\n",
      " [ 1.32470481]\n",
      " [-0.79486931]\n",
      " [-1.58116641]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.23518115]\n",
      " [1.75484285]\n",
      " [0.63181722]\n",
      " [2.50008722]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.640241054326582 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.94476929]\n",
      " [ 3.3828823 ]\n",
      " [ 2.72460668]\n",
      " [ 1.77383213]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  380\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.61962542]\n",
      " [11.72324963]\n",
      " [17.51102945]\n",
      " [16.92517266]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.48037458]\n",
      " [ 1.32324963]\n",
      " [-0.78897055]\n",
      " [-1.57482734]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.23075973]\n",
      " [1.75098959]\n",
      " [0.62247453]\n",
      " [2.48008116]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6355381266274707 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.9485716 ]\n",
      " [ 3.38685026]\n",
      " [ 2.72865326]\n",
      " [ 1.77353837]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  381\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.62416195]\n",
      " [11.72177455]\n",
      " [17.51687844]\n",
      " [16.93147145]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.47583805]\n",
      " [ 1.32177455]\n",
      " [-0.78312156]\n",
      " [-1.56852855]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.22642185]\n",
      " [1.74708797]\n",
      " [0.61327938]\n",
      " [2.46028182]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.630883877235636 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.95233588]\n",
      " [ 3.39080802]\n",
      " [ 2.73268558]\n",
      " [ 1.77324074]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  382\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.62865522]\n",
      " [11.72027988]\n",
      " [17.5226781 ]\n",
      " [16.93773032]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.47134478]\n",
      " [ 1.32027988]\n",
      " [-0.7773219 ]\n",
      " [-1.56226968]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.2221659 ]\n",
      " [1.74313897]\n",
      " [0.60422934]\n",
      " [2.44068656]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6262775956701918 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.95606252]\n",
      " [ 3.39475561]\n",
      " [ 2.73670369]\n",
      " [ 1.77293925]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  383\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.63310565]\n",
      " [11.71876593]\n",
      " [17.52842888]\n",
      " [16.94394962]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.46689435]\n",
      " [ 1.31876593]\n",
      " [-0.77157112]\n",
      " [-1.55605038]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.21799033]\n",
      " [1.73914358]\n",
      " [0.59532199]\n",
      " [2.42129277]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6217185840139781 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.9597519 ]\n",
      " [ 3.39869305]\n",
      " [ 2.74070766]\n",
      " [ 1.77263396]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  384\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.63751367]\n",
      " [11.71723299]\n",
      " [17.53413122]\n",
      " [16.95012971]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.46248633]\n",
      " [ 1.31723299]\n",
      " [-0.76586878]\n",
      " [-1.54987029]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.21389361]\n",
      " [1.73510275]\n",
      " [0.58655499]\n",
      " [2.40209791]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6172061566742338 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.96340438]\n",
      " [ 3.40262038]\n",
      " [ 2.74469753]\n",
      " [ 1.77232491]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  385\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.64187967]\n",
      " [11.71568136]\n",
      " [17.53978555]\n",
      " [16.95627093]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.45812033]\n",
      " [ 1.31568136]\n",
      " [-0.76021445]\n",
      " [-1.54372907]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.20987424]\n",
      " [1.73101744]\n",
      " [0.57792601]\n",
      " [2.38309944]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.6127396401479228 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.96702033]\n",
      " [ 3.40653761]\n",
      " [ 2.74867337]\n",
      " [ 1.77201213]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  386\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.64620408]\n",
      " [11.71411133]\n",
      " [17.54539231]\n",
      " [16.96237362]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.45379592]\n",
      " [ 1.31411133]\n",
      " [-0.75460769]\n",
      " [-1.53762638]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.20593074]\n",
      " [1.72688859]\n",
      " [0.56943277]\n",
      " [2.36429488]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.608318372791681 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.97060013]\n",
      " [ 3.41044477]\n",
      " [ 2.75263524]\n",
      " [ 1.77169568]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  387\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.65048729]\n",
      " [11.7125232 ]\n",
      " [17.55095191]\n",
      " [16.96843813]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.44951271]\n",
      " [ 1.3125232 ]\n",
      " [-0.74904809]\n",
      " [-1.53156187]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.20206168]\n",
      " [1.72271715]\n",
      " [0.56107304]\n",
      " [2.34568177]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.603941704596231 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.97414413]\n",
      " [ 3.41434188]\n",
      " [ 2.75658319]\n",
      " [ 1.77137558]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  388\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.65472971]\n",
      " [11.71091724]\n",
      " [17.55646479]\n",
      " [16.97446478]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.44527029]\n",
      " [ 1.31091724]\n",
      " [-0.74353521]\n",
      " [-1.52553522]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.19826563]\n",
      " [1.71850402]\n",
      " [0.55284461]\n",
      " [2.32725771]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5996089969652115 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.97765269]\n",
      " [ 3.41822898]\n",
      " [ 2.76051727]\n",
      " [ 1.77105188]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  389\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.65893173]\n",
      " [11.70929375]\n",
      " [17.56193136]\n",
      " [16.98045391]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.44106827]\n",
      " [ 1.30929375]\n",
      " [-0.73806864]\n",
      " [-1.51954609]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.19454122]\n",
      " [1.71425013]\n",
      " [0.54474532]\n",
      " [2.30902031]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5953196224983346 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.98112616]\n",
      " [ 3.42210608]\n",
      " [ 2.76443755]\n",
      " [ 1.77072462]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  390\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.66309375]\n",
      " [11.707653  ]\n",
      " [17.56735204]\n",
      " [16.98640586]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.43690625]\n",
      " [ 1.307653  ]\n",
      " [-0.73264796]\n",
      " [-1.51359414]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.19088707]\n",
      " [1.70995638]\n",
      " [0.53677304]\n",
      " [2.29096723]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5910729647787689 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.9845649 ]\n",
      " [ 3.42597322]\n",
      " [ 2.76834407]\n",
      " [ 1.77039384]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  391\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.66721616]\n",
      " [11.70599527]\n",
      " [17.57272723]\n",
      " [16.99232094]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.43278384]\n",
      " [ 1.30599527]\n",
      " [-0.72727277]\n",
      " [-1.50767906]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.18730185]\n",
      " [1.70562365]\n",
      " [0.52892568]\n",
      " [2.27309616]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5868684181646812 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.98796925]\n",
      " [ 3.4298304 ]\n",
      " [ 2.7722369 ]\n",
      " [ 1.77005957]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  392\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.67129933]\n",
      " [11.70432084]\n",
      " [17.57805736]\n",
      " [16.99819948]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.42870067]\n",
      " [ 1.30432084]\n",
      " [-0.72194264]\n",
      " [-1.50180052]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.18378426]\n",
      " [1.70125285]\n",
      " [0.52120118]\n",
      " [2.25540481]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5827053875848326 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.99133956]\n",
      " [ 3.43367767]\n",
      " [ 2.77611609]\n",
      " [ 1.76972186]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  393\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.67534366]\n",
      " [11.70262997]\n",
      " [17.58334281]\n",
      " [17.0040418 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.42465634]\n",
      " [ 1.30262997]\n",
      " [-0.71665719]\n",
      " [-1.4959582 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.18033301]\n",
      " [1.69684483]\n",
      " [0.51359753]\n",
      " [2.23789094]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5785832883381853 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.99467616]\n",
      " [ 3.43751504]\n",
      " [ 2.7799817 ]\n",
      " [ 1.76938073]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  394\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.67934951]\n",
      " [11.70092293]\n",
      " [17.588584  ]\n",
      " [17.00984821]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.42065049]\n",
      " [ 1.30092293]\n",
      " [-0.711416  ]\n",
      " [-1.49015179]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.17694683]\n",
      " [1.69240046]\n",
      " [0.50611273]\n",
      " [2.22055234]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5745015458974034 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[16.9979794 ]\n",
      " [ 3.44134254]\n",
      " [ 2.78383377]\n",
      " [ 1.76903624]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  395\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.68331727]\n",
      " [11.69919998]\n",
      " [17.59378131]\n",
      " [17.01561904]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.41668273]\n",
      " [ 1.29919998]\n",
      " [-0.70621869]\n",
      " [-1.48438096]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.1736245 ]\n",
      " [1.6879206 ]\n",
      " [0.49874484]\n",
      " [2.20338683]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5704595957161958 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.00124961]\n",
      " [ 3.44516019]\n",
      " [ 2.78767237]\n",
      " [ 1.76868842]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  396\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.6872473 ]\n",
      " [11.6974614 ]\n",
      " [17.59893514]\n",
      " [17.02135459]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.4127527 ]\n",
      " [ 1.2974614 ]\n",
      " [-0.70106486]\n",
      " [-1.47864541]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.17036479]\n",
      " [1.68340608]\n",
      " [0.49149193]\n",
      " [2.18639226]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5664568830404051 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.00448711]\n",
      " [ 3.44896801]\n",
      " [ 2.79149755]\n",
      " [ 1.76833731]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  397\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.69113996]\n",
      " [11.69570743]\n",
      " [17.60404589]\n",
      " [17.02705516]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.40886004]\n",
      " [ 1.29570743]\n",
      " [-0.69595411]\n",
      " [-1.47294484]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.16716653]\n",
      " [1.67885775]\n",
      " [0.48435213]\n",
      " [2.1695665 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5624928627227969 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.00769224]\n",
      " [ 3.45276604]\n",
      " [ 2.79530936]\n",
      " [ 1.76798293]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  398\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.69499563]\n",
      " [11.69393834]\n",
      " [17.60911393]\n",
      " [17.03272107]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.40500437]\n",
      " [ 1.29393834]\n",
      " [-0.69088607]\n",
      " [-1.46727893]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.16402854]\n",
      " [1.67427642]\n",
      " [0.47732357]\n",
      " [2.15290747]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5585669990414472 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.01086532]\n",
      " [ 3.4565543 ]\n",
      " [ 2.79910786]\n",
      " [ 1.76762534]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  399\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.69881466]\n",
      " [11.69215437]\n",
      " [17.61413964]\n",
      " [17.03835261]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.40118534]\n",
      " [ 1.29215437]\n",
      " [-0.68586036]\n",
      " [-1.46164739]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.16094968]\n",
      " [1.66966291]\n",
      " [0.47040443]\n",
      " [2.13641311]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5546787655216723 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.01400666]\n",
      " [ 3.4603328 ]\n",
      " [ 2.80289311]\n",
      " [ 1.76726456]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  400\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.7025974 ]\n",
      " [11.69035577]\n",
      " [17.61912341]\n",
      " [17.04395008]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.3974026 ]\n",
      " [ 1.29035577]\n",
      " [-0.68087659]\n",
      " [-1.45604992]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.15792883]\n",
      " [1.66501802]\n",
      " [0.46359293]\n",
      " [2.12008138]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5508276447614391 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.0171166 ]\n",
      " [ 3.46410157]\n",
      " [ 2.80666514]\n",
      " [ 1.76690064]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  401\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.70634421]\n",
      " [11.6885428 ]\n",
      " [17.62406561]\n",
      " [17.04951377]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.39365579]\n",
      " [ 1.2885428 ]\n",
      " [-0.67593439]\n",
      " [-1.45048623]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.15496488]\n",
      " [1.66034255]\n",
      " [0.45688729]\n",
      " [2.1039103 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5470131282601549 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.02019543]\n",
      " [ 3.46786065]\n",
      " [ 2.81042402]\n",
      " [ 1.7665336 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  402\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.71005543]\n",
      " [11.6867157 ]\n",
      " [17.62896662]\n",
      " [17.05504399]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.38994457]\n",
      " [ 1.2867157 ]\n",
      " [-0.67103338]\n",
      " [-1.44495601]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.15205677]\n",
      " [1.65563728]\n",
      " [0.4502858 ]\n",
      " [2.08789788]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5432347162508124 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.02324348]\n",
      " [ 3.47161004]\n",
      " [ 2.81416981]\n",
      " [ 1.76616349]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  403\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.71373141]\n",
      " [11.6848747 ]\n",
      " [17.63382679]\n",
      " [17.06054101]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.38626859]\n",
      " [ 1.2848747 ]\n",
      " [-0.66617321]\n",
      " [-1.43945899]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.14920342]\n",
      " [1.65090299]\n",
      " [0.44378674]\n",
      " [2.07204218]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5394919175354003 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.02626104]\n",
      " [ 3.47534978]\n",
      " [ 2.81790255]\n",
      " [ 1.76579033]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  404\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.71737249]\n",
      " [11.68302005]\n",
      " [17.6386465 ]\n",
      " [17.06600513]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.38262751]\n",
      " [ 1.28302005]\n",
      " [-0.6613535 ]\n",
      " [-1.43399487]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.14640381]\n",
      " [1.64614044]\n",
      " [0.43738845]\n",
      " [2.05634129]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5357842493235083 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.02924843]\n",
      " [ 3.47907988]\n",
      " [ 2.82162229]\n",
      " [ 1.76541417]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  405\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.72097901]\n",
      " [11.68115198]\n",
      " [17.64342611]\n",
      " [17.07143663]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.37902099]\n",
      " [ 1.28115198]\n",
      " [-0.65657389]\n",
      " [-1.42856337]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.14365691]\n",
      " [1.6413504 ]\n",
      " [0.43108927]\n",
      " [2.04079331]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5321112370740803 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.03220595]\n",
      " [ 3.48280038]\n",
      " [ 2.82532909]\n",
      " [ 1.76503504]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  406\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.72455131]\n",
      " [11.67927073]\n",
      " [17.64816597]\n",
      " [17.07683578]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.37544869]\n",
      " [ 1.27927073]\n",
      " [-0.65183403]\n",
      " [-1.42316422]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.14096172]\n",
      " [1.6365336 ]\n",
      " [0.4248876 ]\n",
      " [2.02539639]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.528472414340244 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.03513389]\n",
      " [ 3.48651129]\n",
      " [ 2.82902301]\n",
      " [ 1.76465297]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  407\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.72808971]\n",
      " [11.67737653]\n",
      " [17.65286644]\n",
      " [17.08220288]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.37191029]\n",
      " [ 1.27737653]\n",
      " [-0.64713356]\n",
      " [-1.41779712]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.13831727]\n",
      " [1.63169079]\n",
      " [0.41878184]\n",
      " [2.01014868]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5248673226171765 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.03803255]\n",
      " [ 3.49021264]\n",
      " [ 2.83270408]\n",
      " [ 1.76426799]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  408\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.73159454]\n",
      " [11.6754696 ]\n",
      " [17.65752787]\n",
      " [17.08753819]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.36840546]\n",
      " [ 1.2754696 ]\n",
      " [-0.64247213]\n",
      " [-1.41246181]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.13572258]\n",
      " [1.6268227 ]\n",
      " [0.41277043]\n",
      " [1.99504838]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5212955111928939 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.04090222]\n",
      " [ 3.49390446]\n",
      " [ 2.83637237]\n",
      " [ 1.76388015]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  409\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.73506613]\n",
      " [11.67355017]\n",
      " [17.66215062]\n",
      " [17.09284198]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.36493387]\n",
      " [ 1.27355017]\n",
      " [-0.63784938]\n",
      " [-1.40715802]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.13317673]\n",
      " [1.62193004]\n",
      " [0.40685184]\n",
      " [1.98009369]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5177565370019752 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.0437432 ]\n",
      " [ 3.49758676]\n",
      " [ 2.84002792]\n",
      " [ 1.76348947]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  410\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.7385048 ]\n",
      " [11.67161847]\n",
      " [17.66673501]\n",
      " [17.09811453]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.3614952 ]\n",
      " [ 1.27161847]\n",
      " [-0.63326499]\n",
      " [-1.40188547]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.13067878]\n",
      " [1.61701352]\n",
      " [0.40102455]\n",
      " [1.96528287]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5142499644821183 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.04655577]\n",
      " [ 3.50125956]\n",
      " [ 2.8436708 ]\n",
      " [ 1.76309599]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  411\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.74191086]\n",
      " [11.6696747 ]\n",
      " [17.6712814 ]\n",
      " [17.10335611]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.35808914]\n",
      " [ 1.2696747 ]\n",
      " [-0.6287186 ]\n",
      " [-1.39664389]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.12822783]\n",
      " [1.61207386]\n",
      " [0.39528707]\n",
      " [1.95061417]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5107753654334737 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.04934021]\n",
      " [ 3.5049229 ]\n",
      " [ 2.84730103]\n",
      " [ 1.76269974]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  412\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.74528464]\n",
      " [11.6677191 ]\n",
      " [17.67579013]\n",
      " [17.10856697]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.35471536]\n",
      " [ 1.2677191 ]\n",
      " [-0.62420987]\n",
      " [-1.39143303]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.12582298]\n",
      " [1.60711173]\n",
      " [0.38963796]\n",
      " [1.93608588]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5073323188807347 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.05209681]\n",
      " [ 3.5085768 ]\n",
      " [ 2.85091869]\n",
      " [ 1.76230075]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  413\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.74862645]\n",
      " [11.66575188]\n",
      " [17.68026153]\n",
      " [17.11374738]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.35137355]\n",
      " [ 1.26575188]\n",
      " [-0.61973847]\n",
      " [-1.38625262]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.12346337]\n",
      " [1.60212782]\n",
      " [0.38407577]\n",
      " [1.92169632]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5039204109378862 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.05482584]\n",
      " [ 3.51222127]\n",
      " [ 2.85452382]\n",
      " [ 1.76189906]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  414\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.75193659]\n",
      " [11.66377325]\n",
      " [17.68469593]\n",
      " [17.11889761]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.34806341]\n",
      " [ 1.26377325]\n",
      " [-0.61530407]\n",
      " [-1.38110239]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.12114814]\n",
      " [1.59712282]\n",
      " [0.3785991 ]\n",
      " [1.90744382]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.5005392346755838 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.05752758]\n",
      " [ 3.51585635]\n",
      " [ 2.85811646]\n",
      " [ 1.7614947 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  415\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.75521537]\n",
      " [11.66178341]\n",
      " [17.68909366]\n",
      " [17.1240179 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.34478463]\n",
      " [ 1.26178341]\n",
      " [-0.61090634]\n",
      " [-1.3759821 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.11887644]\n",
      " [1.59209737]\n",
      " [0.37320656]\n",
      " [1.89332675]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4971883899911155 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.06020231]\n",
      " [ 3.51948204]\n",
      " [ 2.86169668]\n",
      " [ 1.76108769]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  416\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.75846309]\n",
      " [11.65978258]\n",
      " [17.69345505]\n",
      " [17.12910851]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.34153691]\n",
      " [ 1.25978258]\n",
      " [-0.60654495]\n",
      " [-1.37089149]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.11664746]\n",
      " [1.58705215]\n",
      " [0.36789677]\n",
      " [1.87934348]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4938674834808885 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.06285028]\n",
      " [ 3.52309839]\n",
      " [ 2.86526451]\n",
      " [ 1.76067808]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  417\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.76168005]\n",
      " [11.65777097]\n",
      " [17.69778043]\n",
      " [17.1341697 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.33831995]\n",
      " [ 1.25777097]\n",
      " [-0.60221957]\n",
      " [-1.3658303 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.11446039]\n",
      " [1.5819878 ]\n",
      " [0.36266842]\n",
      " [1.86549242]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.490576128315373 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.06547178]\n",
      " [ 3.5267054 ]\n",
      " [ 2.86882001]\n",
      " [ 1.7602659 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  418\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.76486656]\n",
      " [11.65574877]\n",
      " [17.7020701 ]\n",
      " [17.1392017 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.33513344]\n",
      " [ 1.25574877]\n",
      " [-0.5979299 ]\n",
      " [-1.3607983 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.11231443]\n",
      " [1.57690496]\n",
      " [0.35752016]\n",
      " [1.851772  ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.48731394411649753 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.06806706]\n",
      " [ 3.53030311]\n",
      " [ 2.87236323]\n",
      " [ 1.75985116]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  419\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.76802289]\n",
      " [11.65371618]\n",
      " [17.7063244 ]\n",
      " [17.14420478]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.33197711]\n",
      " [ 1.25371618]\n",
      " [-0.5936756 ]\n",
      " [-1.35579522]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.1102088 ]\n",
      " [1.57180426]\n",
      " [0.35245072]\n",
      " [1.83818067]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4840805568374017 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.07063639]\n",
      " [ 3.53389153]\n",
      " [ 2.87589422]\n",
      " [ 1.75943391]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  420\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.77114936]\n",
      " [11.65167341]\n",
      " [17.71054363]\n",
      " [17.14917918]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.32885064]\n",
      " [ 1.25167341]\n",
      " [-0.58945637]\n",
      " [-1.35082082]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.10814275]\n",
      " [1.56668633]\n",
      " [0.34745881]\n",
      " [1.8247169 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.48087559864452945 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.07318003]\n",
      " [ 3.5374707 ]\n",
      " [ 2.87941302]\n",
      " [ 1.75901418]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  421\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.77424623]\n",
      " [11.64962065]\n",
      " [17.71472811]\n",
      " [17.15412513]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.32575377]\n",
      " [ 1.24962065]\n",
      " [-0.58527189]\n",
      " [-1.34587487]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.10611552]\n",
      " [1.56155178]\n",
      " [0.34254319]\n",
      " [1.81137917]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.47769870780200746 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.07569823]\n",
      " [ 3.54104062]\n",
      " [ 2.88291969]\n",
      " [ 1.758592  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  422\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.77731381]\n",
      " [11.6475581 ]\n",
      " [17.71887814]\n",
      " [17.15904287]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.32268619]\n",
      " [ 1.2475581 ]\n",
      " [-0.58112186]\n",
      " [-1.34095713]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.10412638]\n",
      " [1.55640121]\n",
      " [0.33770262]\n",
      " [1.79816602]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4745495285582599 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.07819125]\n",
      " [ 3.54460132]\n",
      " [ 2.88641428]\n",
      " [ 1.75816739]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  423\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.78035236]\n",
      " [11.64548594]\n",
      " [17.72299403]\n",
      " [17.16393265]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.31964764]\n",
      " [ 1.24548594]\n",
      " [-0.57700597]\n",
      " [-1.33606735]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.10217461]\n",
      " [1.55123523]\n",
      " [0.33293589]\n",
      " [1.78507595]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4714277110348274 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.08065933]\n",
      " [ 3.54815283]\n",
      " [ 2.88989682]\n",
      " [ 1.75774039]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  424\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.78336218]\n",
      " [11.64340437]\n",
      " [17.72707609]\n",
      " [17.1687947 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.31663782]\n",
      " [ 1.24340437]\n",
      " [-0.57292391]\n",
      " [-1.3312053 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.10025951]\n",
      " [1.54605443]\n",
      " [0.32824181]\n",
      " [1.77210754]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.46833291111733777 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.08310274]\n",
      " [ 3.55169517]\n",
      " [ 2.89336737]\n",
      " [ 1.75731102]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  425\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.78634353]\n",
      " [11.64131357]\n",
      " [17.73112461]\n",
      " [17.17362926]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.31365647]\n",
      " [ 1.24131357]\n",
      " [-0.56887539]\n",
      " [-1.32637074]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.09838038]\n",
      " [1.54085938]\n",
      " [0.32361921]\n",
      " [1.75925935]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4652647903485702 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.08552171]\n",
      " [ 3.55522836]\n",
      " [ 2.89682598]\n",
      " [ 1.75687933]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  426\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.7892967 ]\n",
      " [11.63921373]\n",
      " [17.73513989]\n",
      " [17.17843654]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.3107033 ]\n",
      " [ 1.23921373]\n",
      " [-0.56486011]\n",
      " [-1.32156346]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.09653654]\n",
      " [1.53565066]\n",
      " [0.31906694]\n",
      " [1.74652998]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.46222301582362446 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.0879165 ]\n",
      " [ 3.55875242]\n",
      " [ 2.9002727 ]\n",
      " [ 1.75644532]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  427\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.79222195]\n",
      " [11.63710502]\n",
      " [17.73912223]\n",
      " [17.18321678]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.30777805]\n",
      " [ 1.23710502]\n",
      " [-0.56087777]\n",
      " [-1.31678322]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.09472733]\n",
      " [1.53042884]\n",
      " [0.31458387]\n",
      " [1.73391804]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4592072600870814 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.09028733]\n",
      " [ 3.56226737]\n",
      " [ 2.90370757]\n",
      " [ 1.75600904]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  428\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.79511955]\n",
      " [11.63498764]\n",
      " [17.74307192]\n",
      " [17.18797021]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.30488045]\n",
      " [ 1.23498764]\n",
      " [-0.55692808]\n",
      " [-1.31202979]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.09295209]\n",
      " [1.52519447]\n",
      " [0.31016889]\n",
      " [1.72142216]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.456217201032177 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.09263446]\n",
      " [ 3.56577324]\n",
      " [ 2.90713064]\n",
      " [ 1.75557052]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  429\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.79798977]\n",
      " [11.63286176]\n",
      " [17.74698925]\n",
      " [17.19269706]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.30201023]\n",
      " [ 1.23286176]\n",
      " [-0.55301075]\n",
      " [-1.30730294]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.09121018]\n",
      " [1.51994812]\n",
      " [0.30582089]\n",
      " [1.70904099]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4532525218019191 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.09495811]\n",
      " [ 3.56927005]\n",
      " [ 2.91054195]\n",
      " [ 1.75512977]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  430\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.80083288]\n",
      " [11.63072755]\n",
      " [17.7508745 ]\n",
      " [17.19739753]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.29916712]\n",
      " [ 1.23072755]\n",
      " [-0.5491255 ]\n",
      " [-1.30260247]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.08950097]\n",
      " [1.5146903 ]\n",
      " [0.30153882]\n",
      " [1.6967732 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4503129106921152 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.09725853]\n",
      " [ 3.57275783]\n",
      " [ 2.91394157]\n",
      " [ 1.75468684]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  431\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.80364913]\n",
      " [11.62858519]\n",
      " [17.75472796]\n",
      " [17.20207185]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.29635087]\n",
      " [ 1.22858519]\n",
      " [-0.54527204]\n",
      " [-1.29792815]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.08782384]\n",
      " [1.50942158]\n",
      " [0.2973216 ]\n",
      " [1.68461747]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4473980610562704 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.09953595]\n",
      " [ 3.57623658]\n",
      " [ 2.91732952]\n",
      " [ 1.75424174]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  432\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.80643878]\n",
      " [11.62643486]\n",
      " [17.75854991]\n",
      " [17.20672025]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.29356122]\n",
      " [ 1.22643486]\n",
      " [-0.54145009]\n",
      " [-1.29327975]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.08617819]\n",
      " [1.50414246]\n",
      " [0.2931682 ]\n",
      " [1.67257252]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.44450767121232637 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.10179059]\n",
      " [ 3.57970634]\n",
      " [ 2.92070585]\n",
      " [ 1.75379451]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  433\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.80920208]\n",
      " [11.62427671]\n",
      " [17.76234063]\n",
      " [17.21134292]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.29079792]\n",
      " [ 1.22427671]\n",
      " [-0.53765937]\n",
      " [-1.28865708]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.08456343]\n",
      " [1.49885347]\n",
      " [0.2890776 ]\n",
      " [1.66063706]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4416414443512148 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.10402268]\n",
      " [ 3.58316713]\n",
      " [ 2.92407062]\n",
      " [ 1.75334518]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  434\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.8119393 ]\n",
      " [11.62211093]\n",
      " [17.7661004 ]\n",
      " [17.2159401 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.2880607 ]\n",
      " [ 1.22211093]\n",
      " [-0.5338996 ]\n",
      " [-1.2840599 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.08297896]\n",
      " [1.49355512]\n",
      " [0.28504879]\n",
      " [1.64880983]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.43879908844714677 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.10623245]\n",
      " [ 3.58661896]\n",
      " [ 2.92742387]\n",
      " [ 1.75289376]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  435\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.81465069]\n",
      " [11.61993767]\n",
      " [17.76982948]\n",
      " [17.22051198]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.28534931]\n",
      " [ 1.21993767]\n",
      " [-0.53017052]\n",
      " [-1.27948802]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.08142423]\n",
      " [1.48824792]\n",
      " [0.28108078]\n",
      " [1.6370896 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4359803161696605 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.10842013]\n",
      " [ 3.59006187]\n",
      " [ 2.93076565]\n",
      " [ 1.75244029]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  436\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.81733648]\n",
      " [11.61775711]\n",
      " [17.77352816]\n",
      " [17.22505878]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.28266352]\n",
      " [ 1.21775711]\n",
      " [-0.52647184]\n",
      " [-1.27494122]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.07989867]\n",
      " [1.48293237]\n",
      " [0.2771726 ]\n",
      " [1.62547512]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.433184844797353 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.11058593]\n",
      " [ 3.59349587]\n",
      " [ 2.93409599]\n",
      " [ 1.7519848 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  437\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.81999693]\n",
      " [11.61556939]\n",
      " [17.77719669]\n",
      " [17.2295807 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.28000307]\n",
      " [ 1.21556939]\n",
      " [-0.52280331]\n",
      " [-1.2704193 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.07840172]\n",
      " [1.47760895]\n",
      " [0.2733233 ]\n",
      " [1.6139652 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.43041239613328075 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.11273007]\n",
      " [ 3.59692098]\n",
      " [ 2.93741495]\n",
      " [ 1.75152731]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  438\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.82263228]\n",
      " [11.61337469]\n",
      " [17.78083536]\n",
      " [17.23407795]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.27736772]\n",
      " [ 1.21337469]\n",
      " [-0.51916464]\n",
      " [-1.26592205]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.07693285]\n",
      " [1.47227815]\n",
      " [0.26953193]\n",
      " [1.60255864]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4276626964219853 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.11485277]\n",
      " [ 3.60033723]\n",
      " [ 2.94072258]\n",
      " [ 1.75106784]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  439\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.82524277]\n",
      " [11.61117317]\n",
      " [17.78444441]\n",
      " [17.23855073]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.27475723]\n",
      " [ 1.21117317]\n",
      " [-0.51555559]\n",
      " [-1.26144927]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.07549153]\n",
      " [1.46694044]\n",
      " [0.26579757]\n",
      " [1.59125427]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.424935476268131 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.11695424]\n",
      " [ 3.60374463]\n",
      " [ 2.9440189 ]\n",
      " [ 1.75060644]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  440\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.82782865]\n",
      " [11.60896497]\n",
      " [17.78802411]\n",
      " [17.24299924]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.27217135]\n",
      " [ 1.20896497]\n",
      " [-0.51197589]\n",
      " [-1.25700076]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.07407725]\n",
      " [1.4615963 ]\n",
      " [0.26211931]\n",
      " [1.58005091]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4222304705566874 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.1190347 ]\n",
      " [ 3.60714322]\n",
      " [ 2.94730398]\n",
      " [ 1.75014311]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  441\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.83039014]\n",
      " [11.60675025]\n",
      " [17.79157472]\n",
      " [17.24742368]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.26960986]\n",
      " [ 1.20675025]\n",
      " [-0.50842528]\n",
      " [-1.25257632]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.07268948]\n",
      " [1.45624618]\n",
      " [0.25849626]\n",
      " [1.56894743]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4195474183746828 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.12109435]\n",
      " [ 3.610533  ]\n",
      " [ 2.95057785]\n",
      " [ 1.74967789]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  442\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.83292748]\n",
      " [11.60452917]\n",
      " [17.7950965 ]\n",
      " [17.25182425]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.26707252]\n",
      " [ 1.20452917]\n",
      " [-0.5049035 ]\n",
      " [-1.24817575]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.07132773]\n",
      " [1.45089053]\n",
      " [0.25492754]\n",
      " [1.5579427 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.416886062934423 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.12313341]\n",
      " [ 3.613914  ]\n",
      " [ 2.95384057]\n",
      " [ 1.7492108 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  443\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.8354409 ]\n",
      " [11.60230188]\n",
      " [17.7985897 ]\n",
      " [17.25620114]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.2645591 ]\n",
      " [ 1.20230188]\n",
      " [-0.5014103 ]\n",
      " [-1.24379886]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06999152]\n",
      " [1.44552982]\n",
      " [0.25141228]\n",
      " [1.54703559]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4142461514982322 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.12515207]\n",
      " [ 3.61728625]\n",
      " [ 2.95709216]\n",
      " [ 1.74874187]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  444\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.83793064]\n",
      " [11.60006853]\n",
      " [17.80205458]\n",
      " [17.26055455]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.26206936]\n",
      " [ 1.20006853]\n",
      " [-0.49794542]\n",
      " [-1.23944545]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06868035]\n",
      " [1.44016447]\n",
      " [0.24794964]\n",
      " [1.53622502]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.411627435304602 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.12715055]\n",
      " [ 3.62064976]\n",
      " [ 2.96033269]\n",
      " [ 1.74827112]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  445\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.84039691]\n",
      " [11.59782926]\n",
      " [17.80549138]\n",
      " [17.26488467]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.25960309]\n",
      " [ 1.19782926]\n",
      " [-0.49450862]\n",
      " [-1.23511533]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06739376]\n",
      " [1.43479493]\n",
      " [0.24453878]\n",
      " [1.52550989]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.409029669495788 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.12912905]\n",
      " [ 3.62400456]\n",
      " [ 2.96356218]\n",
      " [ 1.74779858]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  446\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.84283996]\n",
      " [11.59558422]\n",
      " [17.80890034]\n",
      " [17.26919168]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.25716004]\n",
      " [ 1.19558422]\n",
      " [-0.49109966]\n",
      " [-1.23080832]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06613129]\n",
      " [1.42942162]\n",
      " [0.24117887]\n",
      " [1.51488913]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4064526130467877 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.13108776]\n",
      " [ 3.62735066]\n",
      " [ 2.96678069]\n",
      " [ 1.74732427]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  447\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.84525999]\n",
      " [11.59333355]\n",
      " [17.81228172]\n",
      " [17.27347577]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.25474001]\n",
      " [ 1.19333355]\n",
      " [-0.48771828]\n",
      " [-1.22652423]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06489247]\n",
      " [1.42404496]\n",
      " [0.23786912]\n",
      " [1.50436168]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.40389602869567764 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.13302688]\n",
      " [ 3.6306881 ]\n",
      " [ 2.96998826]\n",
      " [ 1.74684822]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  448\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.84765722]\n",
      " [11.5910774 ]\n",
      " [17.81563576]\n",
      " [17.27773714]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.25234278]\n",
      " [ 1.1910774 ]\n",
      " [-0.48436424]\n",
      " [-1.22226286]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06367688]\n",
      " [1.41866536]\n",
      " [0.23460871]\n",
      " [1.49392651]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.4013596828753095 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.13494661]\n",
      " [ 3.63401688]\n",
      " [ 2.97318493]\n",
      " [ 1.74637045]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  449\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.85003189]\n",
      " [11.5888159 ]\n",
      " [17.8189627 ]\n",
      " [17.28197595]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.24996811]\n",
      " [ 1.1888159 ]\n",
      " [-0.4810373 ]\n",
      " [-1.21802405]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06248406]\n",
      " [1.41328325]\n",
      " [0.23139688]\n",
      " [1.48358258]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3988433456462855 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.13684715]\n",
      " [ 3.63733703]\n",
      " [ 2.97637074]\n",
      " [ 1.74589099]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  450\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.8523842 ]\n",
      " [11.5865492 ]\n",
      " [17.82226278]\n",
      " [17.2861924 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.2476158 ]\n",
      " [ 1.1865492 ]\n",
      " [-0.47773722]\n",
      " [-1.2138076 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06131359]\n",
      " [1.40789901]\n",
      " [0.22823285]\n",
      " [1.47332888]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.39634679063125605 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.13872867]\n",
      " [ 3.64064857]\n",
      " [ 2.97954575]\n",
      " [ 1.74540986]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  451\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.85471436]\n",
      " [11.58427743]\n",
      " [17.82553623]\n",
      " [17.29038667]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.24528564]\n",
      " [ 1.18427743]\n",
      " [-0.47446377]\n",
      " [-1.20961333]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.06016504]\n",
      " [1.40251304]\n",
      " [0.22511587]\n",
      " [1.46316441]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3938697949504495 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.14059139]\n",
      " [ 3.64395152]\n",
      " [ 2.98270998]\n",
      " [ 1.74492708]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  452\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.8570226 ]\n",
      " [11.58200073]\n",
      " [17.82878328]\n",
      " [17.29455893]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.2429774 ]\n",
      " [ 1.18200073]\n",
      " [-0.47121672]\n",
      " [-1.20544107]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.05903802]\n",
      " [1.39712573]\n",
      " [0.22204519]\n",
      " [1.45308817]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3914121391584603 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.14243547]\n",
      " [ 3.64724591]\n",
      " [ 2.98586348]\n",
      " [ 1.74444268]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  453\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.85930912]\n",
      " [11.57971923]\n",
      " [17.83200418]\n",
      " [17.29870936]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.24069088]\n",
      " [ 1.17971923]\n",
      " [-0.46799582]\n",
      " [-1.20129064]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0579321 ]\n",
      " [1.39173747]\n",
      " [0.21902009]\n",
      " [1.4430992 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3889736071822246 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.14426112]\n",
      " [ 3.65053175]\n",
      " [ 2.9890063 ]\n",
      " [ 1.74395668]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  454\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.86157412]\n",
      " [11.57743307]\n",
      " [17.83519914]\n",
      " [17.30283814]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.23842588]\n",
      " [ 1.17743307]\n",
      " [-0.46480086]\n",
      " [-1.19716186]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0568469 ]\n",
      " [1.38634863]\n",
      " [0.21603984]\n",
      " [1.43319652]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3865539862602144 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.14606851]\n",
      " [ 3.65380906]\n",
      " [ 2.99213847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 1.7434691 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  455\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.86381782]\n",
      " [11.57514237]\n",
      " [17.8383684 ]\n",
      " [17.30694543]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.23618218]\n",
      " [ 1.17514237]\n",
      " [-0.4616316 ]\n",
      " [-1.19305457]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.05578202]\n",
      " [1.38095959]\n",
      " [0.21310373]\n",
      " [1.4233792 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.38415306688277007 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.14785782]\n",
      " [ 3.65707787]\n",
      " [ 2.99526005]\n",
      " [ 1.74297998]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  456\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.86604042]\n",
      " [11.57284726]\n",
      " [17.84151219]\n",
      " [17.31103142]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.23395958]\n",
      " [ 1.17284726]\n",
      " [-0.45848781]\n",
      " [-1.18896858]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.05473709]\n",
      " [1.3755707 ]\n",
      " [0.21021107]\n",
      " [1.41364628]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3817706427335895 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.14962924]\n",
      " [ 3.6603382 ]\n",
      " [ 2.99837106]\n",
      " [ 1.74248932]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  457\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.86824212]\n",
      " [11.57054788]\n",
      " [17.84463072]\n",
      " [17.31509627]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.23175788]\n",
      " [ 1.17054788]\n",
      " [-0.45536928]\n",
      " [-1.18490373]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.05371172]\n",
      " [1.37018233]\n",
      " [0.20736119]\n",
      " [1.40399685]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.37940651063233427 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.15138295]\n",
      " [ 3.66359006]\n",
      " [ 3.00147155]\n",
      " [ 1.74199716]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  458\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.87042311]\n",
      " [11.56824434]\n",
      " [17.84772421]\n",
      " [17.31914014]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.22957689]\n",
      " [ 1.16824434]\n",
      " [-0.45227579]\n",
      " [-1.18085986]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.05270555]\n",
      " [1.36479483]\n",
      " [0.20455339]\n",
      " [1.39443   ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.37706047047833635 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.15311912]\n",
      " [ 3.66683348]\n",
      " [ 3.00456157]\n",
      " [ 1.74150351]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  459\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.87258361]\n",
      " [11.56593677]\n",
      " [17.85079289]\n",
      " [17.32316322]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.22741639]\n",
      " [ 1.16593677]\n",
      " [-0.44920711]\n",
      " [-1.17683678]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.05171821]\n",
      " [1.35940855]\n",
      " [0.20178702]\n",
      " [1.38494481]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3747323251953715 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.15483793]\n",
      " [ 3.67006847]\n",
      " [ 3.00764115]\n",
      " [ 1.7410084 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  460\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.8747238 ]\n",
      " [11.56362529]\n",
      " [17.85383698]\n",
      " [17.32716565]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.2252762 ]\n",
      " [ 1.16362529]\n",
      " [-0.44616302]\n",
      " [-1.17283435]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.05074937]\n",
      " [1.35402383]\n",
      " [0.19906144]\n",
      " [1.37554041]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.37242188067750126 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.15653955]\n",
      " [ 3.67329507]\n",
      " [ 3.01071034]\n",
      " [ 1.74051185]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  461\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.87684388]\n",
      " [11.56131004]\n",
      " [17.85685668]\n",
      " [17.33114761]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.22315612]\n",
      " [ 1.16131004]\n",
      " [-0.44314332]\n",
      " [-1.16885239]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04979865]\n",
      " [1.348641  ]\n",
      " [0.196376  ]\n",
      " [1.36621591]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.37012894573594296 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.15822416]\n",
      " [ 3.67651328]\n",
      " [ 3.01376917]\n",
      " [ 1.74001388]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  462\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.87894404]\n",
      " [11.55899111]\n",
      " [17.85985222]\n",
      " [17.33510925]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.22105596]\n",
      " [ 1.15899111]\n",
      " [-0.44014778]\n",
      " [-1.16489075]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04886574]\n",
      " [1.3432604 ]\n",
      " [0.19373007]\n",
      " [1.35697046]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.367853332046954 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.15989191]\n",
      " [ 3.67972314]\n",
      " [ 3.01681768]\n",
      " [ 1.73951452]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  463\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.88102447]\n",
      " [11.55666864]\n",
      " [17.8628238 ]\n",
      " [17.33905074]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.21897553]\n",
      " [ 1.15666864]\n",
      " [-0.4371762 ]\n",
      " [-1.16094926]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04795028]\n",
      " [1.33788235]\n",
      " [0.19112303]\n",
      " [1.34780318]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3655948541007125 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.161543  ]\n",
      " [ 3.68292465]\n",
      " [ 3.01985592]\n",
      " [ 1.73901378]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  464\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.88308536]\n",
      " [11.55434274]\n",
      " [17.86577164]\n",
      " [17.34297224]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.21691464]\n",
      " [ 1.15434274]\n",
      " [-0.43422836]\n",
      " [-1.15702776]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04705196]\n",
      " [1.33250716]\n",
      " [0.18855427]\n",
      " [1.33871324]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3633533291511776 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.16317757]\n",
      " [ 3.68611784]\n",
      " [ 3.02288393]\n",
      " [ 1.73851169]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  465\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.8851269 ]\n",
      " [11.55201353]\n",
      " [17.86869594]\n",
      " [17.3468739 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.2148731 ]\n",
      " [ 1.15201353]\n",
      " [-0.43130406]\n",
      " [-1.1531261 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04617045]\n",
      " [1.32713517]\n",
      " [0.1860232 ]\n",
      " [1.32969981]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3611285771668916 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.16479579]\n",
      " [ 3.68930274]\n",
      " [ 3.02590175]\n",
      " [ 1.73800827]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  466\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.88714927]\n",
      " [11.54968111]\n",
      " [17.8715969 ]\n",
      " [17.35075588]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.21285073]\n",
      " [ 1.14968111]\n",
      " [-0.4284031 ]\n",
      " [-1.14924412]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04530543]\n",
      " [1.32176666]\n",
      " [0.18352922]\n",
      " [1.32076206]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.35892042078274305 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.16639783]\n",
      " [ 3.69247935]\n",
      " [ 3.02890941]\n",
      " [ 1.73750353]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  467\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.88915265]\n",
      " [11.54734561]\n",
      " [17.87447474]\n",
      " [17.35461833]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.21084735]\n",
      " [ 1.14734561]\n",
      " [-0.42552526]\n",
      " [-1.14538167]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0444566 ]\n",
      " [1.31640195]\n",
      " [0.18107175]\n",
      " [1.31189918]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.35672868525262547 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.16798385]\n",
      " [ 3.6956477 ]\n",
      " [ 3.03190695]\n",
      " [ 1.73699751]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  468\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.89113723]\n",
      " [11.54500713]\n",
      " [17.87732964]\n",
      " [17.3584614 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.20886277]\n",
      " [ 1.14500713]\n",
      " [-0.42267036]\n",
      " [-1.1415386 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04362366]\n",
      " [1.31104133]\n",
      " [0.17865023]\n",
      " [1.30311037]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.35455319840301247 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.16955401]\n",
      " [ 3.69880782]\n",
      " [ 3.03489442]\n",
      " [ 1.73649021]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  469\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.89310319]\n",
      " [11.54266579]\n",
      " [17.88016183]\n",
      " [17.36228526]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.20689681]\n",
      " [ 1.14266579]\n",
      " [-0.41983817]\n",
      " [-1.13771474]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04280629]\n",
      " [1.3056851 ]\n",
      " [0.17626409]\n",
      " [1.29439484]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3523937905874126 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.17110847]\n",
      " [ 3.70195971]\n",
      " [ 3.03787186]\n",
      " [ 1.73598167]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  470\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.8950507 ]\n",
      " [11.54032169]\n",
      " [17.88297148]\n",
      " [17.36609004]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.2049493 ]\n",
      " [ 1.14032169]\n",
      " [-0.41702852]\n",
      " [-1.13390996]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04200422]\n",
      " [1.30033355]\n",
      " [0.17391279]\n",
      " [1.28575181]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3502502946416878 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.17264739]\n",
      " [ 3.70510341]\n",
      " [ 3.0408393 ]\n",
      " [ 1.7354719 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  471\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.89697994]\n",
      " [11.53797493]\n",
      " [17.8857588 ]\n",
      " [17.36987589]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.20302006]\n",
      " [ 1.13797493]\n",
      " [-0.4142412 ]\n",
      " [-1.13012411]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.04121715]\n",
      " [1.29498695]\n",
      " [0.17159577]\n",
      " [1.2771805 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.348122545840229 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.17417092]\n",
      " [ 3.70823893]\n",
      " [ 3.04379678]\n",
      " [ 1.73496093]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  472\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.89889108]\n",
      " [11.53562563]\n",
      " [17.88852398]\n",
      " [17.37364297]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.20110892]\n",
      " [ 1.13562563]\n",
      " [-0.41147602]\n",
      " [-1.12635703]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0404448 ]\n",
      " [1.28964558]\n",
      " [0.16931251]\n",
      " [1.26868017]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3460103818529513 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.17567921]\n",
      " [ 3.71136629]\n",
      " [ 3.04674434]\n",
      " [ 1.73444876]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  473\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.9007843 ]\n",
      " [11.53327389]\n",
      " [17.89126722]\n",
      " [17.37739141]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.1992157 ]\n",
      " [ 1.13327389]\n",
      " [-0.40873278]\n",
      " [-1.12260859]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0396869 ]\n",
      " [1.28430972]\n",
      " [0.16706248]\n",
      " [1.26025004]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3439136427031265 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.17717241]\n",
      " [ 3.71448551]\n",
      " [ 3.04968203]\n",
      " [ 1.73393543]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  474\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.90265977]\n",
      " [11.53091982]\n",
      " [17.89398871]\n",
      " [17.38112137]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.19734023]\n",
      " [ 1.13091982]\n",
      " [-0.40601129]\n",
      " [-1.11887863]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03894317]\n",
      " [1.27897963]\n",
      " [0.16484517]\n",
      " [1.25188939]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.34183217072599104 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.17865069]\n",
      " [ 3.71759661]\n",
      " [ 3.05260987]\n",
      " [ 1.73342095]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  475\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.90451765]\n",
      " [11.52856351]\n",
      " [17.89668863]\n",
      " [17.38483298]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.19548235]\n",
      " [ 1.12856351]\n",
      " [-0.40331137]\n",
      " [-1.11516702]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03821335]\n",
      " [1.27365559]\n",
      " [0.16266006]\n",
      " [1.24359749]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3397658105281629 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.18011418]\n",
      " [ 3.72069961]\n",
      " [ 3.0555279 ]\n",
      " [ 1.73290534]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  476\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.90635812]\n",
      " [11.52620506]\n",
      " [17.89936717]\n",
      " [17.38852638]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.19364188]\n",
      " [ 1.12620506]\n",
      " [-0.40063283]\n",
      " [-1.11147362]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03749718]\n",
      " [1.26833783]\n",
      " [0.16050666]\n",
      " [1.2353736 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.33771440894781235 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.18156304]\n",
      " [ 3.72379453]\n",
      " [ 3.05843618]\n",
      " [ 1.73238862]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  477\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.90818134]\n",
      " [11.52384458]\n",
      " [17.90202453]\n",
      " [17.39220173]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.19181866]\n",
      " [ 1.12384458]\n",
      " [-0.39797547]\n",
      " [-1.10779827]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0367944 ]\n",
      " [1.26302663]\n",
      " [0.15838447]\n",
      " [1.22721702]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3356778150155981 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.18299741]\n",
      " [ 3.72688139]\n",
      " [ 3.06133472]\n",
      " [ 1.73187081]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  478\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.90998747]\n",
      " [11.52148215]\n",
      " [17.90466088]\n",
      " [17.39585914]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.19001253]\n",
      " [ 1.12148215]\n",
      " [-0.39533912]\n",
      " [-1.10414086]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03610476]\n",
      " [1.25772222]\n",
      " [0.15629302]\n",
      " [1.21912703]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.33365587991633283 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.18441744]\n",
      " [ 3.72996022]\n",
      " [ 3.06422357]\n",
      " [ 1.73135193]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  479\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.91177668]\n",
      " [11.51911789]\n",
      " [17.9072764 ]\n",
      " [17.39949877]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.18822332]\n",
      " [ 1.11911789]\n",
      " [-0.3927236 ]\n",
      " [-1.10050123]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03542802]\n",
      " [1.25242486]\n",
      " [0.15423182]\n",
      " [1.21110296]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.33164845695138667 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.18582326]\n",
      " [ 3.73303102]\n",
      " [ 3.06710277]\n",
      " [ 1.73083199]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  480\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.91354913]\n",
      " [11.51675189]\n",
      " [17.90987129]\n",
      " [17.40312075]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.18645087]\n",
      " [ 1.11675189]\n",
      " [-0.39012871]\n",
      " [-1.09687925]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03476393]\n",
      " [1.24713478]\n",
      " [0.15220041]\n",
      " [1.2031441 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.32965540150179173 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.18721503]\n",
      " [ 3.73609382]\n",
      " [ 3.06997236]\n",
      " [ 1.73031103]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  481\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.91530498]\n",
      " [11.51438423]\n",
      " [17.91244571]\n",
      " [17.4067252 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.18469502]\n",
      " [ 1.11438423]\n",
      " [-0.38755429]\n",
      " [-1.0932748 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03411225]\n",
      " [1.24185221]\n",
      " [0.15019833]\n",
      " [1.19524978]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3276765709920523 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.18859288]\n",
      " [ 3.73914864]\n",
      " [ 3.07283237]\n",
      " [ 1.72978905]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  482\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.91704439]\n",
      " [11.51201501]\n",
      " [17.91499984]\n",
      " [17.41031228]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.18295561]\n",
      " [ 1.11201501]\n",
      " [-0.38500016]\n",
      " [-1.08968772]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03347276]\n",
      " [1.23657739]\n",
      " [0.14822512]\n",
      " [1.18741933]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.32571182485463046 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.18995695]\n",
      " [ 3.74219549]\n",
      " [ 3.07568283]\n",
      " [ 1.72926607]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  483\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.91876751]\n",
      " [11.50964433]\n",
      " [17.91753387]\n",
      " [17.4138821 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.18123249]\n",
      " [ 1.10964433]\n",
      " [-0.38246613]\n",
      " [-1.0861179 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03284522]\n",
      " [1.23131054]\n",
      " [0.14628034]\n",
      " [1.17965209]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.32376102449511723 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.19130738]\n",
      " [ 3.74523441]\n",
      " [ 3.0785238 ]\n",
      " [ 1.72874212]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  484\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.92047449]\n",
      " [11.50727228]\n",
      " [17.92004796]\n",
      " [17.4174348 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.17952551]\n",
      " [ 1.10727228]\n",
      " [-0.37995204]\n",
      " [-1.0825652 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03222941]\n",
      " [1.22605189]\n",
      " [0.14436355]\n",
      " [1.17194741]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.32182403325804326 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.19264431]\n",
      " [ 3.7482654 ]\n",
      " [ 3.08135529]\n",
      " [ 1.7282172 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  485\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.9221655 ]\n",
      " [11.50489893]\n",
      " [17.92254229]\n",
      " [17.42097051]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.1778345 ]\n",
      " [ 1.10489893]\n",
      " [-0.37745771]\n",
      " [-1.07902949]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03162511]\n",
      " [1.22080166]\n",
      " [0.14247433]\n",
      " [1.16430464]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3199007163933483 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.19396786]\n",
      " [ 3.75128849]\n",
      " [ 3.08417736]\n",
      " [ 1.72769135]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  486\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.92384069]\n",
      " [11.5025244 ]\n",
      " [17.92501702]\n",
      " [17.42448936]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.17615931]\n",
      " [ 1.1025244 ]\n",
      " [-0.37498298]\n",
      " [-1.07551064]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0310321 ]\n",
      " [1.21556005]\n",
      " [0.14061223]\n",
      " [1.15672314]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3179909410234766 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.19527819]\n",
      " [ 3.7543037 ]\n",
      " [ 3.08699002]\n",
      " [ 1.72716457]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  487\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.92550019]\n",
      " [11.50014875]\n",
      " [17.92747234]\n",
      " [17.42799147]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.17449981]\n",
      " [ 1.10014875]\n",
      " [-0.37252766]\n",
      " [-1.07200853]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.03045018]\n",
      " [1.21032727]\n",
      " [0.13877686]\n",
      " [1.1492023 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3160945761110936 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.1965754 ]\n",
      " [ 3.75731104]\n",
      " [ 3.08979334]\n",
      " [ 1.72663688]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  488\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.92714417]\n",
      " [11.49777208]\n",
      " [17.9299084 ]\n",
      " [17.43147697]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.17285583]\n",
      " [ 1.09777208]\n",
      " [-0.3700916 ]\n",
      " [-1.06852303]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02987914]\n",
      " [1.20510354]\n",
      " [0.13696779]\n",
      " [1.14174147]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3142114924274154 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.19785965]\n",
      " [ 3.76031053]\n",
      " [ 3.09258733]\n",
      " [ 1.72610831]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  489\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.92877278]\n",
      " [11.49539447]\n",
      " [17.93232537]\n",
      " [17.43494598]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.17122722]\n",
      " [ 1.09539447]\n",
      " [-0.36767463]\n",
      " [-1.06505402]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02931876]\n",
      " [1.19988905]\n",
      " [0.13518463]\n",
      " [1.13434006]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3123415625211274 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.19913105]\n",
      " [ 3.7633022 ]\n",
      " [ 3.09537203]\n",
      " [ 1.72557886]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  490\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.93038615]\n",
      " [11.49301601]\n",
      " [17.93472343]\n",
      " [17.43839864]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.16961385]\n",
      " [ 1.09301601]\n",
      " [-0.36527657]\n",
      " [-1.06160136]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02876886]\n",
      " [1.19468399]\n",
      " [0.13342698]\n",
      " [1.12699746]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.31048466068788483 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.20038974]\n",
      " [ 3.76628606]\n",
      " [ 3.09814748]\n",
      " [ 1.72504856]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  491\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.93198443]\n",
      " [11.49063677]\n",
      " [17.93710272]\n",
      " [17.44183505]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.16801557]\n",
      " [ 1.09063677]\n",
      " [-0.36289728]\n",
      " [-1.05816495]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02822923]\n",
      " [1.18948857]\n",
      " [0.13169444]\n",
      " [1.11971306]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.30864066294040626 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.20163585]\n",
      " [ 3.76926214]\n",
      " [ 3.10091372]\n",
      " [ 1.72451742]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  492\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.93356777]\n",
      " [11.48825685]\n",
      " [17.93946342]\n",
      " [17.44525534]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.16643223]\n",
      " [ 1.08825685]\n",
      " [-0.36053658]\n",
      " [-1.05474466]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02769969]\n",
      " [1.18430297]\n",
      " [0.12998663]\n",
      " [1.11248629]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3068094469791043 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.20286949]\n",
      " [ 3.77223044]\n",
      " [ 3.10367077]\n",
      " [ 1.72398547]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  493\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.9351363 ]\n",
      " [11.48587632]\n",
      " [17.94180568]\n",
      " [17.44865964]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.1648637 ]\n",
      " [ 1.08587632]\n",
      " [-0.35819432]\n",
      " [-1.05134036]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02718004]\n",
      " [1.17912738]\n",
      " [0.12830317]\n",
      " [1.10531655]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.30499089216328046 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.20409079]\n",
      " [ 3.775191  ]\n",
      " [ 3.10641869]\n",
      " [ 1.72345271]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  494\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.93669018]\n",
      " [11.48349526]\n",
      " [17.94412967]\n",
      " [17.45204806]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.16330982]\n",
      " [ 1.08349526]\n",
      " [-0.35587033]\n",
      " [-1.04795194]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0266701 ]\n",
      " [1.17396198]\n",
      " [0.12664369]\n",
      " [1.09820327]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3031848794828641 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.20529988]\n",
      " [ 3.77814382]\n",
      " [ 3.10915749]\n",
      " [ 1.72291916]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  495\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.93822953]\n",
      " [11.48111375]\n",
      " [17.94643554]\n",
      " [17.45542072]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.16177047]\n",
      " [ 1.08111375]\n",
      " [-0.35356446]\n",
      " [-1.04457928]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02616968]\n",
      " [1.16880694]\n",
      " [0.12500783]\n",
      " [1.09114588]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.3013912915306679 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.20649689]\n",
      " [ 3.78108894]\n",
      " [ 3.11188722]\n",
      " [ 1.72238485]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  496\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.9397545 ]\n",
      " [11.47873187]\n",
      " [17.94872345]\n",
      " [17.45877773]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.1602455 ]\n",
      " [ 1.07873187]\n",
      " [-0.35127655]\n",
      " [-1.04122227]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02567862]\n",
      " [1.16366245]\n",
      " [0.12339522]\n",
      " [1.08414382]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.29961001247518027 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.20768192]\n",
      " [ 3.78402636]\n",
      " [ 3.11460791]\n",
      " [ 1.72184978]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  497\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.94126522]\n",
      " [11.47634969]\n",
      " [17.95099355]\n",
      " [17.46211921]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.15873478]\n",
      " [ 1.07634969]\n",
      " [-0.34900645]\n",
      " [-1.03788079]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02519673]\n",
      " [1.15852866]\n",
      " [0.1218055 ]\n",
      " [1.07719653]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2978409280338509 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2088551 ]\n",
      " [ 3.78695611]\n",
      " [ 3.11731959]\n",
      " [ 1.72131397]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  498\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.94276183]\n",
      " [11.47396729]\n",
      " [17.95324599]\n",
      " [17.46544528]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.15723817]\n",
      " [ 1.07396729]\n",
      " [-0.34675401]\n",
      " [-1.03455472]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02472384]\n",
      " [1.15340575]\n",
      " [0.12023834]\n",
      " [1.07030347]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.29608392544688866 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21001655]\n",
      " [ 3.7898782 ]\n",
      " [ 3.12002231]\n",
      " [ 1.72077744]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  499\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.94424445]\n",
      " [11.47158475]\n",
      " [17.95548094]\n",
      " [17.46875605]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.15575555]\n",
      " [ 1.07158475]\n",
      " [-0.34451906]\n",
      " [-1.03124395]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02425979]\n",
      " [1.14829388]\n",
      " [0.11869339]\n",
      " [1.06346409]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2943388934515439 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21116638]\n",
      " [ 3.79279265]\n",
      " [ 3.12271608]\n",
      " [ 1.72024021]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  500\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.94571324]\n",
      " [11.46920214]\n",
      " [17.95769853]\n",
      " [17.47205162]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.15428676]\n",
      " [ 1.06920214]\n",
      " [-0.34230147]\n",
      " [-1.02794838]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02380441]\n",
      " [1.14319321]\n",
      " [0.1171703 ]\n",
      " [1.05667787]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2926057222568701 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21230472]\n",
      " [ 3.79569949]\n",
      " [ 3.12540096]\n",
      " [ 1.71970229]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  501\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.94716831]\n",
      " [11.46681952]\n",
      " [17.95989892]\n",
      " [17.47533212]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.15283169]\n",
      " [ 1.06681952]\n",
      " [-0.34010108]\n",
      " [-1.02466788]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02335753]\n",
      " [1.1381039 ]\n",
      " [0.11566874]\n",
      " [1.04994426]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2908843035189582 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21343167]\n",
      " [ 3.79859873]\n",
      " [ 3.12807697]\n",
      " [ 1.71916369]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  502\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.94860979]\n",
      " [11.46443698]\n",
      " [17.96208226]\n",
      " [17.47859765]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.15139021]\n",
      " [ 1.06443698]\n",
      " [-0.33791774]\n",
      " [-1.02140235]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.022919  ]\n",
      " [1.13302609]\n",
      " [0.1141884 ]\n",
      " [1.04326275]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.28917453031664064 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21454735]\n",
      " [ 3.80149039]\n",
      " [ 3.13074414]\n",
      " [ 1.71862444]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  503\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.95003782]\n",
      " [11.46205459]\n",
      " [17.96424869]\n",
      " [17.48184833]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.14996218]\n",
      " [ 1.06205459]\n",
      " [-0.33575131]\n",
      " [-1.01815167]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02248866]\n",
      " [1.12795994]\n",
      " [0.11272895]\n",
      " [1.03663283]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2874762971276311 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21565188]\n",
      " [ 3.80437449]\n",
      " [ 3.13340251]\n",
      " [ 1.71808455]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  504\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.95145252]\n",
      " [11.4596724 ]\n",
      " [17.96639835]\n",
      " [17.48508425]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.14854748]\n",
      " [ 1.0596724 ]\n",
      " [-0.33360165]\n",
      " [-1.01491575]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02206635]\n",
      " [1.1229056 ]\n",
      " [0.11129006]\n",
      " [1.03005398]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2857894998051297 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21674536]\n",
      " [ 3.80725105]\n",
      " [ 3.13605212]\n",
      " [ 1.71754402]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  505\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.95285402]\n",
      " [11.4572905 ]\n",
      " [17.9685314 ]\n",
      " [17.48830553]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.14714598]\n",
      " [ 1.0572905 ]\n",
      " [-0.3314686 ]\n",
      " [-1.01169447]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02165194]\n",
      " [1.1178632 ]\n",
      " [0.10987143]\n",
      " [1.02352571]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.28411403555484527 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21782791]\n",
      " [ 3.81012008]\n",
      " [ 3.13869299]\n",
      " [ 1.71700289]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  506\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.95424244]\n",
      " [11.45490895]\n",
      " [17.97064798]\n",
      " [17.49151227]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.14575756]\n",
      " [ 1.05490895]\n",
      " [-0.32935202]\n",
      " [-1.00848773]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02124527]\n",
      " [1.11283289]\n",
      " [0.10847276]\n",
      " [1.01704751]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.28244980291245836 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21889963]\n",
      " [ 3.81298161]\n",
      " [ 3.14132516]\n",
      " [ 1.71646116]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  507\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.95561791]\n",
      " [11.45252782]\n",
      " [17.97274822]\n",
      " [17.49470457]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.14438209]\n",
      " [ 1.05252782]\n",
      " [-0.32725178]\n",
      " [-1.00529543]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02084619]\n",
      " [1.1078148 ]\n",
      " [0.10709373]\n",
      " [1.01061889]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2807967017214958 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.21996063]\n",
      " [ 3.81583565]\n",
      " [ 3.14394866]\n",
      " [ 1.71591885]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  508\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.95698055]\n",
      " [11.45014717]\n",
      " [17.97483226]\n",
      " [17.49788256]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.14301945]\n",
      " [ 1.05014717]\n",
      " [-0.32516774]\n",
      " [-1.00211744]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02045456]\n",
      " [1.10280907]\n",
      " [0.10573406]\n",
      " [1.00423937]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2791546331116201 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.22101103]\n",
      " [ 3.81868222]\n",
      " [ 3.14656353]\n",
      " [ 1.71537597]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  509\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.95833048]\n",
      " [11.44776706]\n",
      " [17.97690025]\n",
      " [17.50104631]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.14166952]\n",
      " [ 1.04776706]\n",
      " [-0.32309975]\n",
      " [-0.99895369]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.02007025]\n",
      " [1.09781582]\n",
      " [0.10439345]\n",
      " [0.99790848]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.27752349947731947 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.22205092]\n",
      " [ 3.82152134]\n",
      " [ 3.1491698 ]\n",
      " [ 1.71483253]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  510\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.95966782]\n",
      " [11.44538758]\n",
      " [17.97895232]\n",
      " [17.50419594]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.14033218]\n",
      " [ 1.04538758]\n",
      " [-0.32104768]\n",
      " [-0.99580406]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01969312]\n",
      " [1.09283518]\n",
      " [0.10307161]\n",
      " [0.99162572]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.27590320445699623 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.22308041]\n",
      " [ 3.82435303]\n",
      " [ 3.1517675 ]\n",
      " [ 1.71428856]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  511\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.9609927 ]\n",
      " [11.44300876]\n",
      " [17.98098861]\n",
      " [17.50733155]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.1390073 ]\n",
      " [ 1.04300876]\n",
      " [-0.31901139]\n",
      " [-0.99266845]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01932303]\n",
      " [1.08786728]\n",
      " [0.10176826]\n",
      " [0.98539065]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.27429365291243596 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2240996 ]\n",
      " [ 3.8271773 ]\n",
      " [ 3.15435666]\n",
      " [ 1.71374407]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  512\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.96230522]\n",
      " [11.44063069]\n",
      " [17.98300926]\n",
      " [17.51045324]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.13769478]\n",
      " [ 1.04063069]\n",
      " [-0.31699074]\n",
      " [-0.98954676]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01895985]\n",
      " [1.08291223]\n",
      " [0.10048313]\n",
      " [0.97920279]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.27269475090867035 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.22510861]\n",
      " [ 3.82999418]\n",
      " [ 3.15693732]\n",
      " [ 1.71319907]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  513\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.96360551]\n",
      " [11.43825342]\n",
      " [17.98501439]\n",
      " [17.5135611 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.13639449]\n",
      " [ 1.03825342]\n",
      " [-0.31498561]\n",
      " [-0.9864389 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01860346]\n",
      " [1.07797016]\n",
      " [0.09921593]\n",
      " [0.9730617 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2711064056941932 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.22610752]\n",
      " [ 3.83280369]\n",
      " [ 3.1595095 ]\n",
      " [ 1.71265357]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  514\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.96489368]\n",
      " [11.43587701]\n",
      " [17.98700414]\n",
      " [17.51665525]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.13510632]\n",
      " [ 1.03587701]\n",
      " [-0.31299586]\n",
      " [-0.98334475]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01825372]\n",
      " [1.07304118]\n",
      " [0.09796641]\n",
      " [0.96696691]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.26952852568156127 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.22709645]\n",
      " [ 3.83560583]\n",
      " [ 3.16207325]\n",
      " [ 1.71210759]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  515\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.96616985]\n",
      " [11.43350152]\n",
      " [17.98897865]\n",
      " [17.51973576]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.13383015]\n",
      " [ 1.03350152]\n",
      " [-0.31102135]\n",
      " [-0.98026424]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01791051]\n",
      " [1.06812539]\n",
      " [0.09673428]\n",
      " [0.96091798]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost =  0.267961020428342 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.22807548]\n",
      " [ 3.83840063]\n",
      " [ 3.16462859]\n",
      " [ 1.71156115]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  516\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.96743413]\n",
      " [11.43112701]\n",
      " [17.99093803]\n",
      " [17.52280274]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.13256587]\n",
      " [ 1.03112701]\n",
      " [-0.30906197]\n",
      " [-0.97719726]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01757371]\n",
      " [1.06322292]\n",
      " [0.0955193 ]\n",
      " [0.95491448]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.26640380061841606 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.22904473]\n",
      " [ 3.84118812]\n",
      " [ 3.16717555]\n",
      " [ 1.71101425]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  517\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.96868663]\n",
      " [11.42875355]\n",
      " [17.99288243]\n",
      " [17.52585629]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.13131337]\n",
      " [ 1.02875355]\n",
      " [-0.30711757]\n",
      " [-0.97414371]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0172432 ]\n",
      " [1.05833386]\n",
      " [0.0943212 ]\n",
      " [0.94895596]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.26485677804362573 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23000428]\n",
      " [ 3.84396829]\n",
      " [ 3.16971417]\n",
      " [ 1.71046691]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  518\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.96992747]\n",
      " [11.42638118]\n",
      " [17.99481197]\n",
      " [17.5288965 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.13007253]\n",
      " [ 1.02638118]\n",
      " [-0.30518803]\n",
      " [-0.9711035 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01691886]\n",
      " [1.05345832]\n",
      " [0.09313974]\n",
      " [0.943042  ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2633198655857586 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23095424]\n",
      " [ 3.84674119]\n",
      " [ 3.17224448]\n",
      " [ 1.70991915]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  519\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.97115675]\n",
      " [11.42400996]\n",
      " [17.99672677]\n",
      " [17.53192347]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.12884325]\n",
      " [ 1.02400996]\n",
      " [-0.30327323]\n",
      " [-0.96807653]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01660058]\n",
      " [1.0485964 ]\n",
      " [0.09197465]\n",
      " [0.93717218]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2617929771988672 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23189469]\n",
      " [ 3.84950681]\n",
      " [ 3.1747665 ]\n",
      " [ 1.70937097]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  520\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.97237458]\n",
      " [11.42163996]\n",
      " [17.99862696]\n",
      " [17.53493728]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.12762542]\n",
      " [ 1.02163996]\n",
      " [-0.30137304]\n",
      " [-0.96506272]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01628825]\n",
      " [1.0437482 ]\n",
      " [0.09082571]\n",
      " [0.93134606]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.26027602789191273 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23282575]\n",
      " [ 3.85226518]\n",
      " [ 3.17728028]\n",
      " [ 1.7088224 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  521\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.97358108]\n",
      " [11.41927122]\n",
      " [18.00051266]\n",
      " [17.53793802]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.12641892]\n",
      " [ 1.01927122]\n",
      " [-0.29948734]\n",
      " [-0.96206198]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01598174]\n",
      " [1.03891382]\n",
      " [0.08969266]\n",
      " [0.92556325]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2587689337117199 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23374749]\n",
      " [ 3.85501632]\n",
      " [ 3.17978583]\n",
      " [ 1.70827344]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  522\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.97477634]\n",
      " [11.4169038 ]\n",
      " [18.00238401]\n",
      " [17.5409258 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.12522366]\n",
      " [ 1.0169038 ]\n",
      " [-0.29761599]\n",
      " [-0.9590742 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01568096]\n",
      " [1.03409334]\n",
      " [0.08857528]\n",
      " [0.91982332]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2572716117262589 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23466001]\n",
      " [ 3.85776025]\n",
      " [ 3.1822832 ]\n",
      " [ 1.70772411]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  523\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.97596048]\n",
      " [11.41453775]\n",
      " [18.00424112]\n",
      " [17.5439007 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.12403952]\n",
      " [ 1.01453775]\n",
      " [-0.29575888]\n",
      " [-0.9560993 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0153858 ]\n",
      " [1.02928685]\n",
      " [0.08747332]\n",
      " [0.91412587]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2557839800082223 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23556341]\n",
      " [ 3.86049698]\n",
      " [ 3.18477241]\n",
      " [ 1.70717441]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  524\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.9771336 ]\n",
      " [11.41217314]\n",
      " [18.00608411]\n",
      " [17.54686281]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.1228664 ]\n",
      " [ 1.01217314]\n",
      " [-0.29391589]\n",
      " [-0.95313719]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01509615]\n",
      " [1.02449446]\n",
      " [0.08638655]\n",
      " [0.9084705 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.25430595761890656 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23645778]\n",
      " [ 3.86322653]\n",
      " [ 3.18725349]\n",
      " [ 1.70662438]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  525\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.97829581]\n",
      " [11.40981   ]\n",
      " [18.0079131 ]\n",
      " [17.54981222]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.12170419]\n",
      " [ 1.00981   ]\n",
      " [-0.2920869 ]\n",
      " [-0.95018778]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01481191]\n",
      " [1.01971623]\n",
      " [0.08531476]\n",
      " [0.90285682]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.25283746459239576 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2373432 ]\n",
      " [ 3.86594892]\n",
      " [ 3.18972648]\n",
      " [ 1.706074  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  526\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.9794472 ]\n",
      " [11.40744839]\n",
      " [18.00972821]\n",
      " [17.55274901]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.1205528 ]\n",
      " [ 1.00744839]\n",
      " [-0.29027179]\n",
      " [-0.94725099]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01453298]\n",
      " [1.01495225]\n",
      " [0.08425771]\n",
      " [0.89728443]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2513784219200203 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23821977]\n",
      " [ 3.86866416]\n",
      " [ 3.1921914 ]\n",
      " [ 1.70552331]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  527\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.98058788]\n",
      " [11.40508836]\n",
      " [18.01152956]\n",
      " [17.55567328]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.11941212]\n",
      " [ 1.00508836]\n",
      " [-0.28847044]\n",
      " [-0.94432672]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01425925]\n",
      " [1.01020261]\n",
      " [0.08321519]\n",
      " [0.89175295]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2499287515351093 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.23908757]\n",
      " [ 3.87137228]\n",
      " [ 3.19464829]\n",
      " [ 1.70497231]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  528\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.98171795]\n",
      " [11.40272996]\n",
      " [18.01331727]\n",
      " [17.55858511]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.11828205]\n",
      " [ 1.00272996]\n",
      " [-0.28668273]\n",
      " [-0.94141489]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01399064]\n",
      " [1.00546738]\n",
      " [0.08218699]\n",
      " [0.886262  ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.24848837629802273 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2399467 ]\n",
      " [ 3.8740733 ]\n",
      " [ 3.19709717]\n",
      " [ 1.70442101]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  529\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.98283751]\n",
      " [11.40037325]\n",
      " [18.01509145]\n",
      " [17.56148458]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.11716249]\n",
      " [ 1.00037325]\n",
      " [-0.28490855]\n",
      " [-0.93851542]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01372705]\n",
      " [1.00074663]\n",
      " [0.08117288]\n",
      " [0.8808112 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.24705721998145236 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24079723]\n",
      " [ 3.87676722]\n",
      " [ 3.19953808]\n",
      " [ 1.70386942]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  530\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.98394666]\n",
      " [11.39801826]\n",
      " [18.01685221]\n",
      " [17.56437178]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.11605334]\n",
      " [ 0.99801826]\n",
      " [-0.28314779]\n",
      " [-0.93562822]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01346838]\n",
      " [0.99604045]\n",
      " [0.08017267]\n",
      " [0.87540016]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.24563520725598897 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24163926]\n",
      " [ 3.87945407]\n",
      " [ 3.20197104]\n",
      " [ 1.70331757]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  531\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.9850455 ]\n",
      " [11.39566505]\n",
      " [18.01859968]\n",
      " [17.5672468 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.1149545 ]\n",
      " [ 0.99566505]\n",
      " [-0.28140032]\n",
      " [-0.9327532 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01321454]\n",
      " [0.99134889]\n",
      " [0.07918614]\n",
      " [0.87002854]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.24422226367595876 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24247286]\n",
      " [ 3.88213387]\n",
      " [ 3.20439608]\n",
      " [ 1.70276546]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  532\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.98613413]\n",
      " [11.39331367]\n",
      " [18.02033396]\n",
      " [17.57010971]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.11386587]\n",
      " [ 0.99331367]\n",
      " [-0.27966604]\n",
      " [-0.92989029]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01296544]\n",
      " [0.98667204]\n",
      " [0.0782131 ]\n",
      " [0.86469595]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.24281831566551126 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24329814]\n",
      " [ 3.88480662]\n",
      " [ 3.20681324]\n",
      " [ 1.70221309]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  533\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.98721263]\n",
      " [11.39096415]\n",
      " [18.02205516]\n",
      " [17.5729606 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.11278737]\n",
      " [ 0.99096415]\n",
      " [-0.27794484]\n",
      " [-0.9270394 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01272099]\n",
      " [0.98200995]\n",
      " [0.07725333]\n",
      " [0.85940205]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.24142329050496397 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24411515]\n",
      " [ 3.88747236]\n",
      " [ 3.20922254]\n",
      " [ 1.7016605 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  534\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.98828111]\n",
      " [11.38861656]\n",
      " [18.0237634 ]\n",
      " [17.57579955]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.11171889]\n",
      " [ 0.98861656]\n",
      " [-0.2762366 ]\n",
      " [-0.92420045]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01248111]\n",
      " [0.97736269]\n",
      " [0.07630666]\n",
      " [0.85414647]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.24003711631739044 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.244924  ]\n",
      " [ 3.8901311 ]\n",
      " [ 3.21162402]\n",
      " [ 1.70110768]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  535\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.98933967]\n",
      " [11.38627092]\n",
      " [18.02545878]\n",
      " [17.57862665]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.11066033]\n",
      " [ 0.98627092]\n",
      " [-0.27454122]\n",
      " [-0.92137335]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01224571]\n",
      " [0.97273033]\n",
      " [0.07537288]\n",
      " [0.84892886]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.23865972205545438 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24572476]\n",
      " [ 3.89278285]\n",
      " [ 3.2140177 ]\n",
      " [ 1.70055464]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  536\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99038839]\n",
      " [11.38392729]\n",
      " [18.02714141]\n",
      " [17.58144196]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10961161]\n",
      " [ 0.98392729]\n",
      " [-0.27285859]\n",
      " [-0.91855804]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01201471]\n",
      " [0.96811292]\n",
      " [0.07445181]\n",
      " [0.84374887]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.23729103748848857 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24651752]\n",
      " [ 3.89542763]\n",
      " [ 3.2164036 ]\n",
      " [ 1.70000141]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  537\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99142736]\n",
      " [11.38158571]\n",
      " [18.02881141]\n",
      " [17.58424558]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10857264]\n",
      " [ 0.98158571]\n",
      " [-0.27118859]\n",
      " [-0.91575442]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01178802]\n",
      " [0.96351051]\n",
      " [0.07354325]\n",
      " [0.83860616]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2359309931897918 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24730234]\n",
      " [ 3.89806546]\n",
      " [ 3.21878177]\n",
      " [ 1.69944799]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  538\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99245669]\n",
      " [11.37924623]\n",
      " [18.03046887]\n",
      " [17.58703757]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10754331]\n",
      " [ 0.97924623]\n",
      " [-0.26953113]\n",
      " [-0.91296243]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01156556]\n",
      " [0.95892318]\n",
      " [0.07264703]\n",
      " [0.83350039]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.23457952052416953 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24807932]\n",
      " [ 3.90069636]\n",
      " [ 3.22115223]\n",
      " [ 1.69889439]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  539\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99347646]\n",
      " [11.37690888]\n",
      " [18.03211391]\n",
      " [17.58981802]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10652354]\n",
      " [ 0.97690888]\n",
      " [-0.26788609]\n",
      " [-0.91018198]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01134727]\n",
      " [0.95435096]\n",
      " [0.07176296]\n",
      " [0.82843123]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2332365516356968 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24884852]\n",
      " [ 3.90332034]\n",
      " [ 3.22351501]\n",
      " [ 1.69834062]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  540\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99448675]\n",
      " [11.37457371]\n",
      " [18.03374662]\n",
      " [17.59258701]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10551325]\n",
      " [ 0.97457371]\n",
      " [-0.26625338]\n",
      " [-0.90741299]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01113305]\n",
      " [0.94979392]\n",
      " [0.07089086]\n",
      " [0.82339833]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.23190201943569266 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.24961004]\n",
      " [ 3.90593743]\n",
      " [ 3.22587013]\n",
      " [ 1.6977867 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  541\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99548767]\n",
      " [11.37224076]\n",
      " [18.03536712]\n",
      " [17.59534461]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10451233]\n",
      " [ 0.97224076]\n",
      " [-0.26463288]\n",
      " [-0.90465539]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01092283]\n",
      " [0.94525209]\n",
      " [0.07003056]\n",
      " [0.81840138]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.23057585759092414 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25036394]\n",
      " [ 3.90854763]\n",
      " [ 3.22821763]\n",
      " [ 1.69723263]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  542\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99647929]\n",
      " [11.36991007]\n",
      " [18.0369755 ]\n",
      " [17.59809089]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10352071]\n",
      " [ 0.96991007]\n",
      " [-0.2630245 ]\n",
      " [-0.90190911]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01071654]\n",
      " [0.94072554]\n",
      " [0.06918189]\n",
      " [0.81344004]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.22925800051201617 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2511103 ]\n",
      " [ 3.91115096]\n",
      " [ 3.23055753]\n",
      " [ 1.69667843]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  543\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99746171]\n",
      " [11.36758168]\n",
      " [18.03857187]\n",
      " [17.60082594]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10253829]\n",
      " [ 0.96758168]\n",
      " [-0.26142813]\n",
      " [-0.89917406]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0105141 ]\n",
      " [0.9362143 ]\n",
      " [0.06834467]\n",
      " [0.80851399]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.22794838334206374 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2518492 ]\n",
      " [ 3.91374745]\n",
      " [ 3.23288986]\n",
      " [ 1.69612411]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  544\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99843501]\n",
      " [11.36525563]\n",
      " [18.04015632]\n",
      " [17.60354982]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10156499]\n",
      " [ 0.96525563]\n",
      " [-0.25984368]\n",
      " [-0.89645018]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.01031545]\n",
      " [0.93171843]\n",
      " [0.06751874]\n",
      " [0.80362292]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.22664694194546595 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2525807 ]\n",
      " [ 3.91633711]\n",
      " [ 3.23521465]\n",
      " [ 1.69556968]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  545\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[21.99939928]\n",
      " [11.36293196]\n",
      " [18.04172897]\n",
      " [17.60626261]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.10060072]\n",
      " [ 0.96293196]\n",
      " [-0.25827103]\n",
      " [-0.89373739]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0101205 ]\n",
      " [0.92723795]\n",
      " [0.06670393]\n",
      " [0.79876652]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.22535361289693795 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2533049 ]\n",
      " [ 3.91891996]\n",
      " [ 3.23753193]\n",
      " [ 1.69501515]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  546\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0003546 ]\n",
      " [11.3606107 ]\n",
      " [18.0432899 ]\n",
      " [17.60896439]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0996454 ]\n",
      " [ 0.9606107 ]\n",
      " [-0.2567101 ]\n",
      " [-0.89103561]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00992921]\n",
      " [0.92277292]\n",
      " [0.06590008]\n",
      " [0.79394446]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2240683334707369 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25402185]\n",
      " [ 3.92149601]\n",
      " [ 3.23984173]\n",
      " [ 1.69446052]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  547\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00130106]\n",
      " [11.3582919 ]\n",
      " [18.04483921]\n",
      " [17.61165522]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09869894]\n",
      " [ 0.9582919 ]\n",
      " [-0.25516079]\n",
      " [-0.88834478]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00974148]\n",
      " [0.91832337]\n",
      " [0.06510703]\n",
      " [0.78915646]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.22279104163007502 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25473163]\n",
      " [ 3.92406528]\n",
      " [ 3.24214406]\n",
      " [ 1.69390582]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  548\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00223874]\n",
      " [11.35597559]\n",
      " [18.04637701]\n",
      " [17.61433517]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09776126]\n",
      " [ 0.95597559]\n",
      " [-0.25362299]\n",
      " [-0.88566483]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00955726]\n",
      " [0.91388934]\n",
      " [0.06432462]\n",
      " [0.78440219]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2215216760167164 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25543431]\n",
      " [ 3.92662779]\n",
      " [ 3.24443897]\n",
      " [ 1.69335105]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  549\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00316772]\n",
      " [11.35366181]\n",
      " [18.04790339]\n",
      " [17.61700433]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09683228]\n",
      " [ 0.95366181]\n",
      " [-0.25209661]\n",
      " [-0.88299567]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00937649]\n",
      " [0.90947086]\n",
      " [0.0635527 ]\n",
      " [0.77968136]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.22026017594077096 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25612997]\n",
      " [ 3.92918355]\n",
      " [ 3.24672648]\n",
      " [ 1.69279622]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  550\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00408808]\n",
      " [11.3513506 ]\n",
      " [18.04941845]\n",
      " [17.61966275]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09591192]\n",
      " [ 0.9513506 ]\n",
      " [-0.25058155]\n",
      " [-0.88033725]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0091991 ]\n",
      " [0.90506796]\n",
      " [0.06279111]\n",
      " [0.77499368]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.21900648137066148 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25681867]\n",
      " [ 3.93173259]\n",
      " [ 3.24900661]\n",
      " [ 1.69224134]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  551\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00499991]\n",
      " [11.34904198]\n",
      " [18.05092228]\n",
      " [17.62231051]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09500009]\n",
      " [ 0.94904198]\n",
      " [-0.24907772]\n",
      " [-0.87768949]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00902502]\n",
      " [0.90068069]\n",
      " [0.06203971]\n",
      " [0.77033885]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2177605329232681 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25750048]\n",
      " [ 3.93427491]\n",
      " [ 3.2512794 ]\n",
      " [ 1.69168642]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  552\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00590329]\n",
      " [11.346736  ]\n",
      " [18.05241497]\n",
      " [17.62494767]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09409671]\n",
      " [ 0.946736  ]\n",
      " [-0.24758503]\n",
      " [-0.87505233]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00885419]\n",
      " [0.89630906]\n",
      " [0.06129835]\n",
      " [0.76571657]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2165222718542572 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25817548]\n",
      " [ 3.93681054]\n",
      " [ 3.25354486]\n",
      " [ 1.69113147]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  553\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00679829]\n",
      " [11.34443269]\n",
      " [18.05389662]\n",
      " [17.62757432]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09320171]\n",
      " [ 0.94443269]\n",
      " [-0.24610338]\n",
      " [-0.87242568]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00868656]\n",
      " [0.89195311]\n",
      " [0.06056688]\n",
      " [0.76112657]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.21529164004857176 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25884372]\n",
      " [ 3.93933948]\n",
      " [ 3.25580303]\n",
      " [ 1.69057651]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  554\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.007685  ]\n",
      " [11.34213208]\n",
      " [18.05536731]\n",
      " [17.6301905 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.092315  ]\n",
      " [ 0.94213208]\n",
      " [-0.24463269]\n",
      " [-0.8698095 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00852206]\n",
      " [0.88761287]\n",
      " [0.05984515]\n",
      " [0.75656856]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2140685800110963 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.25950529]\n",
      " [ 3.94186177]\n",
      " [ 3.25805394]\n",
      " [ 1.69002154]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  555\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00856348]\n",
      " [11.33983421]\n",
      " [18.05682716]\n",
      " [17.6327963 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09143652]\n",
      " [ 0.93983421]\n",
      " [-0.24317284]\n",
      " [-0.8672037 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00836064]\n",
      " [0.88328835]\n",
      " [0.05913303]\n",
      " [0.75204226]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.21285303485749 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26016023]\n",
      " [ 3.94437741]\n",
      " [ 3.2602976 ]\n",
      " [ 1.68946656]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  556\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.00943383]\n",
      " [11.33753911]\n",
      " [18.05827623]\n",
      " [17.63539177]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.09056617]\n",
      " [ 0.93753911]\n",
      " [-0.24172377]\n",
      " [-0.86460823]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00820223]\n",
      " [0.87897958]\n",
      " [0.05843038]\n",
      " [0.74754739]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.21164494830516967 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26080863]\n",
      " [ 3.94688643]\n",
      " [ 3.26253406]\n",
      " [ 1.6889116 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  557\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01029611]\n",
      " [11.33524681]\n",
      " [18.05971462]\n",
      " [17.63797699]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08970389]\n",
      " [ 0.93524681]\n",
      " [-0.24028538]\n",
      " [-0.86202301]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00804679]\n",
      " [0.87468659]\n",
      " [0.05773706]\n",
      " [0.74308367]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.21044426466446678 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26145055]\n",
      " [ 3.94938883]\n",
      " [ 3.26476332]\n",
      " [ 1.68835666]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  558\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0111504 ]\n",
      " [11.33295734]\n",
      " [18.06114243]\n",
      " [17.64055201]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0888496 ]\n",
      " [ 0.93295734]\n",
      " [-0.23885757]\n",
      " [-0.85944799]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00789425]\n",
      " [0.8704094 ]\n",
      " [0.05705294]\n",
      " [0.73865084]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2092509288299333 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26208604]\n",
      " [ 3.95188463]\n",
      " [ 3.26698543]\n",
      " [ 1.68780175]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  559\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01199677]\n",
      " [11.33067074]\n",
      " [18.06255974]\n",
      " [17.64311691]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08800323]\n",
      " [ 0.93067074]\n",
      " [-0.23744026]\n",
      " [-0.85688309]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00774457]\n",
      " [0.86614802]\n",
      " [0.05637788]\n",
      " [0.73424863]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.20806488627179553 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26271518]\n",
      " [ 3.95437386]\n",
      " [ 3.26920041]\n",
      " [ 1.68724688]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  560\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01283531]\n",
      " [11.32838703]\n",
      " [18.06396663]\n",
      " [17.64567175]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08716469]\n",
      " [ 0.92838703]\n",
      " [-0.23603337]\n",
      " [-0.85432825]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00759768]\n",
      " [0.86190247]\n",
      " [0.05571175]\n",
      " [0.72987676]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.20688608302757122 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26333803]\n",
      " [ 3.95685653]\n",
      " [ 3.27140827]\n",
      " [ 1.68669205]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  561\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01366608]\n",
      " [11.32610624]\n",
      " [18.0653632 ]\n",
      " [17.64821659]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08633392]\n",
      " [ 0.92610624]\n",
      " [-0.2346368 ]\n",
      " [-0.85178341]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00745355]\n",
      " [0.85767277]\n",
      " [0.05505443]\n",
      " [0.72553498]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2057144656938238 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26395465]\n",
      " [ 3.95933265]\n",
      " [ 3.27360906]\n",
      " [ 1.68613729]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  562\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01448915]\n",
      " [11.32382841]\n",
      " [18.06674953]\n",
      " [17.65075149]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08551085]\n",
      " [ 0.92382841]\n",
      " [-0.23325047]\n",
      " [-0.84924851]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0073121 ]\n",
      " [0.85345894]\n",
      " [0.05440578]\n",
      " [0.72122303]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2045499814180604 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2645651 ]\n",
      " [ 3.96180224]\n",
      " [ 3.27580279]\n",
      " [ 1.68558259]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  563\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01530461]\n",
      " [11.32155357]\n",
      " [18.06812571]\n",
      " [17.65327652]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08469539]\n",
      " [ 0.92155357]\n",
      " [-0.23187429]\n",
      " [-0.84672348]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00717331]\n",
      " [0.84926098]\n",
      " [0.05376569]\n",
      " [0.71694065]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2033925778907859 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26516945]\n",
      " [ 3.96426531]\n",
      " [ 3.27798949]\n",
      " [ 1.68502797]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  564\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01611251]\n",
      " [11.31928174]\n",
      " [18.06949181]\n",
      " [17.65579174]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08388749]\n",
      " [ 0.91928174]\n",
      " [-0.23050819]\n",
      " [-0.84420826]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00703711]\n",
      " [0.84507891]\n",
      " [0.05313403]\n",
      " [0.71268758]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.2022422033376733 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26576776]\n",
      " [ 3.96672189]\n",
      " [ 3.28016919]\n",
      " [ 1.68447343]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  565\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01691294]\n",
      " [11.31701294]\n",
      " [18.07084793]\n",
      " [17.65829721]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08308706]\n",
      " [ 0.91701294]\n",
      " [-0.22915207]\n",
      " [-0.84170279]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00690346]\n",
      " [0.84091274]\n",
      " [0.05251067]\n",
      " [0.70846358]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.201098806511891 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26636008]\n",
      " [ 3.96917199]\n",
      " [ 3.28234191]\n",
      " [ 1.68391899]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  566\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01770595]\n",
      " [11.31474722]\n",
      " [18.07219414]\n",
      " [17.660793  ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08229405]\n",
      " [ 0.91474722]\n",
      " [-0.22780586]\n",
      " [-0.839207  ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00677231]\n",
      " [0.83676248]\n",
      " [0.05189551]\n",
      " [0.7042684 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1999623366865554 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26694648]\n",
      " [ 3.97161563]\n",
      " [ 3.28450768]\n",
      " [ 1.68336465]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  567\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01849163]\n",
      " [11.31248459]\n",
      " [18.07353054]\n",
      " [17.66327915]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08150837]\n",
      " [ 0.91248459]\n",
      " [-0.22646946]\n",
      " [-0.83672085]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00664361]\n",
      " [0.83262814]\n",
      " [0.05128842]\n",
      " [0.70010178]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1988327436473154 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26752701]\n",
      " [ 3.97405281]\n",
      " [ 3.28666652]\n",
      " [ 1.68281042]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  568\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.01927003]\n",
      " [11.31022509]\n",
      " [18.07485719]\n",
      " [17.66575574]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.08072997]\n",
      " [ 0.91022509]\n",
      " [-0.22514281]\n",
      " [-0.83424426]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00651733]\n",
      " [0.82850972]\n",
      " [0.05068929]\n",
      " [0.69596349]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1977099776850646 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26810174]\n",
      " [ 3.97648357]\n",
      " [ 3.28881846]\n",
      " [ 1.68225631]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  569\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02004123]\n",
      " [11.30796874]\n",
      " [18.07617418]\n",
      " [17.66822281]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07995877]\n",
      " [ 0.90796874]\n",
      " [-0.22382582]\n",
      " [-0.83177719]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0063934 ]\n",
      " [0.82440723]\n",
      " [0.050098  ]\n",
      " [0.69185329]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.19659398958878305 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26867072]\n",
      " [ 3.97890791]\n",
      " [ 3.29096352]\n",
      " [ 1.68170233]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  570\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0208053 ]\n",
      " [11.30571556]\n",
      " [18.0774816 ]\n",
      " [17.67068044]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0791947 ]\n",
      " [ 0.90571556]\n",
      " [-0.2225184 ]\n",
      " [-0.82931956]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0062718 ]\n",
      " [0.82032067]\n",
      " [0.04951444]\n",
      " [0.68777093]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.19548473063850302 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26923402]\n",
      " [ 3.98132585]\n",
      " [ 3.29310173]\n",
      " [ 1.68114849]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  571\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0215623 ]\n",
      " [11.30346558]\n",
      " [18.07877952]\n",
      " [17.67312867]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0784377 ]\n",
      " [ 0.90346558]\n",
      " [-0.22122048]\n",
      " [-0.82687133]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00615247]\n",
      " [0.81625006]\n",
      " [0.0489385 ]\n",
      " [0.68371619]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.19438215259839636 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.26979168]\n",
      " [ 3.9837374 ]\n",
      " [ 3.29523312]\n",
      " [ 1.68059479]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  572\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02231229]\n",
      " [11.30121883]\n",
      " [18.08006801]\n",
      " [17.67556758]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07768771]\n",
      " [ 0.90121883]\n",
      " [-0.21993199]\n",
      " [-0.82443242]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00603538]\n",
      " [0.81219538]\n",
      " [0.04837008]\n",
      " [0.67968882]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.19328620770997496 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27034376]\n",
      " [ 3.98614259]\n",
      " [ 3.2973577 ]\n",
      " [ 1.68004124]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  573\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02305535]\n",
      " [11.29897533]\n",
      " [18.08134716]\n",
      " [17.6779972 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07694465]\n",
      " [ 0.89897533]\n",
      " [-0.21865284]\n",
      " [-0.8220028 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00592048]\n",
      " [0.80815664]\n",
      " [0.04780906]\n",
      " [0.6756886 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.19219684868541892 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27089032]\n",
      " [ 3.98854143]\n",
      " [ 3.29947551]\n",
      " [ 1.67948786]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  574\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02379154]\n",
      " [11.2967351 ]\n",
      " [18.08261705]\n",
      " [17.6804176 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07620846]\n",
      " [ 0.8967351 ]\n",
      " [-0.21738295]\n",
      " [-0.8195824 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00580773]\n",
      " [0.80413385]\n",
      " [0.04725535]\n",
      " [0.67171531]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.19111402870101452 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27143142]\n",
      " [ 3.99093393]\n",
      " [ 3.30158657]\n",
      " [ 1.67893465]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  575\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02452092]\n",
      " [11.29449818]\n",
      " [18.08387775]\n",
      " [17.68282884]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07547908]\n",
      " [ 0.89449818]\n",
      " [-0.21612225]\n",
      " [-0.81717116]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00569709]\n",
      " [0.80012699]\n",
      " [0.04670883]\n",
      " [0.6677687 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.19003770139070464 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27196711]\n",
      " [ 3.99332011]\n",
      " [ 3.30369089]\n",
      " [ 1.67838162]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  576\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02524355]\n",
      " [11.29226457]\n",
      " [18.08512933]\n",
      " [17.68523097]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07475645]\n",
      " [ 0.89226457]\n",
      " [-0.21487067]\n",
      " [-0.81476903]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00558853]\n",
      " [0.79613607]\n",
      " [0.04616941]\n",
      " [0.66384857]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.18896782083975006 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27249743]\n",
      " [ 3.99569999]\n",
      " [ 3.30578852]\n",
      " [ 1.67782877]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  577\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0259595 ]\n",
      " [11.29003431]\n",
      " [18.08637187]\n",
      " [17.68762405]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0740405 ]\n",
      " [ 0.89003431]\n",
      " [-0.21362813]\n",
      " [-0.81237595]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.005482  ]\n",
      " [0.79216108]\n",
      " [0.04563698]\n",
      " [0.65995468]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.18790434157850067 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27302246]\n",
      " [ 3.99807358]\n",
      " [ 3.30787946]\n",
      " [ 1.67727612]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  578\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02666884]\n",
      " [11.28780742]\n",
      " [18.08760546]\n",
      " [17.69000813]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07333116]\n",
      " [ 0.88780742]\n",
      " [-0.21239454]\n",
      " [-0.80999187]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00537746]\n",
      " [0.78820201]\n",
      " [0.04511144]\n",
      " [0.65608683]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.186847218576276 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27354224]\n",
      " [ 4.0004409 ]\n",
      " [ 3.30996376]\n",
      " [ 1.67672367]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  579\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02737161]\n",
      " [11.28558392]\n",
      " [18.08883015]\n",
      " [17.69238326]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07262839]\n",
      " [ 0.88558392]\n",
      " [-0.21116985]\n",
      " [-0.80761674]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00527488]\n",
      " [0.78425888]\n",
      " [0.04459271]\n",
      " [0.65224479]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1857964072353417 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27405681]\n",
      " [ 4.00280196]\n",
      " [ 3.31204142]\n",
      " [ 1.67617144]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  580\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02806789]\n",
      " [11.28336383]\n",
      " [18.09004602]\n",
      " [17.69474951]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07193211]\n",
      " [ 0.88336383]\n",
      " [-0.20995398]\n",
      " [-0.80525049]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00517423]\n",
      " [0.78033165]\n",
      " [0.04408067]\n",
      " [0.64842836]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1847518633849985 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27456624]\n",
      " [ 4.00515679]\n",
      " [ 3.31411247]\n",
      " [ 1.67561942]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  581\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02875774]\n",
      " [11.28114717]\n",
      " [18.09125316]\n",
      " [17.69710691]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07124226]\n",
      " [ 0.88114717]\n",
      " [-0.20874684]\n",
      " [-0.80289309]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00507546]\n",
      " [0.77642033]\n",
      " [0.04357525]\n",
      " [0.64463731]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.18371354327576467 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27507058]\n",
      " [ 4.00750538]\n",
      " [ 3.31617695]\n",
      " [ 1.67506762]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  582\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.02944121]\n",
      " [11.27893397]\n",
      " [18.09245161]\n",
      " [17.69945554]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.07055879]\n",
      " [ 0.87893397]\n",
      " [-0.20754839]\n",
      " [-0.80054446]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00497854]\n",
      " [0.77252492]\n",
      " [0.04307633]\n",
      " [0.64087144]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.18268140357366616 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27556988]\n",
      " [ 4.00984777]\n",
      " [ 3.31823486]\n",
      " [ 1.67451606]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  583\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03011837]\n",
      " [11.27672424]\n",
      " [18.09364147]\n",
      " [17.70179543]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06988163]\n",
      " [ 0.87672424]\n",
      " [-0.20635853]\n",
      " [-0.79820457]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00488344]\n",
      " [0.76864539]\n",
      " [0.04258384]\n",
      " [0.63713054]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.18165540135461244 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27606418]\n",
      " [ 4.01218397]\n",
      " [ 3.32028624]\n",
      " [ 1.67396474]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  584\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03078927]\n",
      " [11.274518  ]\n",
      " [18.0948228 ]\n",
      " [17.70412664]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06921073]\n",
      " [ 0.874518  ]\n",
      " [-0.2051772 ]\n",
      " [-0.79587336]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00479012]\n",
      " [0.76478173]\n",
      " [0.04209768]\n",
      " [0.63341441]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.18063549409887475 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27655354]\n",
      " [ 4.01451399]\n",
      " [ 3.32233111]\n",
      " [ 1.67341366]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  585\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03145398]\n",
      " [11.27231528]\n",
      " [18.09599567]\n",
      " [17.70644922]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06854602]\n",
      " [ 0.87231528]\n",
      " [-0.20400433]\n",
      " [-0.79355078]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00469856]\n",
      " [0.76093395]\n",
      " [0.04161777]\n",
      " [0.62972284]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17962163968565625 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.277038  ]\n",
      " [ 4.01683784]\n",
      " [ 3.32436949]\n",
      " [ 1.67286284]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  586\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03211254]\n",
      " [11.27011609]\n",
      " [18.09716015]\n",
      " [17.70876322]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06788746]\n",
      " [ 0.87011609]\n",
      " [-0.20283985]\n",
      " [-0.79123678]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00460871]\n",
      " [0.75710202]\n",
      " [0.04114401]\n",
      " [0.62605564]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1786137963877577 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27751762]\n",
      " [ 4.01915555]\n",
      " [ 3.32640141]\n",
      " [ 1.67231229]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  587\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03276502]\n",
      " [11.26792046]\n",
      " [18.0983163 ]\n",
      " [17.7110687 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06723498]\n",
      " [ 0.86792046]\n",
      " [-0.2016837 ]\n",
      " [-0.7889313 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00452054]\n",
      " [0.75328593]\n",
      " [0.04067631]\n",
      " [0.6224126 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17761192286632466 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27799244]\n",
      " [ 4.02146713]\n",
      " [ 3.32842688]\n",
      " [ 1.671762  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  588\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03341148]\n",
      " [11.2657284 ]\n",
      " [18.09946421]\n",
      " [17.7133657 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06658852]\n",
      " [ 0.8657284 ]\n",
      " [-0.20053579]\n",
      " [-0.7866343 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00443403]\n",
      " [0.74948566]\n",
      " [0.0402146 ]\n",
      " [0.61879353]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17661597816568914 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27846252]\n",
      " [ 4.02377259]\n",
      " [ 3.33044594]\n",
      " [ 1.67121199]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  589\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03405196]\n",
      " [11.26353993]\n",
      " [18.10060392]\n",
      " [17.71565427]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06594804]\n",
      " [ 0.86353993]\n",
      " [-0.19939608]\n",
      " [-0.78434573]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00434914]\n",
      " [0.74570121]\n",
      " [0.0397588 ]\n",
      " [0.61519823]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17562592170829747 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27892789]\n",
      " [ 4.02607195]\n",
      " [ 3.3324586 ]\n",
      " [ 1.67066227]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  590\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03468653]\n",
      " [11.26135507]\n",
      " [18.10173552]\n",
      " [17.71793446]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06531347]\n",
      " [ 0.86135507]\n",
      " [-0.19826448]\n",
      " [-0.78206554]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00426585]\n",
      " [0.74193255]\n",
      " [0.0393088 ]\n",
      " [0.6116265 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17464171328972267 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27938862]\n",
      " [ 4.02836523]\n",
      " [ 3.3344649 ]\n",
      " [ 1.67011283]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  591\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03531524]\n",
      " [11.25917383]\n",
      " [18.10285906]\n",
      " [17.72020633]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06468476]\n",
      " [ 0.85917383]\n",
      " [-0.19714094]\n",
      " [-0.77979367]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00418412]\n",
      " [0.73817967]\n",
      " [0.03886455]\n",
      " [0.60807817]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17366331307375787 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.27984473]\n",
      " [ 4.03065244]\n",
      " [ 3.33646484]\n",
      " [ 1.6695637 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  592\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03593815]\n",
      " [11.25699623]\n",
      " [18.10397462]\n",
      " [17.72246991]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06406185]\n",
      " [ 0.85699623]\n",
      " [-0.19602538]\n",
      " [-0.77753009]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00410392]\n",
      " [0.73444254]\n",
      " [0.03842595]\n",
      " [0.60455304]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17269068158759823 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28029628]\n",
      " [ 4.03293359]\n",
      " [ 3.33845846]\n",
      " [ 1.66901487]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  593\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03655531]\n",
      " [11.2548223 ]\n",
      " [18.10508226]\n",
      " [17.72472526]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06344469]\n",
      " [ 0.8548223 ]\n",
      " [-0.19491774]\n",
      " [-0.77527474]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00402523]\n",
      " [0.73072116]\n",
      " [0.03799293]\n",
      " [0.60105092]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17172377971709285 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28074332]\n",
      " [ 4.03520871]\n",
      " [ 3.34044577]\n",
      " [ 1.66846635]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  594\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03716677]\n",
      " [11.25265204]\n",
      " [18.10618204]\n",
      " [17.72697243]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06283323]\n",
      " [ 0.85265204]\n",
      " [-0.19381796]\n",
      " [-0.77302757]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00394801]\n",
      " [0.7270155 ]\n",
      " [0.0375654 ]\n",
      " [0.59757163]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.17076256870208617 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28118589]\n",
      " [ 4.0374778 ]\n",
      " [ 3.34242681]\n",
      " [ 1.66791814]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  595\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03777259]\n",
      " [11.25048548]\n",
      " [18.10727402]\n",
      " [17.72921146]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06222741]\n",
      " [ 0.85048548]\n",
      " [-0.19272598]\n",
      " [-0.77078854]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00387225]\n",
      " [0.72332555]\n",
      " [0.0371433 ]\n",
      " [0.59411498]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.16980701013182986 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28162403]\n",
      " [ 4.03974089]\n",
      " [ 3.34440159]\n",
      " [ 1.66737027]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  596\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03837282]\n",
      " [11.24832262]\n",
      " [18.10835828]\n",
      " [17.73144239]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06162718]\n",
      " [ 0.84832262]\n",
      " [-0.19164172]\n",
      " [-0.76855761]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00379791]\n",
      " [0.71965127]\n",
      " [0.03672655]\n",
      " [0.5906808 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.16885706594047722 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28205779]\n",
      " [ 4.04199798]\n",
      " [ 3.34637013]\n",
      " [ 1.66682272]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  597\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03896751]\n",
      " [11.24616349]\n",
      " [18.10943487]\n",
      " [17.73366528]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06103249]\n",
      " [ 0.84616349]\n",
      " [-0.19056513]\n",
      " [-0.76633472]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00372496]\n",
      " [0.71599265]\n",
      " [0.03631507]\n",
      " [0.5872689 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.16791269840264145 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28248721]\n",
      " [ 4.04424909]\n",
      " [ 3.34833246]\n",
      " [ 1.66627552]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  598\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.03955671]\n",
      " [11.2440081 ]\n",
      " [18.11050385]\n",
      " [17.73588017]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.06044329]\n",
      " [ 0.8440081 ]\n",
      " [-0.18949615]\n",
      " [-0.76411983]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00365339]\n",
      " [0.71234967]\n",
      " [0.03590879]\n",
      " [0.58387911]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.16697387012904005 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28291234]\n",
      " [ 4.04649424]\n",
      " [ 3.3502886 ]\n",
      " [ 1.66572866]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  599\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04014048]\n",
      " [11.24185646]\n",
      " [18.1115653 ]\n",
      " [17.73808711]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05985952]\n",
      " [ 0.84185646]\n",
      " [-0.1884347 ]\n",
      " [-0.76191289]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00358316]\n",
      " [0.7087223 ]\n",
      " [0.03550764]\n",
      " [0.58051125]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1660405440622013 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28333321]\n",
      " [ 4.04873344]\n",
      " [ 3.35223857]\n",
      " [ 1.66518214]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  600\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04071886]\n",
      " [11.23970859]\n",
      " [18.11261926]\n",
      " [17.74028614]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05928114]\n",
      " [ 0.83970859]\n",
      " [-0.18738074]\n",
      " [-0.75971386]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00351425]\n",
      " [0.70511052]\n",
      " [0.03511154]\n",
      " [0.57716515]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1651126834722461 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28374988]\n",
      " [ 4.05096671]\n",
      " [ 3.35418239]\n",
      " [ 1.66463599]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  601\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04129191]\n",
      " [11.23756451]\n",
      " [18.1136658 ]\n",
      " [17.74247731]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05870809]\n",
      " [ 0.83756451]\n",
      " [-0.1863342 ]\n",
      " [-0.75752269]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00344664]\n",
      " [0.70151431]\n",
      " [0.03472043]\n",
      " [0.57384063]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1641902519527385 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28416238]\n",
      " [ 4.05319407]\n",
      " [ 3.35612009]\n",
      " [ 1.6640902 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  602\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04185967]\n",
      " [11.23542423]\n",
      " [18.11470499]\n",
      " [17.74466065]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05814033]\n",
      " [ 0.83542423]\n",
      " [-0.18529501]\n",
      " [-0.75533935]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0033803 ]\n",
      " [0.69793364]\n",
      " [0.03433424]\n",
      " [0.57053753]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.16327321341660206 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28457076]\n",
      " [ 4.05541552]\n",
      " [ 3.35805168]\n",
      " [ 1.66354478]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  603\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04242219]\n",
      " [11.23328775]\n",
      " [18.11573687]\n",
      " [17.74683622]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05757781]\n",
      " [ 0.83328775]\n",
      " [-0.18426313]\n",
      " [-0.75316378]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0033152 ]\n",
      " [0.69436848]\n",
      " [0.0339529 ]\n",
      " [0.56725567]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.16236153209210807 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28497505]\n",
      " [ 4.05763108]\n",
      " [ 3.3599772 ]\n",
      " [ 1.66299974]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  604\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04297953]\n",
      " [11.2311551 ]\n",
      " [18.11676151]\n",
      " [17.74900406]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05702047]\n",
      " [ 0.8311551 ]\n",
      " [-0.18323849]\n",
      " [-0.75099594]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00325133]\n",
      " [0.69081881]\n",
      " [0.03357634]\n",
      " [0.5639949 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1614551725189208 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2853753 ]\n",
      " [ 4.05984077]\n",
      " [ 3.36189666]\n",
      " [ 1.66245507]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  605\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04353172]\n",
      " [11.22902629]\n",
      " [18.11777897]\n",
      " [17.75116422]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05646828]\n",
      " [ 0.82902629]\n",
      " [-0.18222103]\n",
      " [-0.74883578]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00318867]\n",
      " [0.6872846 ]\n",
      " [0.0332045 ]\n",
      " [0.56075503]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1605540995442156 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28577155]\n",
      " [ 4.06204461]\n",
      " [ 3.36381007]\n",
      " [ 1.6619108 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  606\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04407883]\n",
      " [11.22690133]\n",
      " [18.11878931]\n",
      " [17.75331672]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05592117]\n",
      " [ 0.82690133]\n",
      " [-0.18121069]\n",
      " [-0.74668328]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00312718]\n",
      " [0.68376582]\n",
      " [0.03283731]\n",
      " [0.55753592]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15965827831885263 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28616383]\n",
      " [ 4.0642426 ]\n",
      " [ 3.36571748]\n",
      " [ 1.66136692]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  607\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04462089]\n",
      " [11.22478024]\n",
      " [18.11979258]\n",
      " [17.75546162]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05537911]\n",
      " [ 0.82478024]\n",
      " [-0.18020742]\n",
      " [-0.74453838]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00306685]\n",
      " [0.68026244]\n",
      " [0.03247471]\n",
      " [0.55433739]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1587676742936222 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28655219]\n",
      " [ 4.06643476]\n",
      " [ 3.36761889]\n",
      " [ 1.66082344]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  608\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04515795]\n",
      " [11.22266302]\n",
      " [18.12078884]\n",
      " [17.75759897]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05484205]\n",
      " [ 0.82266302]\n",
      " [-0.17921116]\n",
      " [-0.74240103]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00300765]\n",
      " [0.67677444]\n",
      " [0.03211664]\n",
      " [0.55115929]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15788225321554106 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28693667]\n",
      " [ 4.06862111]\n",
      " [ 3.36951432]\n",
      " [ 1.66028036]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  609\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04569006]\n",
      " [11.22054969]\n",
      " [18.12177815]\n",
      " [17.75972879]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05430994]\n",
      " [ 0.82054969]\n",
      " [-0.17822185]\n",
      " [-0.74027121]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00294957]\n",
      " [0.67330179]\n",
      " [0.03176303]\n",
      " [0.54800146]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15700198112421276 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28731731]\n",
      " [ 4.07080166]\n",
      " [ 3.3714038 ]\n",
      " [ 1.6597377 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  610\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04621727]\n",
      " [11.21844025]\n",
      " [18.12276056]\n",
      " [17.76185114]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05378273]\n",
      " [ 0.81844025]\n",
      " [-0.17723944]\n",
      " [-0.73814886]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00289258]\n",
      " [0.66984445]\n",
      " [0.03141382]\n",
      " [0.54486374]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1561268243482466 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28769413]\n",
      " [ 4.07297643]\n",
      " [ 3.37328736]\n",
      " [ 1.65919545]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  611\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04673962]\n",
      " [11.21633473]\n",
      " [18.12373613]\n",
      " [17.76396605]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05326038]\n",
      " [ 0.81633473]\n",
      " [-0.17626387]\n",
      " [-0.73603395]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00283667]\n",
      " [0.6664024 ]\n",
      " [0.03106895]\n",
      " [0.54174598]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1552567495017339 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28806719]\n",
      " [ 4.07514542]\n",
      " [ 3.375165  ]\n",
      " [ 1.65865363]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  612\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04725715]\n",
      " [11.21423313]\n",
      " [18.12470491]\n",
      " [17.76607356]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05274285]\n",
      " [ 0.81423313]\n",
      " [-0.17529509]\n",
      " [-0.73392644]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00278181]\n",
      " [0.6629756 ]\n",
      " [0.03072837]\n",
      " [0.53864802]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15439172348078561 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28843652]\n",
      " [ 4.07730867]\n",
      " [ 3.37703675]\n",
      " [ 1.65811223]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  613\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04776992]\n",
      " [11.21213547]\n",
      " [18.12566697]\n",
      " [17.76817372]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05223008]\n",
      " [ 0.81213547]\n",
      " [-0.17433303]\n",
      " [-0.73182628]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00272798]\n",
      " [0.65956402]\n",
      " [0.03039201]\n",
      " [0.5355697 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15353171346010813 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28880215]\n",
      " [ 4.07946617]\n",
      " [ 3.37890264]\n",
      " [ 1.65757127]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  614\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04827796]\n",
      " [11.21004175]\n",
      " [18.12662235]\n",
      " [17.77026657]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05172204]\n",
      " [ 0.81004175]\n",
      " [-0.17337765]\n",
      " [-0.72973343]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00267517]\n",
      " [0.65616763]\n",
      " [0.03005981]\n",
      " [0.53251088]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15267668688966082 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28916413]\n",
      " [ 4.08161795]\n",
      " [ 3.38076268]\n",
      " [ 1.65703075]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  615\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04878131]\n",
      " [11.20795198]\n",
      " [18.1275711 ]\n",
      " [17.77235214]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05121869]\n",
      " [ 0.80795198]\n",
      " [-0.1724289 ]\n",
      " [-0.72764786]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00262335]\n",
      " [0.6527864 ]\n",
      " [0.02973173]\n",
      " [0.52947141]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15182661149134047 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28952249]\n",
      " [ 4.08376402]\n",
      " [ 3.38261689]\n",
      " [ 1.65649067]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  616\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04928003]\n",
      " [11.20586618]\n",
      " [18.12851328]\n",
      " [17.77443047]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05071997]\n",
      " [ 0.80586618]\n",
      " [-0.17148672]\n",
      " [-0.72556953]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00257251]\n",
      " [0.64942029]\n",
      " [0.02940769]\n",
      " [0.52645114]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15098145525573742 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.28987727]\n",
      " [ 4.08590439]\n",
      " [ 3.3844653 ]\n",
      " [ 1.65595105]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  617\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.04977416]\n",
      " [11.20378435]\n",
      " [18.12944895]\n",
      " [17.77650161]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.05022584]\n",
      " [ 0.80378435]\n",
      " [-0.17055105]\n",
      " [-0.72349839]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00252264]\n",
      " [0.64606927]\n",
      " [0.02908766]\n",
      " [0.52344992]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.15014118643893096 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29022849]\n",
      " [ 4.08803908]\n",
      " [ 3.38630792]\n",
      " [ 1.65541188]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  618\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05026373]\n",
      " [11.2017065 ]\n",
      " [18.13037815]\n",
      " [17.77856559]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04973627]\n",
      " [ 0.8017065 ]\n",
      " [-0.16962185]\n",
      " [-0.72143441]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0024737 ]\n",
      " [0.64273331]\n",
      " [0.02877157]\n",
      " [0.52046761]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1493057735593429 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29057621]\n",
      " [ 4.09016811]\n",
      " [ 3.38814478]\n",
      " [ 1.65487317]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  619\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05074879]\n",
      " [11.19963265]\n",
      " [18.13130094]\n",
      " [17.78062245]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04925121]\n",
      " [ 0.79963265]\n",
      " [-0.16869906]\n",
      " [-0.71937755]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00242568]\n",
      " [0.63941237]\n",
      " [0.02845937]\n",
      " [0.51750406]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.148475185394637 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29092045]\n",
      " [ 4.09229148]\n",
      " [ 3.38997589]\n",
      " [ 1.65433492]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  620\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05122939]\n",
      " [11.1975628 ]\n",
      " [18.13221737]\n",
      " [17.78267223]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04877061]\n",
      " [ 0.7975628 ]\n",
      " [-0.16778263]\n",
      " [-0.71732777]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00237857]\n",
      " [0.63610641]\n",
      " [0.02815101]\n",
      " [0.51455913]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14764939097866644 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29126124]\n",
      " [ 4.09440921]\n",
      " [ 3.39180128]\n",
      " [ 1.65379715]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  621\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05170556]\n",
      " [11.19549696]\n",
      " [18.13312749]\n",
      " [17.78471496]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04829444]\n",
      " [ 0.79549696]\n",
      " [-0.16687251]\n",
      " [-0.71528504]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00233235]\n",
      " [0.63281541]\n",
      " [0.02784643]\n",
      " [0.51163268]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14682835959847432 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29159863]\n",
      " [ 4.09652132]\n",
      " [ 3.39362097]\n",
      " [ 1.65325985]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  622\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05217734]\n",
      " [11.19343514]\n",
      " [18.13403135]\n",
      " [17.78675069]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04782266]\n",
      " [ 0.79343514]\n",
      " [-0.16596865]\n",
      " [-0.71324931]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00228701]\n",
      " [0.62953931]\n",
      " [0.02754559]\n",
      " [0.50872457]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14601206079133572 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29193264]\n",
      " [ 4.09862782]\n",
      " [ 3.39543497]\n",
      " [ 1.65272304]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  623\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05264478]\n",
      " [11.19137734]\n",
      " [18.134929  ]\n",
      " [17.78877946]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04735522]\n",
      " [ 0.79137734]\n",
      " [-0.165071  ]\n",
      " [-0.71122054]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00224252]\n",
      " [0.6262781 ]\n",
      " [0.02724844]\n",
      " [0.50583466]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14520046434184816 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29226332]\n",
      " [ 4.10072873]\n",
      " [ 3.39724331]\n",
      " [ 1.65218671]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  624\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05310791]\n",
      " [11.18932359]\n",
      " [18.13582049]\n",
      " [17.79080129]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04689209]\n",
      " [ 0.78932359]\n",
      " [-0.16417951]\n",
      " [-0.70919871]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00219887]\n",
      " [0.62303172]\n",
      " [0.02695491]\n",
      " [0.50296282]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14439354027906665 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29259068]\n",
      " [ 4.10282405]\n",
      " [ 3.399046  ]\n",
      " [ 1.65165087]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  625\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05356678]\n",
      " [11.18727387]\n",
      " [18.13670586]\n",
      " [17.79281622]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04643322]\n",
      " [ 0.78727387]\n",
      " [-0.16329414]\n",
      " [-0.70718378]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00215604]\n",
      " [0.61980015]\n",
      " [0.02666498]\n",
      " [0.5001089 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14359125887368518 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29291478]\n",
      " [ 4.10491381]\n",
      " [ 3.40084307]\n",
      " [ 1.65111553]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  626\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05402142]\n",
      " [11.18522821]\n",
      " [18.13758518]\n",
      " [17.7948243 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04597858]\n",
      " [ 0.78522821]\n",
      " [-0.16241482]\n",
      " [-0.7051757 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00211403]\n",
      " [0.61658335]\n",
      " [0.02637857]\n",
      " [0.49727277]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14279359063525934 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29323563]\n",
      " [ 4.10699802]\n",
      " [ 3.40263454]\n",
      " [ 1.65058068]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  627\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05447188]\n",
      " [11.18318661]\n",
      " [18.13845848]\n",
      " [17.79682555]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04552812]\n",
      " [ 0.78318661]\n",
      " [-0.16154152]\n",
      " [-0.70317445]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00207281]\n",
      " [0.61338127]\n",
      " [0.02609566]\n",
      " [0.49445431]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14200050630947467 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29355327]\n",
      " [ 4.10907668]\n",
      " [ 3.40442042]\n",
      " [ 1.65004635]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  628\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05491819]\n",
      " [11.18114908]\n",
      " [18.13932582]\n",
      " [17.79882001]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04508181]\n",
      " [ 0.78114908]\n",
      " [-0.16067418]\n",
      " [-0.70117999]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00203237]\n",
      " [0.61019388]\n",
      " [0.02581619]\n",
      " [0.49165337]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.141211976875454 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29386774]\n",
      " [ 4.11114983]\n",
      " [ 3.40620074]\n",
      " [ 1.64951252]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  629\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05536039]\n",
      " [11.17911561]\n",
      " [18.14018723]\n",
      " [17.80080773]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04463961]\n",
      " [ 0.77911561]\n",
      " [-0.15981277]\n",
      " [-0.69919227]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0019927 ]\n",
      " [0.60702114]\n",
      " [0.02554012]\n",
      " [0.48886983]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.14042797354310899 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29417906]\n",
      " [ 4.11321746]\n",
      " [ 3.40797551]\n",
      " [ 1.64897921]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  630\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05579852]\n",
      " [11.17708623]\n",
      " [18.14104278]\n",
      " [17.80278873]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04420148]\n",
      " [ 0.77708623]\n",
      " [-0.15895722]\n",
      " [-0.69721127]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00195377]\n",
      " [0.60386301]\n",
      " [0.0252674 ]\n",
      " [0.48610356]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13964846775052878 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29448727]\n",
      " [ 4.1152796 ]\n",
      " [ 3.40974476]\n",
      " [ 1.64844642]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  631\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05623261]\n",
      " [11.17506094]\n",
      " [18.1418925 ]\n",
      " [17.80476304]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04376739]\n",
      " [ 0.77506094]\n",
      " [-0.1581075 ]\n",
      " [-0.69523696]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00191558]\n",
      " [0.60071945]\n",
      " [0.02499798]\n",
      " [0.48335443]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1388734311614145 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2947924 ]\n",
      " [ 4.11733625]\n",
      " [ 3.4115085 ]\n",
      " [ 1.64791415]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  632\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05666271]\n",
      " [11.17303973]\n",
      " [18.14273645]\n",
      " [17.80673071]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04333729]\n",
      " [ 0.77303973]\n",
      " [-0.15726355]\n",
      " [-0.69326929]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00187812]\n",
      " [0.59759043]\n",
      " [0.02473183]\n",
      " [0.48062231]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13810283566254883 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29509448]\n",
      " [ 4.11938744]\n",
      " [ 3.41326676]\n",
      " [ 1.64738241]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  633\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05708885]\n",
      " [11.17102263]\n",
      " [18.14357466]\n",
      " [17.80869176]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04291115]\n",
      " [ 0.77102263]\n",
      " [-0.15642534]\n",
      " [-0.69130824]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00184137]\n",
      " [0.59447589]\n",
      " [0.02446889]\n",
      " [0.47790708]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13733665336130238 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29539353]\n",
      " [ 4.12143317]\n",
      " [ 3.41501954]\n",
      " [ 1.64685121]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  634\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05751107]\n",
      " [11.16900963]\n",
      " [18.14440718]\n",
      " [17.81064624]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04248893]\n",
      " [ 0.76900963]\n",
      " [-0.15559282]\n",
      " [-0.68935376]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00180531]\n",
      " [0.59137581]\n",
      " [0.02420912]\n",
      " [0.47520861]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13657485658318022 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2956896 ]\n",
      " [ 4.12347346]\n",
      " [ 3.41676688]\n",
      " [ 1.64632054]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  635\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0579294 ]\n",
      " [11.16700074]\n",
      " [18.14523407]\n",
      " [17.81259417]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0420706 ]\n",
      " [ 0.76700074]\n",
      " [-0.15476593]\n",
      " [-0.68740583]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00176994]\n",
      " [0.58829014]\n",
      " [0.02395249]\n",
      " [0.47252677]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1358174178694106 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2959827 ]\n",
      " [ 4.12550833]\n",
      " [ 3.41850879]\n",
      " [ 1.64579042]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  636\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05834388]\n",
      " [11.16499597]\n",
      " [18.14605535]\n",
      " [17.81453559]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04165612]\n",
      " [ 0.76499597]\n",
      " [-0.15394465]\n",
      " [-0.68546441]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00173523]\n",
      " [0.58521884]\n",
      " [0.02369895]\n",
      " [0.46986146]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13506430997455815 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29627287]\n",
      " [ 4.12753778]\n",
      " [ 3.42024529]\n",
      " [ 1.64526084]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  637\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05875455]\n",
      " [11.16299532]\n",
      " [18.14687109]\n",
      " [17.81647053]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04124545]\n",
      " [ 0.76299532]\n",
      " [-0.15312891]\n",
      " [-0.68352947]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00170119]\n",
      " [0.58216186]\n",
      " [0.02344846]\n",
      " [0.46721254]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13431550586418456 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29656014]\n",
      " [ 4.12956184]\n",
      " [ 3.42197639]\n",
      " [ 1.64473181]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  638\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05916144]\n",
      " [11.1609988 ]\n",
      " [18.14768131]\n",
      " [17.81839902]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04083856]\n",
      " [ 0.7609988 ]\n",
      " [-0.15231869]\n",
      " [-0.68160098]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00166779]\n",
      " [0.57911917]\n",
      " [0.02320098]\n",
      " [0.46457989]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13357097871253903 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29684454]\n",
      " [ 4.13158051]\n",
      " [ 3.42370213]\n",
      " [ 1.64420333]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  639\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05956459]\n",
      " [11.15900641]\n",
      " [18.14848607]\n",
      " [17.82032111]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04043541]\n",
      " [ 0.75900641]\n",
      " [-0.15151393]\n",
      " [-0.67967889]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00163502]\n",
      " [0.57609072]\n",
      " [0.02295647]\n",
      " [0.4619634 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1328307019002828 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2971261 ]\n",
      " [ 4.13359381]\n",
      " [ 3.42542251]\n",
      " [ 1.64367541]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  640\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.05996402]\n",
      " [11.15701815]\n",
      " [18.14928541]\n",
      " [17.82223681]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.04003598]\n",
      " [ 0.75701815]\n",
      " [-0.15071459]\n",
      " [-0.67776319]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00160288]\n",
      " [0.57307648]\n",
      " [0.02271489]\n",
      " [0.45936295]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1320946490122502 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29740484]\n",
      " [ 4.13560176]\n",
      " [ 3.42713755]\n",
      " [ 1.64314806]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  641\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06035978]\n",
      " [11.15503403]\n",
      " [18.15007937]\n",
      " [17.82414616]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03964022]\n",
      " [ 0.75503403]\n",
      " [-0.14992063]\n",
      " [-0.67585384]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00157135]\n",
      " [0.57007639]\n",
      " [0.02247619]\n",
      " [0.45677842]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13136279383524282 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29768079]\n",
      " [ 4.13760436]\n",
      " [ 3.42884728]\n",
      " [ 1.64262127]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  642\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0607519 ]\n",
      " [11.15305407]\n",
      " [18.15086799]\n",
      " [17.82604919]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0392481 ]\n",
      " [ 0.75305407]\n",
      " [-0.14913201]\n",
      " [-0.67395081]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00154041]\n",
      " [0.56709043]\n",
      " [0.02224035]\n",
      " [0.45420969]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.13063511035585212 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29795398]\n",
      " [ 4.13960163]\n",
      " [ 3.43055171]\n",
      " [ 1.64209506]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  643\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06114041]\n",
      " [11.15107824]\n",
      " [18.15165132]\n",
      " [17.82794594]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03885959]\n",
      " [ 0.75107824]\n",
      " [-0.14834868]\n",
      " [-0.67205406]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00151007]\n",
      " [0.56411853]\n",
      " [0.02200733]\n",
      " [0.45165665]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1299115727583204 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29822444]\n",
      " [ 4.14159358]\n",
      " [ 3.43225086]\n",
      " [ 1.64156942]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  644\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06152534]\n",
      " [11.14910658]\n",
      " [18.1524294 ]\n",
      " [17.82983644]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03847466]\n",
      " [ 0.74910658]\n",
      " [-0.1475706 ]\n",
      " [-0.67016356]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0014803 ]\n",
      " [0.56116067]\n",
      " [0.02177708]\n",
      " [0.4491192 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12919215542242996 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2984922 ]\n",
      " [ 4.14358024]\n",
      " [ 3.43394475]\n",
      " [ 1.64104436]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  645\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06190674]\n",
      " [11.14713907]\n",
      " [18.15320226]\n",
      " [17.83172071]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03809326]\n",
      " [ 0.74713907]\n",
      " [-0.14679774]\n",
      " [-0.66827929]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0014511 ]\n",
      " [0.55821679]\n",
      " [0.02154958]\n",
      " [0.4465972 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12847683292142453 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29875727]\n",
      " [ 4.1455616 ]\n",
      " [ 3.43563339]\n",
      " [ 1.64051988]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  646\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06228462]\n",
      " [11.14517572]\n",
      " [18.15396996]\n",
      " [17.8335988 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03771538]\n",
      " [ 0.74517572]\n",
      " [-0.14603004]\n",
      " [-0.6664012 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00142245]\n",
      " [0.55528685]\n",
      " [0.02132477]\n",
      " [0.44409056]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12776558001995914 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2990197 ]\n",
      " [ 4.14753769]\n",
      " [ 3.43731681]\n",
      " [ 1.63999599]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  647\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06265903]\n",
      " [11.14321653]\n",
      " [18.15473252]\n",
      " [17.83547072]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03734097]\n",
      " [ 0.74321653]\n",
      " [-0.14526748]\n",
      " [-0.66452928]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00139435]\n",
      " [0.55237082]\n",
      " [0.02110264]\n",
      " [0.44159917]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12705837167208217 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.2992795 ]\n",
      " [ 4.14950852]\n",
      " [ 3.43899503]\n",
      " [ 1.63947268]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  648\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06302999]\n",
      " [11.14126152]\n",
      " [18.15549   ]\n",
      " [17.83733651]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03697001]\n",
      " [ 0.74126152]\n",
      " [-0.14451   ]\n",
      " [-0.66266349]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00136678]\n",
      " [0.54946864]\n",
      " [0.02088314]\n",
      " [0.4391229 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1263551830192477 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29953671]\n",
      " [ 4.1514741 ]\n",
      " [ 3.44066805]\n",
      " [ 1.63894998]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  649\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06339754]\n",
      " [11.13931067]\n",
      " [18.15624242]\n",
      " [17.8391962 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03660246]\n",
      " [ 0.73931067]\n",
      " [-0.14375758]\n",
      " [-0.6608038 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00133974]\n",
      " [0.54658027]\n",
      " [0.02066624]\n",
      " [0.43666167]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12565598938835354 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.29979134]\n",
      " [ 4.15343444]\n",
      " [ 3.44233591]\n",
      " [ 1.63842787]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  650\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06376171]\n",
      " [11.137364  ]\n",
      " [18.15698984]\n",
      " [17.84104982]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03623829]\n",
      " [ 0.737364  ]\n",
      " [-0.14301016]\n",
      " [-0.65895018]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00131321]\n",
      " [0.54370567]\n",
      " [0.02045191]\n",
      " [0.43421535]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12496076628980998 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30004343]\n",
      " [ 4.15538956]\n",
      " [ 3.44399861]\n",
      " [ 1.63790636]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  651\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06412253]\n",
      " [11.1354215 ]\n",
      " [18.15773228]\n",
      " [17.84289739]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03587747]\n",
      " [ 0.7354215 ]\n",
      " [-0.14226772]\n",
      " [-0.65710261]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00128719]\n",
      " [0.54084478]\n",
      " [0.0202401 ]\n",
      " [0.43178384]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12426948941563508 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30029299]\n",
      " [ 4.15733948]\n",
      " [ 3.44565618]\n",
      " [ 1.63738545]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  652\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06448003]\n",
      " [11.13348318]\n",
      " [18.1584698 ]\n",
      " [17.84473896]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03551997]\n",
      " [ 0.73348318]\n",
      " [-0.1415302 ]\n",
      " [-0.65526104]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00126167]\n",
      " [0.53799758]\n",
      " [0.0200308 ]\n",
      " [0.42936703]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12358213463758308 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30054006]\n",
      " [ 4.1592842 ]\n",
      " [ 3.44730863]\n",
      " [ 1.63686516]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  653\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06483425]\n",
      " [11.13154905]\n",
      " [18.15920242]\n",
      " [17.84657454]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03516575]\n",
      " [ 0.73154905]\n",
      " [-0.14079758]\n",
      " [-0.65342546]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00123663]\n",
      " [0.53516401]\n",
      " [0.01982396]\n",
      " [0.42696483]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12289867800528542 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30078466]\n",
      " [ 4.16122374]\n",
      " [ 3.44895598]\n",
      " [ 1.63634548]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  654\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0651852 ]\n",
      " [11.12961909]\n",
      " [18.15993018]\n",
      " [17.84840417]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0348148 ]\n",
      " [ 0.72961909]\n",
      " [-0.14006982]\n",
      " [-0.65159583]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00121207]\n",
      " [0.53234402]\n",
      " [0.01961955]\n",
      " [0.42457712]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12221909574444108 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30102682]\n",
      " [ 4.16315811]\n",
      " [ 3.45059825]\n",
      " [ 1.63582641]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  655\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06553293]\n",
      " [11.12769333]\n",
      " [18.16065313]\n",
      " [17.85022788]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03446707]\n",
      " [ 0.72769333]\n",
      " [-0.13934687]\n",
      " [-0.64977212]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00118798]\n",
      " [0.52953758]\n",
      " [0.01941755]\n",
      " [0.42220381]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12154336425500653 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30126655]\n",
      " [ 4.16508733]\n",
      " [ 3.45223545]\n",
      " [ 1.63530796]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  656\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06587746]\n",
      " [11.12577175]\n",
      " [18.1613713 ]\n",
      " [17.85204569]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03412254]\n",
      " [ 0.72577175]\n",
      " [-0.1386287 ]\n",
      " [-0.64795431]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00116435]\n",
      " [0.52674463]\n",
      " [0.01921792]\n",
      " [0.41984479]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12087146010943298 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30150388]\n",
      " [ 4.16701141]\n",
      " [ 3.45386761]\n",
      " [ 1.63479014]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  657\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06621882]\n",
      " [11.12385436]\n",
      " [18.16208473]\n",
      " [17.85385763]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03378118]\n",
      " [ 0.72385436]\n",
      " [-0.13791527]\n",
      " [-0.64614237]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00114117]\n",
      " [0.52396513]\n",
      " [0.01902062]\n",
      " [0.41749996]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.12020336005091864 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30173884]\n",
      " [ 4.16893035]\n",
      " [ 3.45549474]\n",
      " [ 1.63427294]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  658\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06655704]\n",
      " [11.12194116]\n",
      " [18.16279345]\n",
      " [17.85566373]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03344296]\n",
      " [ 0.72194116]\n",
      " [-0.13720655]\n",
      " [-0.64433627]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00111843]\n",
      " [0.52119903]\n",
      " [0.01882564]\n",
      " [0.41516922]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1195390409916858 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30197146]\n",
      " [ 4.17084419]\n",
      " [ 3.45711686]\n",
      " [ 1.63375637]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  659\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06689214]\n",
      " [11.12003215]\n",
      " [18.16349751]\n",
      " [17.85746402]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03310786]\n",
      " [ 0.72003215]\n",
      " [-0.13650249]\n",
      " [-0.64253598]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00109613]\n",
      " [0.5184463 ]\n",
      " [0.01863293]\n",
      " [0.41285248]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11887848001128551 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30220174]\n",
      " [ 4.17275292]\n",
      " [ 3.45873398]\n",
      " [ 1.63324043]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  660\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06722417]\n",
      " [11.11812734]\n",
      " [18.16419693]\n",
      " [17.85925853]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03277583]\n",
      " [ 0.71812734]\n",
      " [-0.13580307]\n",
      " [-0.64074147]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00107426]\n",
      " [0.51570687]\n",
      " [0.01844247]\n",
      " [0.41054963]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11822165435492402 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30242972]\n",
      " [ 4.17465656]\n",
      " [ 3.46034613]\n",
      " [ 1.63272513]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  661\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06755314]\n",
      " [11.11622672]\n",
      " [18.16489175]\n",
      " [17.86104728]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03244686]\n",
      " [ 0.71622672]\n",
      " [-0.13510825]\n",
      " [-0.63895272]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0010528 ]\n",
      " [0.51298071]\n",
      " [0.01825424]\n",
      " [0.40826058]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11756854143181195 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30265543]\n",
      " [ 4.17655513]\n",
      " [ 3.46195331]\n",
      " [ 1.63221047]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  662\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06787909]\n",
      " [11.1143303 ]\n",
      " [18.16558202]\n",
      " [17.8628303 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03212091]\n",
      " [ 0.7143303 ]\n",
      " [-0.13441798]\n",
      " [-0.6371697 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00103175]\n",
      " [0.51026778]\n",
      " [0.01806819]\n",
      " [0.40598523]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11691911881353942 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30287887]\n",
      " [ 4.17844863]\n",
      " [ 3.46355556]\n",
      " [ 1.63169645]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  663\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06820204]\n",
      " [11.11243807]\n",
      " [18.16626776]\n",
      " [17.86460762]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03179796]\n",
      " [ 0.71243807]\n",
      " [-0.13373224]\n",
      " [-0.63539238]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00101111]\n",
      " [0.50756801]\n",
      " [0.01788431]\n",
      " [0.40372348]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11627336423246964 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30310008]\n",
      " [ 4.18033709]\n",
      " [ 3.46515287]\n",
      " [ 1.63118307]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  664\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06852202]\n",
      " [11.11055005]\n",
      " [18.16694901]\n",
      " [17.86637926]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03147798]\n",
      " [ 0.71055005]\n",
      " [-0.13305099]\n",
      " [-0.63362074]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00099086]\n",
      " [0.50488137]\n",
      " [0.01770257]\n",
      " [0.40147524]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11563125558016277 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30331908]\n",
      " [ 4.18222051]\n",
      " [ 3.46674528]\n",
      " [ 1.63067034]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  665\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06883905]\n",
      " [11.10866622]\n",
      " [18.16762581]\n",
      " [17.86814525]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03116095]\n",
      " [ 0.70866622]\n",
      " [-0.13237419]\n",
      " [-0.63185475]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.000971  ]\n",
      " [0.50220781]\n",
      " [0.01752293]\n",
      " [0.39924042]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11499277090580773 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30353589]\n",
      " [ 4.1840989 ]\n",
      " [ 3.4683328 ]\n",
      " [ 1.63015827]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  666\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06915317]\n",
      " [11.10678659]\n",
      " [18.16829818]\n",
      " [17.86990562]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03084683]\n",
      " [ 0.70678659]\n",
      " [-0.13170182]\n",
      " [-0.63009438]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00095153]\n",
      " [0.49954729]\n",
      " [0.01734537]\n",
      " [0.39701893]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11435788841469224 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30375053]\n",
      " [ 4.18597229]\n",
      " [ 3.46991544]\n",
      " [ 1.62964684]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  667\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0694644 ]\n",
      " [11.10491116]\n",
      " [18.16896617]\n",
      " [17.87166039]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0305356 ]\n",
      " [ 0.70491116]\n",
      " [-0.13103383]\n",
      " [-0.62833961]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00093242]\n",
      " [0.49689975]\n",
      " [0.01716986]\n",
      " [0.39481066]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11372658646668156 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30396303]\n",
      " [ 4.18784068]\n",
      " [ 3.47149322]\n",
      " [ 1.62913608]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  668\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.06977277]\n",
      " [11.10303993]\n",
      " [18.16962981]\n",
      " [17.8734096 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.03022723]\n",
      " [ 0.70303993]\n",
      " [-0.13037019]\n",
      " [-0.6265904 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00091369]\n",
      " [0.49426514]\n",
      " [0.01699639]\n",
      " [0.39261553]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11309884357472022 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3041734 ]\n",
      " [ 4.18970408]\n",
      " [ 3.47306615]\n",
      " [ 1.62862597]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  669\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07007831]\n",
      " [11.1011729 ]\n",
      " [18.17028913]\n",
      " [17.87515326]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02992169]\n",
      " [ 0.7011729 ]\n",
      " [-0.12971087]\n",
      " [-0.62484674]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00089531]\n",
      " [0.49164344]\n",
      " [0.01682491]\n",
      " [0.39043345]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11247463840336087 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30438166]\n",
      " [ 4.19156251]\n",
      " [ 3.47463427]\n",
      " [ 1.62811653]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  670\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07038103]\n",
      " [11.09931007]\n",
      " [18.17094416]\n",
      " [17.8768914 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02961897]\n",
      " [ 0.69931007]\n",
      " [-0.12905584]\n",
      " [-0.6231086 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00087728]\n",
      " [0.48903457]\n",
      " [0.01665541]\n",
      " [0.38826433]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11185394976730614 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30458785]\n",
      " [ 4.19341598]\n",
      " [ 3.47619757]\n",
      " [ 1.62760776]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  671\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07068097]\n",
      " [11.09745144]\n",
      " [18.17159494]\n",
      " [17.87862404]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02931903]\n",
      " [ 0.69745144]\n",
      " [-0.12840506]\n",
      " [-0.62137596]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00085961]\n",
      " [0.48643851]\n",
      " [0.01648786]\n",
      " [0.38610808]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11123675662997352 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30479197]\n",
      " [ 4.19526451]\n",
      " [ 3.47775608]\n",
      " [ 1.62709965]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  672\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07097814]\n",
      " [11.09559701]\n",
      " [18.1722415 ]\n",
      " [17.88035122]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02902186]\n",
      " [ 0.69559701]\n",
      " [-0.1277585 ]\n",
      " [-0.61964878]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00084227]\n",
      " [0.48385519]\n",
      " [0.01632223]\n",
      " [0.38396461]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11062303810207628 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30499405]\n",
      " [ 4.1971081 ]\n",
      " [ 3.47930982]\n",
      " [ 1.62659221]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  673\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07127259]\n",
      " [11.09374677]\n",
      " [18.17288388]\n",
      " [17.88207296]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02872741]\n",
      " [ 0.69374677]\n",
      " [-0.12711612]\n",
      " [-0.61792704]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00082526]\n",
      " [0.48128458]\n",
      " [0.01615851]\n",
      " [0.38183383]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.11001277344023014 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30519411]\n",
      " [ 4.19894678]\n",
      " [ 3.4808588 ]\n",
      " [ 1.62608545]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  674\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07156433]\n",
      " [11.09190074]\n",
      " [18.17352209]\n",
      " [17.88378927]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02843567]\n",
      " [ 0.69190074]\n",
      " [-0.12647791]\n",
      " [-0.61621073]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00080859]\n",
      " [0.47872663]\n",
      " [0.01599666]\n",
      " [0.37971566]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10940594204556991 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30539217]\n",
      " [ 4.20078054]\n",
      " [ 3.48240303]\n",
      " [ 1.62557937]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  675\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07185338]\n",
      " [11.0900589 ]\n",
      " [18.17415619]\n",
      " [17.8855002 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02814662]\n",
      " [ 0.6900589 ]\n",
      " [-0.12584381]\n",
      " [-0.6144998 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00079223]\n",
      " [0.47618128]\n",
      " [0.01583666]\n",
      " [0.37761001]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10880252346239452 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30558825]\n",
      " [ 4.20260941]\n",
      " [ 3.48394253]\n",
      " [ 1.62507396]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  676\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07213978]\n",
      " [11.08822126]\n",
      " [18.1747862 ]\n",
      " [17.88720575]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02786022]\n",
      " [ 0.68822126]\n",
      " [-0.1252138 ]\n",
      " [-0.61279425]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00077619]\n",
      " [0.4736485 ]\n",
      " [0.0156785 ]\n",
      " [0.37551679]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10820249737681834 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30578236]\n",
      " [ 4.20443339]\n",
      " [ 3.48547733]\n",
      " [ 1.62456924]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  677\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07242354]\n",
      " [11.08638781]\n",
      " [18.17541214]\n",
      " [17.88890596]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02757646]\n",
      " [ 0.68638781]\n",
      " [-0.12458786]\n",
      " [-0.61109404]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00076046]\n",
      " [0.47112823]\n",
      " [0.01552213]\n",
      " [0.37343593]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10760584361545561 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30597454]\n",
      " [ 4.20625251]\n",
      " [ 3.48700743]\n",
      " [ 1.6240652 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  678\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07270469]\n",
      " [11.08455856]\n",
      " [18.17603406]\n",
      " [17.89060085]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02729531]\n",
      " [ 0.68455856]\n",
      " [-0.12396594]\n",
      " [-0.60939915]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00074503]\n",
      " [0.46862042]\n",
      " [0.01536755]\n",
      " [0.37136733]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1070125421441027 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30616479]\n",
      " [ 4.20806677]\n",
      " [ 3.48853285]\n",
      " [ 1.62356185]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  679\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07298325]\n",
      " [11.0827335 ]\n",
      " [18.17665198]\n",
      " [17.89229044]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = y_predicted - y\n",
      "[[-0.02701675]\n",
      " [ 0.6827335 ]\n",
      " [-0.12334802]\n",
      " [-0.60770956]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0007299 ]\n",
      " [0.46612504]\n",
      " [0.01521473]\n",
      " [0.36931091]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10642257306646025 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30635315]\n",
      " [ 4.20987618]\n",
      " [ 3.4900536 ]\n",
      " [ 1.62305919]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  680\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07325925]\n",
      " [11.08091264]\n",
      " [18.17726593]\n",
      " [17.89397476]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02674075]\n",
      " [ 0.68091264]\n",
      " [-0.12273407]\n",
      " [-0.60602524]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00071507]\n",
      " [0.46364202]\n",
      " [0.01506365]\n",
      " [0.36726659]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10583591662285143 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30653961]\n",
      " [ 4.21168076]\n",
      " [ 3.49156971]\n",
      " [ 1.62255722]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  681\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07353272]\n",
      " [11.07909596]\n",
      " [18.17787595]\n",
      " [17.89565383]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02646728]\n",
      " [ 0.67909596]\n",
      " [-0.12212405]\n",
      " [-0.60434617]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00070052]\n",
      " [0.46117133]\n",
      " [0.01491428]\n",
      " [0.36523429]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10525255318897164 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30672422]\n",
      " [ 4.21348052]\n",
      " [ 3.49308119]\n",
      " [ 1.62205595]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  682\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07380367]\n",
      " [11.07728348]\n",
      " [18.17848206]\n",
      " [17.89732767]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02619633]\n",
      " [ 0.67728348]\n",
      " [-0.12151794]\n",
      " [-0.60267233]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00068625]\n",
      " [0.45871291]\n",
      " [0.01476661]\n",
      " [0.36321393]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10467246327464672 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30690698]\n",
      " [ 4.21527547]\n",
      " [ 3.49458805]\n",
      " [ 1.62155537]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  683\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07407212]\n",
      " [11.07547518]\n",
      " [18.17908429]\n",
      " [17.89899631]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02592788]\n",
      " [ 0.67547518]\n",
      " [-0.12091571]\n",
      " [-0.60100369]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00067225]\n",
      " [0.45626672]\n",
      " [0.01462061]\n",
      " [0.36120543]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1040956275226087 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30708791]\n",
      " [ 4.21706563]\n",
      " [ 3.49609032]\n",
      " [ 1.6210555 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  684\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0743381 ]\n",
      " [11.07367107]\n",
      " [18.17968267]\n",
      " [17.90065977]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0256619 ]\n",
      " [ 0.67367107]\n",
      " [-0.12031733]\n",
      " [-0.59934023]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00065853]\n",
      " [0.45383272]\n",
      " [0.01447626]\n",
      " [0.35920871]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10352202670729196 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30726703]\n",
      " [ 4.21885101]\n",
      " [ 3.49758799]\n",
      " [ 1.62055632]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  685\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07460164]\n",
      " [11.07187115]\n",
      " [18.18027724]\n",
      " [17.90231808]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02539836]\n",
      " [ 0.67187115]\n",
      " [-0.11972276]\n",
      " [-0.59768192]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00064508]\n",
      " [0.45141084]\n",
      " [0.01433354]\n",
      " [0.35722368]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10295164173363905 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30744436]\n",
      " [ 4.22063161]\n",
      " [ 3.4990811 ]\n",
      " [ 1.62005785]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  686\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07486275]\n",
      " [11.07007541]\n",
      " [18.18086802]\n",
      " [17.90397125]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02513725]\n",
      " [ 0.67007541]\n",
      " [-0.11913198]\n",
      " [-0.59602875]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00063188]\n",
      " [0.44900105]\n",
      " [0.01419243]\n",
      " [0.35525027]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.1023844536359228 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30761991]\n",
      " [ 4.22240746]\n",
      " [ 3.50056966]\n",
      " [ 1.61956008]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  687\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07512146]\n",
      " [11.06828384]\n",
      " [18.18145504]\n",
      " [17.90561931]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02487854]\n",
      " [ 0.66828384]\n",
      " [-0.11854496]\n",
      " [-0.59438069]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00061894]\n",
      " [0.44660329]\n",
      " [0.01405291]\n",
      " [0.3532884 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10182044357658793 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30779371]\n",
      " [ 4.22417856]\n",
      " [ 3.50205368]\n",
      " [ 1.61906303]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  688\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07537779]\n",
      " [11.06649646]\n",
      " [18.18203832]\n",
      " [17.90726228]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02462221]\n",
      " [ 0.66649646]\n",
      " [-0.11796168]\n",
      " [-0.59273772]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00060625]\n",
      " [0.44421753]\n",
      " [0.01391496]\n",
      " [0.351338  ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10125959284510336 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30796578]\n",
      " [ 4.22594493]\n",
      " [ 3.50353317]\n",
      " [ 1.61856668]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  689\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07563177]\n",
      " [11.06471325]\n",
      " [18.18261791]\n",
      " [17.90890018]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02436823]\n",
      " [ 0.66471325]\n",
      " [-0.11738209]\n",
      " [-0.59109982]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00059381]\n",
      " [0.44184371]\n",
      " [0.01377856]\n",
      " [0.34939899]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10070188285682777 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30813612]\n",
      " [ 4.22770658]\n",
      " [ 3.50500816]\n",
      " [ 1.61807105]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  690\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0758834 ]\n",
      " [11.06293422]\n",
      " [18.18319382]\n",
      " [17.91053304]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0241166 ]\n",
      " [ 0.66293422]\n",
      " [-0.11680618]\n",
      " [-0.58946696]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00058161]\n",
      " [0.43948178]\n",
      " [0.01364368]\n",
      " [0.34747129]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.10014729515189738 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30830476]\n",
      " [ 4.22946351]\n",
      " [ 3.50647866]\n",
      " [ 1.61757614]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  691\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07613272]\n",
      " [11.06115935]\n",
      " [18.18376608]\n",
      " [17.91216088]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02386728]\n",
      " [ 0.66115935]\n",
      " [-0.11623392]\n",
      " [-0.58783912]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00056965]\n",
      " [0.43713169]\n",
      " [0.01351032]\n",
      " [0.34555483]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0995958113941178 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30847171]\n",
      " [ 4.23121576]\n",
      " [ 3.50794468]\n",
      " [ 1.61708194]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  692\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07637974]\n",
      " [11.05938866]\n",
      " [18.18433472]\n",
      " [17.91378372]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02362026]\n",
      " [ 0.65938866]\n",
      " [-0.11566528]\n",
      " [-0.58621628]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00055792]\n",
      " [0.4347934 ]\n",
      " [0.01337846]\n",
      " [0.34364953]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0990474133698756 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30863699]\n",
      " [ 4.23296331]\n",
      " [ 3.50940624]\n",
      " [ 1.61658846]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  693\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07662449]\n",
      " [11.05762213]\n",
      " [18.18489978]\n",
      " [17.91540158]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02337551]\n",
      " [ 0.65762213]\n",
      " [-0.11510022]\n",
      " [-0.58459842]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00054641]\n",
      " [0.43246687]\n",
      " [0.01324806]\n",
      " [0.34175532]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09850208298706363 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30880062]\n",
      " [ 4.2347062 ]\n",
      " [ 3.51086335]\n",
      " [ 1.6160957 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  694\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07686699]\n",
      " [11.05585977]\n",
      " [18.18546126]\n",
      " [17.91701447]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02313301]\n",
      " [ 0.65585977]\n",
      " [-0.11453874]\n",
      " [-0.58298553]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00053514]\n",
      " [0.43015204]\n",
      " [0.01311912]\n",
      " [0.33987212]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09795980227401788 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30896262]\n",
      " [ 4.23644442]\n",
      " [ 3.51231603]\n",
      " [ 1.61560366]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  695\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07710725]\n",
      " [11.05410157]\n",
      " [18.18601921]\n",
      " [17.91862244]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02289275]\n",
      " [ 0.65410157]\n",
      " [-0.11398079]\n",
      " [-0.58137756]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00052408]\n",
      " [0.42784886]\n",
      " [0.01299162]\n",
      " [0.33799987]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09742055337846912 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30912299]\n",
      " [ 4.238178  ]\n",
      " [ 3.5137643 ]\n",
      " [ 1.61511235]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  696\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07734531]\n",
      " [11.05234752]\n",
      " [18.18657365]\n",
      " [17.92022549]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02265469]\n",
      " [ 0.65234752]\n",
      " [-0.11342635]\n",
      " [-0.57977451]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00051324]\n",
      " [0.42555729]\n",
      " [0.01286554]\n",
      " [0.33613849]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09688431856650313 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30928176]\n",
      " [ 4.23990694]\n",
      " [ 3.51520816]\n",
      " [ 1.61462177]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  697\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07758117]\n",
      " [11.05059763]\n",
      " [18.1871246 ]\n",
      " [17.92182364]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02241883]\n",
      " [ 0.65059763]\n",
      " [-0.1128754 ]\n",
      " [-0.57817636]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.0005026 ]\n",
      " [0.42327728]\n",
      " [0.01274086]\n",
      " [0.3342879 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09635108022154258 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30943894]\n",
      " [ 4.24163125]\n",
      " [ 3.51664764]\n",
      " [ 1.61413192]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  698\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07781486]\n",
      " [11.0488519 ]\n",
      " [18.1876721 ]\n",
      " [17.92341692]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02218514]\n",
      " [ 0.6488519 ]\n",
      " [-0.1123279 ]\n",
      " [-0.57658308]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00049218]\n",
      " [0.42100878]\n",
      " [0.01261756]\n",
      " [0.33244805]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09582082084333322 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30959455]\n",
      " [ 4.24335096]\n",
      " [ 3.51808274]\n",
      " [ 1.6136428 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  699\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0780464 ]\n",
      " [11.04711031]\n",
      " [18.18821616]\n",
      " [17.92500535]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0219536 ]\n",
      " [ 0.64711031]\n",
      " [-0.11178384]\n",
      " [-0.57499465]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00048196]\n",
      " [0.41875175]\n",
      " [0.01249563]\n",
      " [0.33061885]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09529352304694597 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30974861]\n",
      " [ 4.24506606]\n",
      " [ 3.51951349]\n",
      " [ 1.61315441]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  700\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07827581]\n",
      " [11.04537286]\n",
      " [18.18875682]\n",
      " [17.92658895]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02172419]\n",
      " [ 0.64537286]\n",
      " [-0.11124318]\n",
      " [-0.57341105]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00047194]\n",
      " [0.41650613]\n",
      " [0.01237505]\n",
      " [0.32880024]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09476916956178982 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.30990112]\n",
      " [ 4.24677657]\n",
      " [ 3.5209399 ]\n",
      " [ 1.61266676]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  701\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0785031 ]\n",
      " [11.04363956]\n",
      " [18.1892941 ]\n",
      " [17.92816773]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0214969 ]\n",
      " [ 0.64363956]\n",
      " [-0.1107059 ]\n",
      " [-0.57183227]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00046212]\n",
      " [0.41427189]\n",
      " [0.0122558 ]\n",
      " [0.32699214]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09424774323064126 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31005211]\n",
      " [ 4.24848251]\n",
      " [ 3.52236197]\n",
      " [ 1.61217984]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  702\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0787283 ]\n",
      " [11.0419104 ]\n",
      " [18.18982802]\n",
      " [17.92974172]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0212717 ]\n",
      " [ 0.6419104 ]\n",
      " [-0.11017198]\n",
      " [-0.57025828]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00045249]\n",
      " [0.41204896]\n",
      " [0.01213787]\n",
      " [0.3251945 ]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09372922700867595 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31020159]\n",
      " [ 4.25018389]\n",
      " [ 3.52377974]\n",
      " [ 1.61169366]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  703\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07895143]\n",
      " [11.04018538]\n",
      " [18.19035861]\n",
      " [17.93131095]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02104857]\n",
      " [ 0.64018538]\n",
      " [-0.10964139]\n",
      " [-0.56868905]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00044304]\n",
      " [0.40983731]\n",
      " [0.01202123]\n",
      " [0.32340724]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.093213603962524 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31034957]\n",
      " [ 4.25188071]\n",
      " [ 3.5251932 ]\n",
      " [ 1.61120823]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  704\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0791725 ]\n",
      " [11.03846448]\n",
      " [18.19088589]\n",
      " [17.93287542]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0208275 ]\n",
      " [ 0.63846448]\n",
      " [-0.10911411]\n",
      " [-0.56712458]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00043378]\n",
      " [0.40763689]\n",
      " [0.01190589]\n",
      " [0.32163029]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09270085726932834 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31049608]\n",
      " [ 4.25357299]\n",
      " [ 3.52660238]\n",
      " [ 1.61072353]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  705\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07939154]\n",
      " [11.03674772]\n",
      " [18.1914099 ]\n",
      " [17.93443516]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02060846]\n",
      " [ 0.63674772]\n",
      " [-0.1085901 ]\n",
      " [-0.56556484]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00042471]\n",
      " [0.40544765]\n",
      " [0.01179181]\n",
      " [0.31986359]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09219097021581352 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31064112]\n",
      " [ 4.25526074]\n",
      " [ 3.5280073 ]\n",
      " [ 1.61023958]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  706\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07960856]\n",
      " [11.03503507]\n",
      " [18.19193065]\n",
      " [17.93599019]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02039144]\n",
      " [ 0.63503507]\n",
      " [-0.10806935]\n",
      " [-0.56400981]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00041581]\n",
      " [0.40326955]\n",
      " [0.01167898]\n",
      " [0.31810707]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09168392619737561 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31078471]\n",
      " [ 4.25694398]\n",
      " [ 3.52940795]\n",
      " [ 1.60975638]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  707\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.07982358]\n",
      " [11.03332655]\n",
      " [18.19244817]\n",
      " [17.93754052]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.02017642]\n",
      " [ 0.63332655]\n",
      " [-0.10755183]\n",
      " [-0.56245948]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[0.00040709]\n",
      " [0.40110252]\n",
      " [0.0115674 ]\n",
      " [0.31636066]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.09117970871716989 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31092686]\n",
      " [ 4.25862271]\n",
      " [ 3.53080436]\n",
      " [ 1.60927392]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  708\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08003662]\n",
      " [11.03162215]\n",
      " [18.19296248]\n",
      " [17.93908619]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01996338]\n",
      " [ 0.63162215]\n",
      " [-0.10703752]\n",
      " [-0.56091381]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.98536634e-04]\n",
      " [3.98946541e-01]\n",
      " [1.14570303e-02]\n",
      " [3.14624303e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0906783013852189 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31106759]\n",
      " [ 4.26029694]\n",
      " [ 3.53219655]\n",
      " [ 1.60879221]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  709\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08024769]\n",
      " [11.02992186]\n",
      " [18.19347361]\n",
      " [17.9406272 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01975231]\n",
      " [ 0.62992186]\n",
      " [-0.10652639]\n",
      " [-0.5593728 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.90153619e-04]\n",
      " [3.96801549e-01]\n",
      " [1.13478717e-02]\n",
      " [3.12897929e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.090179687917527 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31120692]\n",
      " [ 4.2619667 ]\n",
      " [ 3.53358453]\n",
      " [ 1.60831125]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  710\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08045682]\n",
      " [11.02822568]\n",
      " [18.19398158]\n",
      " [17.94216358]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01954318]\n",
      " [ 0.62822568]\n",
      " [-0.10601842]\n",
      " [-0.55783642]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.81935729e-04]\n",
      " [3.94667503e-01]\n",
      " [1.12399054e-02]\n",
      " [3.11181473e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08968385213520572 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31134485]\n",
      " [ 4.26363198]\n",
      " [ 3.5349683 ]\n",
      " [ 1.60783104]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  711\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08066403]\n",
      " [11.0265336 ]\n",
      " [18.19448641]\n",
      " [17.94369534]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01933597]\n",
      " [ 0.6265336 ]\n",
      " [-0.10551359]\n",
      " [-0.55630466]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.73879837e-04]\n",
      " [3.92544354e-01]\n",
      " [1.11331170e-02]\n",
      " [3.09474873e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08919077796361094 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3114814 ]\n",
      " [ 4.2652928 ]\n",
      " [ 3.53634789]\n",
      " [ 1.60735159]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  712\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08086932]\n",
      " [11.02484563]\n",
      " [18.19498813]\n",
      " [17.94522251]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01913068]\n",
      " [ 0.62484563]\n",
      " [-0.10501187]\n",
      " [-0.55477749]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.65982874e-04]\n",
      " [3.90432056e-01]\n",
      " [1.10274919e-02]\n",
      " [3.07778065e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08870044943148618 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31161658]\n",
      " [ 4.26694918]\n",
      " [ 3.53772331]\n",
      " [ 1.60687289]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  713\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08107272]\n",
      " [11.02316175]\n",
      " [18.19548677]\n",
      " [17.9467451 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01892728]\n",
      " [ 0.62316175]\n",
      " [-0.10451323]\n",
      " [-0.5532549 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.58241830e-04]\n",
      " [3.88330562e-01]\n",
      " [1.09230161e-02]\n",
      " [3.06090985e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08821285067012248 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31175042]\n",
      " [ 4.26860112]\n",
      " [ 3.53909457]\n",
      " [ 1.60639494]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  714\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08127425]\n",
      " [11.02148196]\n",
      " [18.19598233]\n",
      " [17.94826313]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01872575]\n",
      " [ 0.62148196]\n",
      " [-0.10401767]\n",
      " [-0.55173687]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.50653748e-04]\n",
      " [3.86239826e-01]\n",
      " [1.08196754e-02]\n",
      " [3.04413572e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08772796591252015 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31188291]\n",
      " [ 4.27024864]\n",
      " [ 3.54046169]\n",
      " [ 1.60591776]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  715\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08147392]\n",
      " [11.01980626]\n",
      " [18.19647485]\n",
      " [17.94977662]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01852608]\n",
      " [ 0.61980626]\n",
      " [-0.10352515]\n",
      " [-0.55022338]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.43215727e-04]\n",
      " [3.84159800e-01]\n",
      " [1.07174560e-02]\n",
      " [3.02745764e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08724577949256686 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31201408]\n",
      " [ 4.27189175]\n",
      " [ 3.54182468]\n",
      " [ 1.60544133]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  716\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08167175]\n",
      " [11.01813464]\n",
      " [18.19696435]\n",
      " [17.95128559]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01832825]\n",
      " [ 0.61813464]\n",
      " [-0.10303565]\n",
      " [-0.54871441]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.35924922e-04]\n",
      " [3.82090438e-01]\n",
      " [1.06163444e-02]\n",
      " [3.01087499e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08676627584422207 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31214394]\n",
      " [ 4.27353045]\n",
      " [ 3.54318356]\n",
      " [ 1.60496566]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  717\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08186775]\n",
      " [11.01646711]\n",
      " [18.19745086]\n",
      " [17.95279006]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01813225]\n",
      " [ 0.61646711]\n",
      " [-0.10254914]\n",
      " [-0.54720994]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.28778538e-04]\n",
      " [3.80031694e-01]\n",
      " [1.05163269e-02]\n",
      " [2.99438716e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08628943950070991 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3122725 ]\n",
      " [ 4.27516476]\n",
      " [ 3.54453833]\n",
      " [ 1.60449076]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  718\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08206194]\n",
      " [11.01480364]\n",
      " [18.19793438]\n",
      " [17.95429005]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01793806]\n",
      " [ 0.61480364]\n",
      " [-0.10206562]\n",
      " [-0.54570995]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.21773834e-04]\n",
      " [3.77983522e-01]\n",
      " [1.04173903e-02]\n",
      " [2.97799355e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08581525509372481 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31239978]\n",
      " [ 4.2767947 ]\n",
      " [ 3.54588902]\n",
      " [ 1.60401662]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  719\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08225435]\n",
      " [11.01314425]\n",
      " [18.19841495]\n",
      " [17.95578556]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01774565]\n",
      " [ 0.61314425]\n",
      " [-0.10158505]\n",
      " [-0.54421444]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.14908119e-04]\n",
      " [3.75945874e-01]\n",
      " [1.03195216e-02]\n",
      " [2.96169355e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08534370735263898 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31252578]\n",
      " [ 4.27842027]\n",
      " [ 3.54723563]\n",
      " [ 1.60354324]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  720\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08244498]\n",
      " [11.01148892]\n",
      " [18.19889259]\n",
      " [17.95727663]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01755502]\n",
      " [ 0.61148892]\n",
      " [-0.10110741]\n",
      " [-0.54272337]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.08178752e-04]\n",
      " [3.73918704e-01]\n",
      " [1.02227077e-02]\n",
      " [2.94548658e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0848747811037313 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31265052]\n",
      " [ 4.28004148]\n",
      " [ 3.54857818]\n",
      " [ 1.60307063]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  721\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08263385]\n",
      " [11.00983766]\n",
      " [18.19936732]\n",
      " [17.95876326]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01736615]\n",
      " [ 0.60983766]\n",
      " [-0.10063268]\n",
      " [-0.54123674]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.01583142e-04]\n",
      " [3.71901968e-01]\n",
      " [1.01269359e-02]\n",
      " [2.92937204e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08440846126941068 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31277402]\n",
      " [ 4.28165835]\n",
      " [ 3.54991668]\n",
      " [ 1.60259879]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  722\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08282098]\n",
      " [11.00819044]\n",
      " [18.19983916]\n",
      " [17.96024549]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01717902]\n",
      " [ 0.60819044]\n",
      " [-0.10016084]\n",
      " [-0.53975451]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.95118745e-04]\n",
      " [3.69895617e-01]\n",
      " [1.00321936e-02]\n",
      " [2.91334934e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08394473286745757 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31289628]\n",
      " [ 4.28327089]\n",
      " [ 3.55125115]\n",
      " [ 1.60212772]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  723\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08300638]\n",
      " [11.00654728]\n",
      " [18.20030813]\n",
      " [17.96172331]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01699362]\n",
      " [ 0.60654728]\n",
      " [-0.09969187]\n",
      " [-0.53827669]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.88783067e-04]\n",
      " [3.67899607e-01]\n",
      " [9.93846842e-03]\n",
      " [2.89741790e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08348358101027216 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31301732]\n",
      " [ 4.2848791 ]\n",
      " [ 3.5525816 ]\n",
      " [ 1.60165741]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  724\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08319007]\n",
      " [11.00490817]\n",
      " [18.20077426]\n",
      " [17.96319676]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01680993]\n",
      " [ 0.60490817]\n",
      " [-0.09922574]\n",
      " [-0.53680324]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.82573658e-04]\n",
      " [3.65913891e-01]\n",
      " [9.84574802e-03]\n",
      " [2.88157714e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08302499090412642 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31313714]\n",
      " [ 4.28648301]\n",
      " [ 3.55390804]\n",
      " [ 1.60118788]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  725\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08337207]\n",
      " [11.00327309]\n",
      " [18.20123756]\n",
      " [17.96466585]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01662793]\n",
      " [ 0.60327309]\n",
      " [-0.09876244]\n",
      " [-0.53533415]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.76488113e-04]\n",
      " [3.63938424e-01]\n",
      " [9.75402033e-03]\n",
      " [2.86582650e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08256894784843333 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31325577]\n",
      " [ 4.28808262]\n",
      " [ 3.55523049]\n",
      " [ 1.60071912]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  726\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08355238]\n",
      " [11.00164205]\n",
      " [18.20169805]\n",
      " [17.9661306 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01644762]\n",
      " [ 0.60164205]\n",
      " [-0.09830195]\n",
      " [-0.5338694 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.70524074e-04]\n",
      " [3.61973160e-01]\n",
      " [9.66327339e-03]\n",
      " [2.85016540e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08211543723501197 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31337321]\n",
      " [ 4.28967793]\n",
      " [ 3.55654895]\n",
      " [ 1.60025113]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  727\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08373103]\n",
      " [11.00001504]\n",
      " [18.20215576]\n",
      " [17.96759101]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01626897]\n",
      " [ 0.60001504]\n",
      " [-0.09784424]\n",
      " [-0.53240899]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.64679226e-04]\n",
      " [3.60018053e-01]\n",
      " [9.57349544e-03]\n",
      " [2.83459329e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08166444454737501 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31348948]\n",
      " [ 4.29126898]\n",
      " [ 3.55786345]\n",
      " [ 1.59978391]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  728\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08390804]\n",
      " [10.99839206]\n",
      " [18.2026107 ]\n",
      " [17.96904712]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01609196]\n",
      " [ 0.59839206]\n",
      " [-0.0973893 ]\n",
      " [-0.53095288]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.58951297e-04]\n",
      " [3.58073058e-01]\n",
      " [9.48467482e-03]\n",
      " [2.81910959e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08121595536000963 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31360459]\n",
      " [ 4.29285575]\n",
      " [ 3.559174  ]\n",
      " [ 1.59931747]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  729\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0840834 ]\n",
      " [10.9967731 ]\n",
      " [18.20306291]\n",
      " [17.97049894]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0159166 ]\n",
      " [ 0.5967731 ]\n",
      " [-0.09693709]\n",
      " [-0.52950106]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.53338058e-04]\n",
      " [3.56138129e-01]\n",
      " [9.39680008e-03]\n",
      " [2.80371375e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0807699553376781 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31371854]\n",
      " [ 4.29443827]\n",
      " [ 3.56048061]\n",
      " [ 1.59885181]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  730\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08425715]\n",
      " [10.99515815]\n",
      " [18.20351238]\n",
      " [17.97194648]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01574285]\n",
      " [ 0.59515815]\n",
      " [-0.09648762]\n",
      " [-0.52805352]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.47837320e-04]\n",
      " [3.54213222e-01]\n",
      " [9.30985989e-03]\n",
      " [2.78840523e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.08032643023471886 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31383135]\n",
      " [ 4.29601655]\n",
      " [ 3.56178328]\n",
      " [ 1.59838693]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  731\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08442929]\n",
      " [10.99354721]\n",
      " [18.20395916]\n",
      " [17.97338976]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01557071]\n",
      " [ 0.59354721]\n",
      " [-0.09604084]\n",
      " [-0.52661024]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.42446936e-04]\n",
      " [3.52298290e-01]\n",
      " [9.22384306e-03]\n",
      " [2.77318347e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0798853658943567 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31394304]\n",
      " [ 4.2975906 ]\n",
      " [ 3.56308204]\n",
      " [ 1.59792282]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  732\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08459984]\n",
      " [10.99194027]\n",
      " [18.20440325]\n",
      " [17.9748288 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01540016]\n",
      " [ 0.59194027]\n",
      " [-0.09559675]\n",
      " [-0.5251712 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.37164800e-04]\n",
      " [3.50393289e-01]\n",
      " [9.13873856e-03]\n",
      " [2.75804794e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07944674824802453 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31405361]\n",
      " [ 4.29916043]\n",
      " [ 3.5643769 ]\n",
      " [ 1.59745949]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  733\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08476882]\n",
      " [10.99033734]\n",
      " [18.20484468]\n",
      " [17.97626361]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01523118]\n",
      " [ 0.59033734]\n",
      " [-0.09515532]\n",
      " [-0.52373639]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.31988843e-04]\n",
      " [3.48498174e-01]\n",
      " [9.05453552e-03]\n",
      " [2.74299809e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07901056331468337 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31416307]\n",
      " [ 4.30072604]\n",
      " [ 3.56566788]\n",
      " [ 1.59699695]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  734\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08493623]\n",
      " [10.9887384 ]\n",
      " [18.20528346]\n",
      " [17.97769421]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01506377]\n",
      " [ 0.5887384 ]\n",
      " [-0.09471654]\n",
      " [-0.52230579]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.26917036e-04]\n",
      " [3.46612899e-01]\n",
      " [8.97122319e-03]\n",
      " [2.72803338e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0785767972001607 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31427144]\n",
      " [ 4.30228746]\n",
      " [ 3.56695497]\n",
      " [ 1.59653518]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  735\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0851021 ]\n",
      " [10.98714344]\n",
      " [18.20571962]\n",
      " [17.97912062]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0148979 ]\n",
      " [ 0.58714344]\n",
      " [-0.09428038]\n",
      " [-0.52087938]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.21947388e-04]\n",
      " [3.44737420e-01]\n",
      " [8.88879097e-03]\n",
      " [2.71315330e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07814543609648472 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31437873]\n",
      " [ 4.30384469]\n",
      " [ 3.5682382 ]\n",
      " [ 1.5960742 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  736\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08526643]\n",
      " [10.98555247]\n",
      " [18.20615317]\n",
      " [17.98054285]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01473357]\n",
      " [ 0.58555247]\n",
      " [-0.09384683]\n",
      " [-0.51945715]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.17077944e-04]\n",
      " [3.42871693e-01]\n",
      " [8.80722839e-03]\n",
      " [2.69835731e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07771646628123895 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31448494]\n",
      " [ 4.30539774]\n",
      " [ 3.56951758]\n",
      " [ 1.595614  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  737\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08542925]\n",
      " [10.98396547]\n",
      " [18.20658413]\n",
      " [17.98196092]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01457075]\n",
      " [ 0.58396547]\n",
      " [-0.09341587]\n",
      " [-0.51803908]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.12306786e-04]\n",
      " [3.41015673e-01]\n",
      " [8.72652512e-03]\n",
      " [2.68364488e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07728987411690702 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31459009]\n",
      " [ 4.30694662]\n",
      " [ 3.57079313]\n",
      " [ 1.59515458]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  738\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08559056]\n",
      " [10.98238245]\n",
      " [18.20701252]\n",
      " [17.98337484]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01440944]\n",
      " [ 0.58238245]\n",
      " [-0.09298748]\n",
      " [-0.51662516]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.07632033e-04]\n",
      " [3.39169314e-01]\n",
      " [8.64667099e-03]\n",
      " [2.66901551e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07686564605023968 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31469419]\n",
      " [ 4.30849135]\n",
      " [ 3.57206484]\n",
      " [ 1.59469595]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  739\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08575037]\n",
      " [10.98080339]\n",
      " [18.20743837]\n",
      " [17.98478464]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01424963]\n",
      " [ 0.58080339]\n",
      " [-0.09256163]\n",
      " [-0.51521536]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.03051838e-04]\n",
      " [3.37332574e-01]\n",
      " [8.56765592e-03]\n",
      " [2.65446867e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07644376861161999 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31479725]\n",
      " [ 4.31003194]\n",
      " [ 3.57333275]\n",
      " [ 1.59423811]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  740\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08590871]\n",
      " [10.97922829]\n",
      " [18.20786168]\n",
      " [17.98619032]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01409129]\n",
      " [ 0.57922829]\n",
      " [-0.09213832]\n",
      " [-0.51380968]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.98564387e-04]\n",
      " [3.35505407e-01]\n",
      " [8.48946999e-03]\n",
      " [2.64000386e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07602422841443648 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31489928]\n",
      " [ 4.31156839]\n",
      " [ 3.57459685]\n",
      " [ 1.59378105]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  741\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08606559]\n",
      " [10.97765714]\n",
      " [18.20828248]\n",
      " [17.98759191]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01393441]\n",
      " [ 0.57765714]\n",
      " [-0.09171752]\n",
      " [-0.51240809]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.94167903e-04]\n",
      " [3.33687770e-01]\n",
      " [8.41210340e-03]\n",
      " [2.62562056e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07560701215446476 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31500028]\n",
      " [ 4.31310072]\n",
      " [ 3.57585717]\n",
      " [ 1.59332478]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  742\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08622101]\n",
      " [10.97608994]\n",
      " [18.20870079]\n",
      " [17.98898941]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01377899]\n",
      " [ 0.57608994]\n",
      " [-0.09129921]\n",
      " [-0.51101059]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.89860641e-04]\n",
      " [3.31879619e-01]\n",
      " [8.33554649e-03]\n",
      " [2.61131827e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07519210660925399 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31510028]\n",
      " [ 4.31462894]\n",
      " [ 3.57711371]\n",
      " [ 1.5928693 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  743\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08637499]\n",
      " [10.97452668]\n",
      " [18.20911661]\n",
      " [17.99038284]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01362501]\n",
      " [ 0.57452668]\n",
      " [-0.09088339]\n",
      " [-0.50961716]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.85640886e-04]\n",
      " [3.30080909e-01]\n",
      " [8.25978969e-03]\n",
      " [2.59709650e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0747794986375202 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31519928]\n",
      " [ 4.31615305]\n",
      " [ 3.57836649]\n",
      " [ 1.5924146 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  744\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08652755]\n",
      " [10.97296736]\n",
      " [18.20952999]\n",
      " [17.99177222]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01347245]\n",
      " [ 0.57296736]\n",
      " [-0.09047001]\n",
      " [-0.50822778]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.81506960e-04]\n",
      " [3.28291597e-01]\n",
      " [8.18482361e-03]\n",
      " [2.58295474e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0743691751785436 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31529729]\n",
      " [ 4.31767308]\n",
      " [ 3.57961552]\n",
      " [ 1.5919607 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  745\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08667869]\n",
      " [10.97141197]\n",
      " [18.20994091]\n",
      " [17.99315757]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01332131]\n",
      " [ 0.57141197]\n",
      " [-0.09005909]\n",
      " [-0.50684243]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.77457212e-04]\n",
      " [3.26511639e-01]\n",
      " [8.11063892e-03]\n",
      " [2.56889251e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07396112325157755 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31539431]\n",
      " [ 4.31918902]\n",
      " [ 3.58086081]\n",
      " [ 1.59150759]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  746\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08682844]\n",
      " [10.9698605 ]\n",
      " [18.21034942]\n",
      " [17.99453889]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01317156]\n",
      " [ 0.5698605 ]\n",
      " [-0.08965058]\n",
      " [-0.50546111]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.73490023e-04]\n",
      " [3.24740992e-01]\n",
      " [8.03722646e-03]\n",
      " [2.55490931e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07355532995525835 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31549037]\n",
      " [ 4.3207009 ]\n",
      " [ 3.58210237]\n",
      " [ 1.59105527]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  747\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0869768 ]\n",
      " [10.96831295]\n",
      " [18.21075552]\n",
      " [17.99591621]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0130232 ]\n",
      " [ 0.56831295]\n",
      " [-0.08924448]\n",
      " [-0.50408379]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.69603806e-04]\n",
      " [3.22979612e-01]\n",
      " [7.96457716e-03]\n",
      " [2.54100467e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07315178246702209 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31558547]\n",
      " [ 4.32220872]\n",
      " [ 3.58334023]\n",
      " [ 1.59060374]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  748\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08712378]\n",
      " [10.96676932]\n",
      " [18.21115923]\n",
      " [17.99728954]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01287622]\n",
      " [ 0.56676932]\n",
      " [-0.08884077]\n",
      " [-0.50271046]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.65797002e-04]\n",
      " [3.21227456e-01]\n",
      " [7.89268209e-03]\n",
      " [2.52717809e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07275046804252905 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31567961]\n",
      " [ 4.32371249]\n",
      " [ 3.58457438]\n",
      " [ 1.590153  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  749\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0872694 ]\n",
      " [10.96522958]\n",
      " [18.21156057]\n",
      " [17.99865889]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0127306 ]\n",
      " [ 0.56522958]\n",
      " [-0.08843943]\n",
      " [-0.50134111]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.62068082e-04]\n",
      " [3.19484482e-01]\n",
      " [7.82153240e-03]\n",
      " [2.51342910e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07235137401509267 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31577282]\n",
      " [ 4.32521222]\n",
      " [ 3.58580484]\n",
      " [ 1.58970306]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  750\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08741368]\n",
      " [10.96369375]\n",
      " [18.21195956]\n",
      " [18.00002428]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01258632]\n",
      " [ 0.56369375]\n",
      " [-0.08804044]\n",
      " [-0.49997572]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.58415544e-04]\n",
      " [3.17750645e-01]\n",
      " [7.75111940e-03]\n",
      " [2.49975723e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07195448779511411 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31586509]\n",
      " [ 4.32670792]\n",
      " [ 3.58703162]\n",
      " [ 1.58925391]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  751\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08755661]\n",
      " [10.96216181]\n",
      " [18.21235621]\n",
      " [18.00138572]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01244339]\n",
      " [ 0.56216181]\n",
      " [-0.08764379]\n",
      " [-0.49861428]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.54837917e-04]\n",
      " [3.16025903e-01]\n",
      " [7.68143447e-03]\n",
      " [2.48616200e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07155979686952484 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31595644]\n",
      " [ 4.32819961]\n",
      " [ 3.58825474]\n",
      " [ 1.58880556]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  752\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08769822]\n",
      " [10.96063376]\n",
      " [18.21275054]\n",
      " [18.00274323]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01230178]\n",
      " [ 0.56063376]\n",
      " [-0.08724946]\n",
      " [-0.49725677]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.51333754e-04]\n",
      " [3.14310213e-01]\n",
      " [7.61246913e-03]\n",
      " [2.47264295e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07116728880122969 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31604687]\n",
      " [ 4.3296873 ]\n",
      " [ 3.5894742 ]\n",
      " [ 1.588358  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  753\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08783852]\n",
      " [10.95910959]\n",
      " [18.21314256]\n",
      " [18.00409682]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01216148]\n",
      " [ 0.55910959]\n",
      " [-0.08685744]\n",
      " [-0.49590318]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.47901638e-04]\n",
      " [3.12603532e-01]\n",
      " [7.54421499e-03]\n",
      " [2.45919961e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07077695122856031 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3161364 ]\n",
      " [ 4.33117098]\n",
      " [ 3.59069003]\n",
      " [ 1.58791123]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  754\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08797751]\n",
      " [10.95758929]\n",
      " [18.2135323 ]\n",
      " [18.00544651]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01202249]\n",
      " [ 0.55758929]\n",
      " [-0.0864677 ]\n",
      " [-0.49455349]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.44540177e-04]\n",
      " [3.10905819e-01]\n",
      " [7.47666378e-03]\n",
      " [2.44583152e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.07038877186473201 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31622504]\n",
      " [ 4.33265069]\n",
      " [ 3.59190222]\n",
      " [ 1.58746527]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  755\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08811522]\n",
      " [10.95607286]\n",
      " [18.21391976]\n",
      " [18.00679231]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01188478]\n",
      " [ 0.55607286]\n",
      " [-0.08608024]\n",
      " [-0.49320769]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.41248006e-04]\n",
      " [3.09217030e-01]\n",
      " [7.40980734e-03]\n",
      " [2.43253823e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0700027384973071 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31631279]\n",
      " [ 4.33412642]\n",
      " [ 3.5931108 ]\n",
      " [ 1.58702009]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  756\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08825165]\n",
      " [10.9545603 ]\n",
      " [18.21430497]\n",
      " [18.00813424]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01174835]\n",
      " [ 0.5545603 ]\n",
      " [-0.08569503]\n",
      " [-0.49186576]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.38023784e-04]\n",
      " [3.07537123e-01]\n",
      " [7.34363759e-03]\n",
      " [2.41931927e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06961883898766051 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31639966]\n",
      " [ 4.33559818]\n",
      " [ 3.59431577]\n",
      " [ 1.58657572]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  757\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08838681]\n",
      " [10.95305159]\n",
      " [18.21468795]\n",
      " [18.0094723 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01161319]\n",
      " [ 0.55305159]\n",
      " [-0.08531205]\n",
      " [-0.4905277 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.34866197e-04]\n",
      " [3.05866057e-01]\n",
      " [7.27814658e-03]\n",
      " [2.40617421e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06923706127045413 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31648566]\n",
      " [ 4.33706599]\n",
      " [ 3.59551715]\n",
      " [ 1.58613214]] \n",
      "\n",
      "**********************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =  758\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08852072]\n",
      " [10.95154672]\n",
      " [18.2150687 ]\n",
      " [18.01080652]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01147928]\n",
      " [ 0.55154672]\n",
      " [-0.0849313 ]\n",
      " [-0.48919348]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.31773955e-04]\n",
      " [3.04203789e-01]\n",
      " [7.21332644e-03]\n",
      " [2.39310258e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06885739335311342 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31657081]\n",
      " [ 4.33852986]\n",
      " [ 3.59671495]\n",
      " [ 1.58568937]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  759\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08865338]\n",
      " [10.9500457 ]\n",
      " [18.21544724]\n",
      " [18.01213691]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01134662]\n",
      " [ 0.5500457 ]\n",
      " [-0.08455276]\n",
      " [-0.48786309]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.28745792e-04]\n",
      " [3.02550276e-01]\n",
      " [7.14916943e-03]\n",
      " [2.38010395e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06847982331531385 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3166551 ]\n",
      " [ 4.3399898 ]\n",
      " [ 3.59790918]\n",
      " [ 1.58524739]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  760\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08878481]\n",
      " [10.94854852]\n",
      " [18.21582359]\n",
      " [18.01346348]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01121519]\n",
      " [ 0.54854852]\n",
      " [-0.08417641]\n",
      " [-0.48653652]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.25780465e-04]\n",
      " [3.00905479e-01]\n",
      " [7.08566788e-03]\n",
      " [2.36717787e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06810433930846413 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31673855]\n",
      " [ 4.34144581]\n",
      " [ 3.59909984]\n",
      " [ 1.58480621]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  761\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08891502]\n",
      " [10.94705517]\n",
      " [18.21619777]\n",
      " [18.01478624]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01108498]\n",
      " [ 0.54705517]\n",
      " [-0.08380223]\n",
      " [-0.48521376]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.22876756e-04]\n",
      " [2.99269354e-01]\n",
      " [7.02281423e-03]\n",
      " [2.35432391e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06773092955520221 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31682116]\n",
      " [ 4.34289791]\n",
      " [ 3.60028696]\n",
      " [ 1.58436583]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  762\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08904402]\n",
      " [10.94556563]\n",
      " [18.21656978]\n",
      " [18.01610521]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01095598]\n",
      " [ 0.54556563]\n",
      " [-0.08343022]\n",
      " [-0.48389479]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.20033468e-04]\n",
      " [2.97641861e-01]\n",
      " [6.96060101e-03]\n",
      " [2.34154163e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06735958234889307 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31690295]\n",
      " [ 4.34434611]\n",
      " [ 3.60147055]\n",
      " [ 1.58392625]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  763\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08917182]\n",
      " [10.94407992]\n",
      " [18.21693966]\n",
      " [18.01742041]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01082818]\n",
      " [ 0.54407992]\n",
      " [-0.08306034]\n",
      " [-0.48257959]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.17249427e-04]\n",
      " [2.96022958e-01]\n",
      " [6.89902085e-03]\n",
      " [2.32883060e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06699028605312919 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31698392]\n",
      " [ 4.34579042]\n",
      " [ 3.60265061]\n",
      " [ 1.58348746]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  764\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08929844]\n",
      " [10.94259801]\n",
      " [18.2173074 ]\n",
      " [18.01873184]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01070156]\n",
      " [ 0.54259801]\n",
      " [-0.0826926 ]\n",
      " [-0.48126816]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.14523483e-04]\n",
      " [2.94412604e-01]\n",
      " [6.83806649e-03]\n",
      " [2.31619039e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06662302910124053 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31706408]\n",
      " [ 4.34723085]\n",
      " [ 3.60382716]\n",
      " [ 1.58304949]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  765\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08942387]\n",
      " [10.94111991]\n",
      " [18.21767303]\n",
      " [18.02003953]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01057613]\n",
      " [ 0.54111991]\n",
      " [-0.08232697]\n",
      " [-0.47996047]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.11854505e-04]\n",
      " [2.92810758e-01]\n",
      " [6.77773072e-03]\n",
      " [2.30362057e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06625779999580349 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31714344]\n",
      " [ 4.3486674 ]\n",
      " [ 3.60500021]\n",
      " [ 1.58261231]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  766\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08954814]\n",
      " [10.9396456 ]\n",
      " [18.21803655]\n",
      " [18.02134347]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01045186]\n",
      " [ 0.5396456 ]\n",
      " [-0.08196345]\n",
      " [-0.47865653]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.09241384e-04]\n",
      " [2.91217378e-01]\n",
      " [6.71800647e-03]\n",
      " [2.29112073e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06589458730816056 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31722201]\n",
      " [ 4.3501001 ]\n",
      " [ 3.60616976]\n",
      " [ 1.58217593]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  767\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08967125]\n",
      " [10.93817509]\n",
      " [18.218398  ]\n",
      " [18.02264369]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01032875]\n",
      " [ 0.53817509]\n",
      " [-0.081602  ]\n",
      " [-0.47735631]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.06683032e-04]\n",
      " [2.89632425e-01]\n",
      " [6.65888672e-03]\n",
      " [2.27869043e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06553337967794103 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31729979]\n",
      " [ 4.35152894]\n",
      " [ 3.60733584]\n",
      " [ 1.58174035]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  768\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08979322]\n",
      " [10.93670835]\n",
      " [18.21875737]\n",
      " [18.02394021]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01020678]\n",
      " [ 0.53670835]\n",
      " [-0.08124263]\n",
      " [-0.47605979]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.04178382e-04]\n",
      " [2.88055857e-01]\n",
      " [6.60036456e-03]\n",
      " [2.26632927e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06517416581258142 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31737679]\n",
      " [ 4.35295394]\n",
      " [ 3.60849846]\n",
      " [ 1.58130558]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  769\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.08991405]\n",
      " [10.9352454 ]\n",
      " [18.21911469]\n",
      " [18.02523302]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.01008595]\n",
      " [ 0.5352454 ]\n",
      " [-0.08088531]\n",
      " [-0.47476698]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.01726386e-04]\n",
      " [2.86487634e-01]\n",
      " [6.54243317e-03]\n",
      " [2.25403683e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06481693448686383 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31745302]\n",
      " [ 4.35437511]\n",
      " [ 3.60965761]\n",
      " [ 1.58087161]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  770\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09003376]\n",
      " [10.93378621]\n",
      " [18.21946997]\n",
      " [18.02652216]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00996624]\n",
      " [ 0.53378621]\n",
      " [-0.08053003]\n",
      " [-0.47347784]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.93260170e-05]\n",
      " [2.84927715e-01]\n",
      " [6.48508580e-03]\n",
      " [2.24181270e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06446167454244235 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31752849]\n",
      " [ 4.35579246]\n",
      " [ 3.61081332]\n",
      " [ 1.58043844]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  771\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09015235]\n",
      " [10.93233078]\n",
      " [18.21982322]\n",
      " [18.02780762]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00984765]\n",
      " [ 0.53233078]\n",
      " [-0.08017678]\n",
      " [-0.47219238]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.69762659e-05]\n",
      " [2.83376061e-01]\n",
      " [6.42831579e-03]\n",
      " [2.22965646e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0641083748873883 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31760321]\n",
      " [ 4.357206  ]\n",
      " [ 3.6119656 ]\n",
      " [ 1.58000607]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  772\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09026983]\n",
      " [10.93087911]\n",
      " [18.22017446]\n",
      " [18.02908942]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00973017]\n",
      " [ 0.53087911]\n",
      " [-0.07982554]\n",
      " [-0.47091058]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.46761435e-05]\n",
      " [2.81832630e-01]\n",
      " [6.37211658e-03]\n",
      " [2.21756773e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06375702449572701 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31767717]\n",
      " [ 4.35861574]\n",
      " [ 3.61311446]\n",
      " [ 1.57957451]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  773\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09038622]\n",
      " [10.92943119]\n",
      " [18.2205237 ]\n",
      " [18.03036758]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00961378]\n",
      " [ 0.52943119]\n",
      " [-0.0794763 ]\n",
      " [-0.46963242]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.24246788e-05]\n",
      " [2.80297384e-01]\n",
      " [6.31648167e-03]\n",
      " [2.20554609e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06340761240699046 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3177504 ]\n",
      " [ 4.36002169]\n",
      " [ 3.6142599 ]\n",
      " [ 1.57914375]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  774\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09050153]\n",
      " [10.92798701]\n",
      " [18.22087096]\n",
      " [18.03164211]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00949847]\n",
      " [ 0.52798701]\n",
      " [-0.07912904]\n",
      " [-0.46835789]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.02209194e-05]\n",
      " [2.78770283e-01]\n",
      " [6.26140466e-03]\n",
      " [2.19359114e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06306012772576411 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3178229 ]\n",
      " [ 4.36142386]\n",
      " [ 3.61540195]\n",
      " [ 1.57871379]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  775\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09061576]\n",
      " [10.92654657]\n",
      " [18.22121625]\n",
      " [18.03291302]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00938424]\n",
      " [ 0.52654657]\n",
      " [-0.07878375]\n",
      " [-0.46708698]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.80639304e-05]\n",
      " [2.77251286e-01]\n",
      " [6.20687922e-03]\n",
      " [2.18170248e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06271455962124474 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31789467]\n",
      " [ 4.36282225]\n",
      " [ 3.6165406 ]\n",
      " [ 1.57828464]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  776\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09072893]\n",
      " [10.92510985]\n",
      " [18.22155958]\n",
      " [18.03418032]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00927107]\n",
      " [ 0.52510985]\n",
      " [-0.07844042]\n",
      " [-0.46581968]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.59527950e-05]\n",
      " [2.75740354e-01]\n",
      " [6.15289910e-03]\n",
      " [2.16987973e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06237089732679796 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31796572]\n",
      " [ 4.36421689]\n",
      " [ 3.61767588]\n",
      " [ 1.57785629]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  777\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09084104]\n",
      " [10.92367685]\n",
      " [18.22190097]\n",
      " [18.03544403]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00915896]\n",
      " [ 0.52367685]\n",
      " [-0.07809903]\n",
      " [-0.46455597]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.38866134e-05]\n",
      " [2.74237448e-01]\n",
      " [6.09945813e-03]\n",
      " [2.15812249e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06202913013952352 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31803607]\n",
      " [ 4.36560778]\n",
      " [ 3.61880779]\n",
      " [ 1.57742874]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  778\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0909521 ]\n",
      " [10.92224757]\n",
      " [18.22224043]\n",
      " [18.03670416]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0090479 ]\n",
      " [ 0.52224757]\n",
      " [-0.07775957]\n",
      " [-0.46329584]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.18645027e-05]\n",
      " [2.72742528e-01]\n",
      " [6.04655021e-03]\n",
      " [2.14643037e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06168924741982144 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31810571]\n",
      " [ 4.36699492]\n",
      " [ 3.61993634]\n",
      " [ 1.577002  ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  779\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09106213]\n",
      " [10.920822  ]\n",
      " [18.22257798]\n",
      " [18.03796072]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00893787]\n",
      " [ 0.520822  ]\n",
      " [-0.07742202]\n",
      " [-0.46203928]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.98855968e-05]\n",
      " [2.71255555e-01]\n",
      " [5.99416934e-03]\n",
      " [2.13480299e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.061351238590962406 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31817465]\n",
      " [ 4.36837833]\n",
      " [ 3.62106155]\n",
      " [ 1.57657606]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  780\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09117112]\n",
      " [10.91940013]\n",
      " [18.22291362]\n",
      " [18.03921372]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00882888]\n",
      " [ 0.51940013]\n",
      " [-0.07708638]\n",
      " [-0.46078628]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.79490458e-05]\n",
      " [2.69776491e-01]\n",
      " [5.94230957e-03]\n",
      " [2.12323995e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.06101509313866367 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3182429 ]\n",
      " [ 4.36975802]\n",
      " [ 3.62218343]\n",
      " [ 1.57615093]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  781\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0912791 ]\n",
      " [10.91798195]\n",
      " [18.22324738]\n",
      " [18.04046318]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0087209 ]\n",
      " [ 0.51798195]\n",
      " [-0.07675262]\n",
      " [-0.45953682]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.60540160e-05]\n",
      " [2.68305296e-01]\n",
      " [5.89096503e-03]\n",
      " [2.11174090e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.060680800610667024 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31831047]\n",
      " [ 4.371134  ]\n",
      " [ 3.62330197]\n",
      " [ 1.5757266 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  782\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09138608]\n",
      " [10.91656745]\n",
      " [18.22357926]\n",
      " [18.04170911]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00861392]\n",
      " [ 0.51656745]\n",
      " [-0.07642074]\n",
      " [-0.45829089]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.41996893e-05]\n",
      " [2.66841932e-01]\n",
      " [5.84012993e-03]\n",
      " [2.10030543e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.060348350616322544 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31837737]\n",
      " [ 4.37250628]\n",
      " [ 3.62441721]\n",
      " [ 1.57530308]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  783\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09149205]\n",
      " [10.91515664]\n",
      " [18.22390927]\n",
      " [18.04295151]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00850795]\n",
      " [ 0.51515664]\n",
      " [-0.07609073]\n",
      " [-0.45704849]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.23852631e-05]\n",
      " [2.65386361e-01]\n",
      " [5.78979855e-03]\n",
      " [2.08893318e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.060017732826172523 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31844359]\n",
      " [ 4.37387487]\n",
      " [ 3.62552914]\n",
      " [ 1.57488036]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  784\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09159703]\n",
      " [10.91374949]\n",
      " [18.22423744]\n",
      " [18.04419041]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00840297]\n",
      " [ 0.51374949]\n",
      " [-0.07576256]\n",
      " [-0.45580959]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.06099499e-05]\n",
      " [2.63938543e-01]\n",
      " [5.73996523e-03]\n",
      " [2.07762378e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05968893697154394 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31850916]\n",
      " [ 4.37523977]\n",
      " [ 3.62663779]\n",
      " [ 1.57445844]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  785\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09170103]\n",
      " [10.91234602]\n",
      " [18.22456377]\n",
      " [18.04542582]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00829897]\n",
      " [ 0.51234602]\n",
      " [-0.07543623]\n",
      " [-0.45457418]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.88729772e-05]\n",
      " [2.62498440e-01]\n",
      " [5.69062440e-03]\n",
      " [2.06637685e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05936195284413857 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31857407]\n",
      " [ 4.376601  ]\n",
      " [ 3.62774315]\n",
      " [ 1.57403733]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  786\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09180405]\n",
      " [10.9109462 ]\n",
      " [18.22488828]\n",
      " [18.04665774]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00819595]\n",
      " [ 0.5109462 ]\n",
      " [-0.07511172]\n",
      " [-0.45334226]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.71735869e-05]\n",
      " [2.61066015e-01]\n",
      " [5.64177054e-03]\n",
      " [2.05519203e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05903677029563412 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31863833]\n",
      " [ 4.37795857]\n",
      " [ 3.62884523]\n",
      " [ 1.57361703]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  787\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09190611]\n",
      " [10.90955003]\n",
      " [18.22521098]\n",
      " [18.04788619]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00809389]\n",
      " [ 0.50955003]\n",
      " [-0.07478902]\n",
      " [-0.45211381]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.55110354e-05]\n",
      " [2.59641229e-01]\n",
      " [5.59339821e-03]\n",
      " [2.04406895e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05871337923727871 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31870194]\n",
      " [ 4.37931248]\n",
      " [ 3.62994406]\n",
      " [ 1.57319752]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  788\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09200722]\n",
      " [10.9081575 ]\n",
      " [18.22553187]\n",
      " [18.04911118]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00799278]\n",
      " [ 0.5081575 ]\n",
      " [-0.07446813]\n",
      " [-0.45088882]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.38845931e-05]\n",
      " [2.58224045e-01]\n",
      " [5.54550205e-03]\n",
      " [2.03300725e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05839176963950113 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31876492]\n",
      " [ 4.38066275]\n",
      " [ 3.63103964]\n",
      " [ 1.57277883]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  789\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09210737]\n",
      " [10.90676861]\n",
      " [18.22585098]\n",
      " [18.05033273]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00789263]\n",
      " [ 0.50676861]\n",
      " [-0.07414902]\n",
      " [-0.44966727]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.22935442e-05]\n",
      " [2.56814425e-01]\n",
      " [5.49807672e-03]\n",
      " [2.02200657e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05807193153151302 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31882727]\n",
      " [ 4.38200939]\n",
      " [ 3.63213198]\n",
      " [ 1.57236093]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  790\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09220659]\n",
      " [10.90538335]\n",
      " [18.22616832]\n",
      " [18.05155083]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00779341]\n",
      " [ 0.50538335]\n",
      " [-0.07383168]\n",
      " [-0.44844917]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.07371866e-05]\n",
      " [2.55412331e-01]\n",
      " [5.45111700e-03]\n",
      " [2.01106655e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05775385500092477 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.318889  ]\n",
      " [ 4.3833524 ]\n",
      " [ 3.63322109]\n",
      " [ 1.57194385]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  791\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09230488]\n",
      " [10.90400171]\n",
      " [18.22648389]\n",
      " [18.05276552]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00769512]\n",
      " [ 0.50400171]\n",
      " [-0.07351611]\n",
      " [-0.44723448]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.92148311e-05]\n",
      " [2.54017726e-01]\n",
      " [5.40461771e-03]\n",
      " [2.00018683e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05743753019335146 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31895011]\n",
      " [ 4.3846918 ]\n",
      " [ 3.63430699]\n",
      " [ 1.57152756]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  792\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09240225]\n",
      " [10.90262369]\n",
      " [18.22679772]\n",
      " [18.05397679]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00759775]\n",
      " [ 0.50262369]\n",
      " [-0.07320228]\n",
      " [-0.44602321]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.77258021e-05]\n",
      " [2.52630572e-01]\n",
      " [5.35857372e-03]\n",
      " [1.98936707e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.057122947312040456 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31901061]\n",
      " [ 4.38602759]\n",
      " [ 3.63538967]\n",
      " [ 1.57111208]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  793\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0924987 ]\n",
      " [10.90124927]\n",
      " [18.22710981]\n",
      " [18.05518466]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0075013 ]\n",
      " [ 0.50124927]\n",
      " [-0.07289019]\n",
      " [-0.44481534]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.62694363e-05]\n",
      " [2.51250833e-01]\n",
      " [5.31298000e-03]\n",
      " [1.97860690e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05681009661748253 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3190705 ]\n",
      " [ 4.38735978]\n",
      " [ 3.63646916]\n",
      " [ 1.57069741]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  794\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09259425]\n",
      " [10.89987846]\n",
      " [18.22742017]\n",
      " [18.05638914]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00740575]\n",
      " [ 0.49987846]\n",
      " [-0.07257983]\n",
      " [-0.44361086]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.48450832e-05]\n",
      " [2.49878472e-01]\n",
      " [5.26783154e-03]\n",
      " [1.96790599e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0564989684270424 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3191298 ]\n",
      " [ 4.38868839]\n",
      " [ 3.63754546]\n",
      " [ 1.57028354]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  795\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09268891]\n",
      " [10.89851123]\n",
      " [18.22772882]\n",
      " [18.05759024]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00731109]\n",
      " [ 0.49851123]\n",
      " [-0.07227118]\n",
      " [-0.44240976]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.34521047e-05]\n",
      " [2.48513451e-01]\n",
      " [5.22312342e-03]\n",
      " [1.95726398e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05618955311457996 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3191885 ]\n",
      " [ 4.39001342]\n",
      " [ 3.63861858]\n",
      " [ 1.56987047]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  796\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09278267]\n",
      " [10.8971476 ]\n",
      " [18.22803577]\n",
      " [18.05878797]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00721733]\n",
      " [ 0.4971476 ]\n",
      " [-0.07196423]\n",
      " [-0.44121203]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.20898747e-05]\n",
      " [2.47155734e-01]\n",
      " [5.17885078e-03]\n",
      " [1.94668054e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05588184111008637 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31924662]\n",
      " [ 4.39133488]\n",
      " [ 3.63968853]\n",
      " [ 1.56945821]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  797\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09287555]\n",
      " [10.89578754]\n",
      " [18.22834102]\n",
      " [18.05998235]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00712445]\n",
      " [ 0.49578754]\n",
      " [-0.07165898]\n",
      " [-0.44001765]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.07577790e-05]\n",
      " [2.45805285e-01]\n",
      " [5.13500880e-03]\n",
      " [1.93615532e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05557582289931272 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31930415]\n",
      " [ 4.39265279]\n",
      " [ 3.64075533]\n",
      " [ 1.56904675]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  798\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09296756]\n",
      " [10.89443105]\n",
      " [18.2286446 ]\n",
      " [18.06117339]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00703244]\n",
      " [ 0.49443105]\n",
      " [-0.0713554 ]\n",
      " [-0.43882661]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.94552151e-05]\n",
      " [2.44462066e-01]\n",
      " [5.09159273e-03]\n",
      " [1.92568798e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05527148902340869 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31936111]\n",
      " [ 4.39396715]\n",
      " [ 3.64181898]\n",
      " [ 1.5686361 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  799\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0930587 ]\n",
      " [10.89307813]\n",
      " [18.22894651]\n",
      " [18.06236109]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0069413 ]\n",
      " [ 0.49307813]\n",
      " [-0.07105349]\n",
      " [-0.43763891]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.81815919e-05]\n",
      " [2.43126043e-01]\n",
      " [5.04859789e-03]\n",
      " [1.91527819e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05496883007855985 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3194175 ]\n",
      " [ 4.39527796]\n",
      " [ 3.64287949]\n",
      " [ 1.56822625]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  800\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09314899]\n",
      " [10.89172876]\n",
      " [18.22924677]\n",
      " [18.06354547]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00685101]\n",
      " [ 0.49172876]\n",
      " [-0.07075323]\n",
      " [-0.43645453]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.69363296e-05]\n",
      " [2.41797178e-01]\n",
      " [5.00601965e-03]\n",
      " [1.90492560e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05466783671563141 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31947332]\n",
      " [ 4.39658525]\n",
      " [ 3.64393688]\n",
      " [ 1.5678172 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  801\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09323843]\n",
      " [10.89038295]\n",
      " [18.22954538]\n",
      " [18.06472653]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00676157]\n",
      " [ 0.49038295]\n",
      " [-0.07045462]\n",
      " [-0.43527347]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.57188592e-05]\n",
      " [2.40475435e-01]\n",
      " [4.96385341e-03]\n",
      " [1.89462990e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05436849963981387 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31952859]\n",
      " [ 4.39788901]\n",
      " [ 3.64499115]\n",
      " [ 1.56740896]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  802\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09332702]\n",
      " [10.88904067]\n",
      " [18.22984236]\n",
      " [18.0659043 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00667298]\n",
      " [ 0.48904067]\n",
      " [-0.07015764]\n",
      " [-0.4340957 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.45286230e-05]\n",
      " [2.39160780e-01]\n",
      " [4.92209467e-03]\n",
      " [1.88439074e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.054070809610269575 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3195833 ]\n",
      " [ 4.39918927]\n",
      " [ 3.64604231]\n",
      " [ 1.56700151]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  803\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09341478]\n",
      " [10.88770193]\n",
      " [18.23013771]\n",
      " [18.06707878]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00658522]\n",
      " [ 0.48770193]\n",
      " [-0.06986229]\n",
      " [-0.43292122]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.33650733e-05]\n",
      " [2.37853175e-01]\n",
      " [4.88073895e-03]\n",
      " [1.87420780e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05377475743978592 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31963747]\n",
      " [ 4.40048602]\n",
      " [ 3.64709038]\n",
      " [ 1.56659488]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  804\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09350172]\n",
      " [10.88636672]\n",
      " [18.23043146]\n",
      " [18.06824998]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00649828]\n",
      " [ 0.48636672]\n",
      " [-0.06956854]\n",
      " [-0.43175002]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.22276734e-05]\n",
      " [2.36552587e-01]\n",
      " [4.83978185e-03]\n",
      " [1.86408076e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05348033399442542 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3196911 ]\n",
      " [ 4.40177928]\n",
      " [ 3.64813536]\n",
      " [ 1.56618904]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  805\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09358783]\n",
      " [10.88503503]\n",
      " [18.2307236 ]\n",
      " [18.06941792]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00641217]\n",
      " [ 0.48503503]\n",
      " [-0.0692764 ]\n",
      " [-0.43058208]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.11158963e-05]\n",
      " [2.35258978e-01]\n",
      " [4.79921900e-03]\n",
      " [1.85400929e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05318753019318827 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31974418]\n",
      " [ 4.40306905]\n",
      " [ 3.64917726]\n",
      " [ 1.56578401]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  806\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09367313]\n",
      " [10.88370685]\n",
      " [18.23101416]\n",
      " [18.0705826 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00632687]\n",
      " [ 0.48370685]\n",
      " [-0.06898584]\n",
      " [-0.4294174 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.00292256e-05]\n",
      " [2.33972314e-01]\n",
      " [4.75904610e-03]\n",
      " [1.84399306e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.052896337007665994 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31979674]\n",
      " [ 4.40435535]\n",
      " [ 3.65021609]\n",
      " [ 1.56537978]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  807\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09375763]\n",
      " [10.88238217]\n",
      " [18.23130314]\n",
      " [18.07174403]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00624237]\n",
      " [ 0.48238217]\n",
      " [-0.06869686]\n",
      " [-0.42825597]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.89671542e-05]\n",
      " [2.32692561e-01]\n",
      " [4.71925890e-03]\n",
      " [1.83403177e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.052606745461708335 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31984878]\n",
      " [ 4.40563819]\n",
      " [ 3.65125187]\n",
      " [ 1.56497635]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  808\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09384133]\n",
      " [10.881061  ]\n",
      " [18.23159055]\n",
      " [18.07290223]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00615867]\n",
      " [ 0.481061  ]\n",
      " [-0.06840945]\n",
      " [-0.42709777]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.79291851e-05]\n",
      " [2.31419682e-01]\n",
      " [4.67985320e-03]\n",
      " [1.82412509e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05231874663108531 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31990029]\n",
      " [ 4.40691756]\n",
      " [ 3.6522846 ]\n",
      " [ 1.56457372]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  809\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09392424]\n",
      " [10.87974331]\n",
      " [18.2318764 ]\n",
      " [18.0740572 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00607576]\n",
      " [ 0.47974331]\n",
      " [-0.0681236 ]\n",
      " [-0.4259428 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.69148305e-05]\n",
      " [2.30153643e-01]\n",
      " [4.64082485e-03]\n",
      " [1.81427270e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05203233164315629 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.31995128]\n",
      " [ 4.4081935 ]\n",
      " [ 3.65331429]\n",
      " [ 1.56417189]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  810\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09400637]\n",
      " [10.87842911]\n",
      " [18.23216071]\n",
      " [18.07520896]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00599363]\n",
      " [ 0.47842911]\n",
      " [-0.06783929]\n",
      " [-0.42479104]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.59236121e-05]\n",
      " [2.28894410e-01]\n",
      " [4.60216974e-03]\n",
      " [1.80447430e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.051747491676540365 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32000177]\n",
      " [ 4.40946599]\n",
      " [ 3.65434095]\n",
      " [ 1.56377087]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  811\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09408772]\n",
      " [10.87711838]\n",
      " [18.23244348]\n",
      " [18.07635751]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00591228]\n",
      " [ 0.47711838]\n",
      " [-0.06755652]\n",
      " [-0.42364249]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.49550606e-05]\n",
      " [2.27641948e-01]\n",
      " [4.56388382e-03]\n",
      " [1.79472957e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.051464217960788664 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32005175]\n",
      " [ 4.41073505]\n",
      " [ 3.65536459]\n",
      " [ 1.56337065]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  812\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0941683 ]\n",
      " [10.87581112]\n",
      " [18.23272472]\n",
      " [18.07750288]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0058317 ]\n",
      " [ 0.47581112]\n",
      " [-0.06727528]\n",
      " [-0.42249712]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.40087157e-05]\n",
      " [2.26396222e-01]\n",
      " [4.52596310e-03]\n",
      " [1.78503821e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.051182501776060395 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32010124]\n",
      " [ 4.4120007 ]\n",
      " [ 3.65638522]\n",
      " [ 1.56297122]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  813\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09424812]\n",
      " [10.87450732]\n",
      " [18.23300445]\n",
      " [18.07864505]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00575188]\n",
      " [ 0.47450732]\n",
      " [-0.06699555]\n",
      " [-0.42135495]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.30841260e-05]\n",
      " [2.25157198e-01]\n",
      " [4.48840362e-03]\n",
      " [1.77539990e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.050902334452802345 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32015022]\n",
      " [ 4.41326293]\n",
      " [ 3.65740286]\n",
      " [ 1.5625726 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  814\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09432718]\n",
      " [10.87320698]\n",
      " [18.23328267]\n",
      " [18.07978406]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00567282]\n",
      " [ 0.47320698]\n",
      " [-0.06671733]\n",
      " [-0.42021594]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.21808487e-05]\n",
      " [2.23924843e-01]\n",
      " [4.45120147e-03]\n",
      " [1.76581434e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05062370737142659 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32019872]\n",
      " [ 4.41452176]\n",
      " [ 3.6584175 ]\n",
      " [ 1.56217477]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  815\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0944055 ]\n",
      " [10.87191008]\n",
      " [18.2335594 ]\n",
      " [18.08091991]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0055945 ]\n",
      " [ 0.47191008]\n",
      " [-0.0664406 ]\n",
      " [-0.41908009]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.12984494e-05]\n",
      " [2.22699121e-01]\n",
      " [4.41435279e-03]\n",
      " [1.75628123e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05034661196199727 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32024673]\n",
      " [ 4.4157772 ]\n",
      " [ 3.65942916]\n",
      " [ 1.56177775]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  816\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09448307]\n",
      " [10.87061662]\n",
      " [18.23383465]\n",
      " [18.0820526 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00551693]\n",
      " [ 0.47061662]\n",
      " [-0.06616535]\n",
      " [-0.4179474 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.04365021e-05]\n",
      " [2.21480001e-01]\n",
      " [4.37785378e-03]\n",
      " [1.74680027e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.05007103970391352 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32029427]\n",
      " [ 4.41702925]\n",
      " [ 3.66043786]\n",
      " [ 1.56138153]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  817\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09455991]\n",
      " [10.86932659]\n",
      " [18.23410842]\n",
      " [18.08318216]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00544009]\n",
      " [ 0.46932659]\n",
      " [-0.06589158]\n",
      " [-0.41681784]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.95945889e-05]\n",
      " [2.20267446e-01]\n",
      " [4.34170066e-03]\n",
      " [1.73737115e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04979698212560069 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32034132]\n",
      " [ 4.41827793]\n",
      " [ 3.66144359]\n",
      " [ 1.5609861 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  818\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09463602]\n",
      " [10.86803998]\n",
      " [18.23438072]\n",
      " [18.08430858]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00536398]\n",
      " [ 0.46803998]\n",
      " [-0.06561928]\n",
      " [-0.41569142]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.87722999e-05]\n",
      " [2.19061425e-01]\n",
      " [4.30588971e-03]\n",
      " [1.72799359e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04952443080419716 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32038791]\n",
      " [ 4.41952324]\n",
      " [ 3.66244636]\n",
      " [ 1.56059147]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  819\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09471141]\n",
      " [10.86675679]\n",
      " [18.23465157]\n",
      " [18.08543188]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00528859]\n",
      " [ 0.46675679]\n",
      " [-0.06534843]\n",
      " [-0.41456812]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.79692331e-05]\n",
      " [2.17861904e-01]\n",
      " [4.27041726e-03]\n",
      " [1.71866728e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04925337736525188 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32043403]\n",
      " [ 4.4207652 ]\n",
      " [ 3.6634462 ]\n",
      " [ 1.56019764]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  820\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09478608]\n",
      " [10.86547701]\n",
      " [18.23492097]\n",
      " [18.08655207]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00521392]\n",
      " [ 0.46547701]\n",
      " [-0.06507903]\n",
      " [-0.41344793]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.71849944e-05]\n",
      " [2.16668850e-01]\n",
      " [4.23527967e-03]\n",
      " [1.70939194e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04898381348241536 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32047969]\n",
      " [ 4.42200381]\n",
      " [ 3.6644431 ]\n",
      " [ 1.55980461]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  821\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09486004]\n",
      " [10.86420063]\n",
      " [18.23518894]\n",
      " [18.08766915]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00513996]\n",
      " [ 0.46420063]\n",
      " [-0.06481106]\n",
      " [-0.41233085]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.64191969e-05]\n",
      " [2.15482228e-01]\n",
      " [4.20047335e-03]\n",
      " [1.70016726e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04871573087714093 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3205249 ]\n",
      " [ 4.42323907]\n",
      " [ 3.66543708]\n",
      " [ 1.55941237]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  822\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0949333 ]\n",
      " [10.86292765]\n",
      " [18.23545548]\n",
      " [18.08878315]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0050667 ]\n",
      " [ 0.46292765]\n",
      " [-0.06454452]\n",
      " [-0.41121685]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.56714614e-05]\n",
      " [2.14302008e-01]\n",
      " [4.16599476e-03]\n",
      " [1.69099297e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04844912131838498 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32056965]\n",
      " [ 4.42447101]\n",
      " [ 3.66642814]\n",
      " [ 1.55902094]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  823\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09500586]\n",
      " [10.86165805]\n",
      " [18.23572061]\n",
      " [18.08989407]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00499414]\n",
      " [ 0.46165805]\n",
      " [-0.06427939]\n",
      " [-0.41010593]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.49414160e-05]\n",
      " [2.13128155e-01]\n",
      " [4.13184038e-03]\n",
      " [1.68186876e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04818397662230575 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32061395]\n",
      " [ 4.42569963]\n",
      " [ 3.66741629]\n",
      " [ 1.55863029]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  824\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09507773]\n",
      " [10.86039183]\n",
      " [18.23598432]\n",
      " [18.09100191]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00492227]\n",
      " [ 0.46039183]\n",
      " [-0.06401568]\n",
      " [-0.40899809]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.42286958e-05]\n",
      " [2.11960637e-01]\n",
      " [4.09800677e-03]\n",
      " [1.67279437e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.047920288651973085 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32065781]\n",
      " [ 4.42692493]\n",
      " [ 3.66840155]\n",
      " [ 1.55824045]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  825\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09514892]\n",
      " [10.85912898]\n",
      " [18.23624664]\n",
      " [18.09210669]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00485108]\n",
      " [ 0.45912898]\n",
      " [-0.06375336]\n",
      " [-0.40789331]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.35329429e-05]\n",
      " [2.10799421e-01]\n",
      " [4.06449049e-03]\n",
      " [1.66376950e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04765804931707111 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32070123]\n",
      " [ 4.42814693]\n",
      " [ 3.66938392]\n",
      " [ 1.5578514 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  826\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09521943]\n",
      " [10.8578695 ]\n",
      " [18.23650757]\n",
      " [18.09320842]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00478057]\n",
      " [ 0.4578695 ]\n",
      " [-0.06349243]\n",
      " [-0.40679158]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.28538066e-05]\n",
      " [2.09644476e-01]\n",
      " [4.03128816e-03]\n",
      " [1.65479386e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04739725057361069 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32074422]\n",
      " [ 4.42936563]\n",
      " [ 3.67036341]\n",
      " [ 1.55746314]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  827\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09528927]\n",
      " [10.85661337]\n",
      " [18.23676713]\n",
      " [18.09430711]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00471073]\n",
      " [ 0.45661337]\n",
      " [-0.06323287]\n",
      " [-0.40569289]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.21909426e-05]\n",
      " [2.08495769e-01]\n",
      " [3.99839645e-03]\n",
      " [1.64586719e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04713788442363984 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32078678]\n",
      " [ 4.43058105]\n",
      " [ 3.67134004]\n",
      " [ 1.55707568]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  828\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09535845]\n",
      " [10.85536059]\n",
      " [18.23702531]\n",
      " [18.09540277]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00464155]\n",
      " [ 0.45536059]\n",
      " [-0.06297469]\n",
      " [-0.40459723]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.15440135e-05]\n",
      " [2.07353267e-01]\n",
      " [3.96581205e-03]\n",
      " [1.63698920e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04687994291495558 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32082891]\n",
      " [ 4.43179319]\n",
      " [ 3.6723138 ]\n",
      " [ 1.55668902]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  829\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09542696]\n",
      " [10.85411115]\n",
      " [18.23728213]\n",
      " [18.0964954 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00457304]\n",
      " [ 0.45411115]\n",
      " [-0.06271787]\n",
      " [-0.4035046 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.09126883e-05]\n",
      " [2.06216939e-01]\n",
      " [3.93353170e-03]\n",
      " [1.62815962e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04662341814082337 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32087062]\n",
      " [ 4.43300205]\n",
      " [ 3.67328471]\n",
      " [ 1.55630314]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  830\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09549482]\n",
      " [10.85286505]\n",
      " [18.23753759]\n",
      " [18.09758502]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00450518]\n",
      " [ 0.45286505]\n",
      " [-0.06246241]\n",
      " [-0.40241498]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.02966423e-05]\n",
      " [2.05086753e-01]\n",
      " [3.90155218e-03]\n",
      " [1.61937816e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.046368302239692544 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32091191]\n",
      " [ 4.43420766]\n",
      " [ 3.67425278]\n",
      " [ 1.55591806]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  831\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09556203]\n",
      " [10.85162227]\n",
      " [18.23779172]\n",
      " [18.09867164]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00443797]\n",
      " [ 0.45162227]\n",
      " [-0.06220828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-0.40132836]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.96955573e-05]\n",
      " [2.03962677e-01]\n",
      " [3.86987029e-03]\n",
      " [1.61064456e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.046114587394916896 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3209528 ]\n",
      " [ 4.43541002]\n",
      " [ 3.67521802]\n",
      " [ 1.55553377]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  832\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0956286 ]\n",
      " [10.85038281]\n",
      " [18.23804451]\n",
      " [18.09975526]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0043714 ]\n",
      " [ 0.45038281]\n",
      " [-0.06195549]\n",
      " [-0.40024474]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.91091210e-05]\n",
      " [2.02844680e-01]\n",
      " [3.83848290e-03]\n",
      " [1.60195855e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04586226583447821 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32099327]\n",
      " [ 4.43660913]\n",
      " [ 3.67618043]\n",
      " [ 1.55515028]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  833\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09569454]\n",
      " [10.84914667]\n",
      " [18.23829597]\n",
      " [18.10083589]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00430546]\n",
      " [ 0.44914667]\n",
      " [-0.06170403]\n",
      " [-0.39916411]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.85370274e-05]\n",
      " [2.01732730e-01]\n",
      " [3.80738689e-03]\n",
      " [1.59331985e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04561132983070734 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32103333]\n",
      " [ 4.43780501]\n",
      " [ 3.67714003]\n",
      " [ 1.55476758]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  834\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09575984]\n",
      " [10.84791383]\n",
      " [18.23854612]\n",
      " [18.10191355]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00424016]\n",
      " [ 0.44791383]\n",
      " [-0.06145388]\n",
      " [-0.39808645]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.79789763e-05]\n",
      " [2.00626796e-01]\n",
      " [3.77657919e-03]\n",
      " [1.58472819e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.045361771700014944 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.321073  ]\n",
      " [ 4.43899766]\n",
      " [ 3.67809682]\n",
      " [ 1.55438566]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  835\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09582452]\n",
      " [10.84668428]\n",
      " [18.23879496]\n",
      " [18.10298825]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00417548]\n",
      " [ 0.44668428]\n",
      " [-0.06120504]\n",
      " [-0.39701175]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.74346732e-05]\n",
      " [1.99526848e-01]\n",
      " [3.74605676e-03]\n",
      " [1.57618331e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.045113583802616986 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32111227]\n",
      " [ 4.44018709]\n",
      " [ 3.67905081]\n",
      " [ 1.55400454]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  836\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09588857]\n",
      " [10.84545803]\n",
      " [18.2390425 ]\n",
      " [18.10405999]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00411143]\n",
      " [ 0.44545803]\n",
      " [-0.0609575 ]\n",
      " [-0.39594001]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.69038296e-05]\n",
      " [1.98432853e-01]\n",
      " [3.71581660e-03]\n",
      " [1.56768495e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04486675854226528 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32115115]\n",
      " [ 4.44137332]\n",
      " [ 3.68000202]\n",
      " [ 1.55362421]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  837\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09595202]\n",
      " [10.84423505]\n",
      " [18.23928875]\n",
      " [18.10512878]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00404798]\n",
      " [ 0.44423505]\n",
      " [-0.06071125]\n",
      " [-0.39487122]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.63861622e-05]\n",
      " [1.97344781e-01]\n",
      " [3.68585574e-03]\n",
      " [1.55923284e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04462128836598057 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32118964]\n",
      " [ 4.44255634]\n",
      " [ 3.68095044]\n",
      " [ 1.55324467]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  838\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09601485]\n",
      " [10.84301535]\n",
      " [18.23953372]\n",
      " [18.10619463]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00398515]\n",
      " [ 0.44301535]\n",
      " [-0.06046628]\n",
      " [-0.39380537]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.58813936e-05]\n",
      " [1.96262601e-01]\n",
      " [3.65617124e-03]\n",
      " [1.55082672e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04437716576378803 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32122774]\n",
      " [ 4.44373617]\n",
      " [ 3.68189609]\n",
      " [ 1.55286591]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  839\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09607709]\n",
      " [10.84179892]\n",
      " [18.23977741]\n",
      " [18.10725755]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00392291]\n",
      " [ 0.44179892]\n",
      " [-0.06022259]\n",
      " [-0.39274245]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.53892515e-05]\n",
      " [1.95186284e-01]\n",
      " [3.62676022e-03]\n",
      " [1.54246633e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04413438326845013 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32126546]\n",
      " [ 4.44491282]\n",
      " [ 3.68283898]\n",
      " [ 1.55248795]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  840\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09613872]\n",
      " [10.84058574]\n",
      " [18.24001984]\n",
      " [18.10831755]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00386128]\n",
      " [ 0.44058574]\n",
      " [-0.05998016]\n",
      " [-0.39168245]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.49094692e-05]\n",
      " [1.94115797e-01]\n",
      " [3.59761980e-03]\n",
      " [1.53415141e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04389293345520984 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32130281]\n",
      " [ 4.44608629]\n",
      " [ 3.68377912]\n",
      " [ 1.55211077]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  841\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09619977]\n",
      " [10.83937582]\n",
      " [18.24026101]\n",
      " [18.10937464]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00380023]\n",
      " [ 0.43937582]\n",
      " [-0.05973899]\n",
      " [-0.39062536]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.44417848e-05]\n",
      " [1.93051112e-01]\n",
      " [3.56874715e-03]\n",
      " [1.52588171e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04365280894152539 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32133978]\n",
      " [ 4.4472566 ]\n",
      " [ 3.68471651]\n",
      " [ 1.55173438]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  842\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09626022]\n",
      " [10.83816914]\n",
      " [18.24050093]\n",
      " [18.11042883]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00373978]\n",
      " [ 0.43816914]\n",
      " [-0.05949907]\n",
      " [-0.38957117]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.39859417e-05]\n",
      " [1.91992197e-01]\n",
      " [3.54013949e-03]\n",
      " [1.51765696e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04341400238681662 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32137638]\n",
      " [ 4.44842374]\n",
      " [ 3.68565116]\n",
      " [ 1.55135877]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  843\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0963201 ]\n",
      " [10.8369657 ]\n",
      " [18.24073961]\n",
      " [18.11148013]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0036799 ]\n",
      " [ 0.4369657 ]\n",
      " [-0.05926039]\n",
      " [-0.38851987]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.35416885e-05]\n",
      " [1.90939024e-01]\n",
      " [3.51179404e-03]\n",
      " [1.50947692e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04317650649220687 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32141262]\n",
      " [ 4.44958774]\n",
      " [ 3.68658309]\n",
      " [ 1.55098396]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  844\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0963794 ]\n",
      " [10.83576549]\n",
      " [18.24097705]\n",
      " [18.11252854]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0036206 ]\n",
      " [ 0.43576549]\n",
      " [-0.05902295]\n",
      " [-0.38747146]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.31087783e-05]\n",
      " [1.89891561e-01]\n",
      " [3.48370807e-03]\n",
      " [1.50134134e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.042940314000270305 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32144849]\n",
      " [ 4.45074859]\n",
      " [ 3.68751229]\n",
      " [ 1.55060992]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  845\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09643812]\n",
      " [10.8345685 ]\n",
      " [18.24121328]\n",
      " [18.11357407]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00356188]\n",
      " [ 0.4345685 ]\n",
      " [-0.05878672]\n",
      " [-0.38642593]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.26869693e-05]\n",
      " [1.88849780e-01]\n",
      " [3.45587888e-03]\n",
      " [1.49324996e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04270541769477719 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32148401]\n",
      " [ 4.45190631]\n",
      " [ 3.68843879]\n",
      " [ 1.55023667]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  846\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09649628]\n",
      " [10.83337472]\n",
      " [18.24144828]\n",
      " [18.11461674]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00350372]\n",
      " [ 0.43337472]\n",
      " [-0.05855172]\n",
      " [-0.38538326]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.22760244e-05]\n",
      " [1.87813650e-01]\n",
      " [3.42830380e-03]\n",
      " [1.48520253e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04247181040044537 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32151917]\n",
      " [ 4.45306091]\n",
      " [ 3.68936258]\n",
      " [ 1.54986421]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  847\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09655388]\n",
      " [10.83218415]\n",
      " [18.24168208]\n",
      " [18.11565656]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00344612]\n",
      " [ 0.43218415]\n",
      " [-0.05831792]\n",
      " [-0.38434344]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.18757110e-05]\n",
      " [1.86783142e-01]\n",
      " [3.40098019e-03]\n",
      " [1.47719882e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04223948498269123 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32155398]\n",
      " [ 4.45421239]\n",
      " [ 3.69028368]\n",
      " [ 1.54949253]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  848\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09661093]\n",
      " [10.83099678]\n",
      " [18.24191467]\n",
      " [18.11669352]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00338907]\n",
      " [ 0.43099678]\n",
      " [-0.05808533]\n",
      " [-0.38330648]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.14858012e-05]\n",
      " [1.85758227e-01]\n",
      " [3.37390545e-03]\n",
      " [1.46923856e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.042008434347382495 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32158844]\n",
      " [ 4.45536076]\n",
      " [ 3.69120209]\n",
      " [ 1.54912163]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  849\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09666742]\n",
      " [10.82981261]\n",
      " [18.24214607]\n",
      " [18.11772765]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00333258]\n",
      " [ 0.42981261]\n",
      " [-0.05785393]\n",
      " [-0.38227235]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.11060714e-05]\n",
      " [1.84738876e-01]\n",
      " [3.34707699e-03]\n",
      " [1.46132153e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04177865144059155 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32162255]\n",
      " [ 4.45650603]\n",
      " [ 3.69211782]\n",
      " [ 1.54875151]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  850\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09672337]\n",
      " [10.82863161]\n",
      " [18.24237629]\n",
      " [18.11875894]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00327663]\n",
      " [ 0.42863161]\n",
      " [-0.05762371]\n",
      " [-0.38124106]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.07363026e-05]\n",
      " [1.83725059e-01]\n",
      " [3.32049227e-03]\n",
      " [1.45344747e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.041550129248355536 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32165633]\n",
      " [ 4.45764821]\n",
      " [ 3.69303089]\n",
      " [ 1.54838218]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  851\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09677878]\n",
      " [10.8274538 ]\n",
      " [18.24260532]\n",
      " [18.11978741]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00322122]\n",
      " [ 0.4274538 ]\n",
      " [-0.05739468]\n",
      " [-0.38021259]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.03762798e-05]\n",
      " [1.82716747e-01]\n",
      " [3.29414877e-03]\n",
      " [1.44561614e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.041322860796431465 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32168976]\n",
      " [ 4.4587873 ]\n",
      " [ 3.6939413 ]\n",
      " [ 1.54801362]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  852\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09683365]\n",
      " [10.82627915]\n",
      " [18.24283319]\n",
      " [18.12081307]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00316635]\n",
      " [ 0.42627915]\n",
      " [-0.05716681]\n",
      " [-0.37918693]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.00257926e-05]\n",
      " [1.81713913e-01]\n",
      " [3.26804400e-03]\n",
      " [1.43782731e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.041096839150057976 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32172287]\n",
      " [ 4.45992332]\n",
      " [ 3.69484905]\n",
      " [ 1.54764585]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  853\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09688799]\n",
      " [10.82510766]\n",
      " [18.2430599 ]\n",
      " [18.12183592]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00311201]\n",
      " [ 0.42510766]\n",
      " [-0.0569401 ]\n",
      " [-0.37816408]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.68463441e-06]\n",
      " [1.80716526e-01]\n",
      " [3.24217551e-03]\n",
      " [1.43008073e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.040872057413716564 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32175564]\n",
      " [ 4.46105627]\n",
      " [ 3.69575416]\n",
      " [ 1.54727886]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  854\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0969418 ]\n",
      " [10.82393933]\n",
      " [18.24328544]\n",
      " [18.12285597]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0030582 ]\n",
      " [ 0.42393933]\n",
      " [-0.05671456]\n",
      " [-0.37714403]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.35260282e-06]\n",
      " [1.79724559e-01]\n",
      " [3.21654085e-03]\n",
      " [1.42237617e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04064850873089504 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32178808]\n",
      " [ 4.46218616]\n",
      " [ 3.69665664]\n",
      " [ 1.54691264]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  855\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09699509]\n",
      " [10.82277415]\n",
      " [18.24350984]\n",
      " [18.12387324]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00300491]\n",
      " [ 0.42277415]\n",
      " [-0.05649016]\n",
      " [-0.37612676]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.02949942e-06]\n",
      " [1.78737983e-01]\n",
      " [3.19113763e-03]\n",
      " [1.41471340e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04042618628385125 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3218202 ]\n",
      " [ 4.463313  ]\n",
      " [ 3.69755648]\n",
      " [ 1.5465472 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  856\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09704786]\n",
      " [10.82161211]\n",
      " [18.24373311]\n",
      " [18.12488773]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00295214]\n",
      " [ 0.42161211]\n",
      " [-0.05626689]\n",
      " [-0.37511227]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.71512967e-06]\n",
      " [1.77756770e-01]\n",
      " [3.16596346e-03]\n",
      " [1.40709218e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.04020508329338418 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.321852  ]\n",
      " [ 4.4644368 ]\n",
      " [ 3.69845371]\n",
      " [ 1.54618254]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  857\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09710012]\n",
      " [10.8204532 ]\n",
      " [18.24395523]\n",
      " [18.12589944]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00289988]\n",
      " [ 0.4204532 ]\n",
      " [-0.05604477]\n",
      " [-0.37410056]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.40930291e-06]\n",
      " [1.76780891e-01]\n",
      " [3.14101601e-03]\n",
      " [1.39951228e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03998519301859606 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32188348]\n",
      " [ 4.46555756]\n",
      " [ 3.69934833]\n",
      " [ 1.54581866]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  858\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09715187]\n",
      " [10.81929741]\n",
      " [18.24417623]\n",
      " [18.12690839]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00284813]\n",
      " [ 0.41929741]\n",
      " [-0.05582377]\n",
      " [-0.37309161]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.11183220e-06]\n",
      " [1.75810319e-01]\n",
      " [3.11629293e-03]\n",
      " [1.39197346e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03976650875666783 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32191464]\n",
      " [ 4.4666753 ]\n",
      " [ 3.70024034]\n",
      " [ 1.54545555]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  859\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09720312]\n",
      " [10.81814474]\n",
      " [18.24439612]\n",
      " [18.12791459]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00279688]\n",
      " [ 0.41814474]\n",
      " [-0.05560388]\n",
      " [-0.37208541]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.82253432e-06]\n",
      " [1.74845026e-01]\n",
      " [3.09179195e-03]\n",
      " [1.38447550e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03954902384262765 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3219455 ]\n",
      " [ 4.46779001]\n",
      " [ 3.70112976]\n",
      " [ 1.54509321]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  860\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09725387]\n",
      " [10.81699518]\n",
      " [18.24461489]\n",
      " [18.12891805]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00274613]\n",
      " [ 0.41699518]\n",
      " [-0.05538511]\n",
      " [-0.37108195]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.54122965e-06]\n",
      " [1.73884984e-01]\n",
      " [3.06751079e-03]\n",
      " [1.37701817e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.039332731649125555 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32197604]\n",
      " [ 4.46890172]\n",
      " [ 3.70201659]\n",
      " [ 1.54473165]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  861\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09730412]\n",
      " [10.81584873]\n",
      " [18.24483255]\n",
      " [18.12991876]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00269588]\n",
      " [ 0.41584873]\n",
      " [-0.05516745]\n",
      " [-0.37008124]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.26774215e-06]\n",
      " [1.72930165e-01]\n",
      " [3.04344721e-03]\n",
      " [1.36960124e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03911762558620789 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32200628]\n",
      " [ 4.47001042]\n",
      " [ 3.70290085]\n",
      " [ 1.54437087]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  862\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09735389]\n",
      " [10.81470537]\n",
      " [18.24504912]\n",
      " [18.13091674]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00264611]\n",
      " [ 0.41470537]\n",
      " [-0.05495088]\n",
      " [-0.36908326]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.00189923e-06]\n",
      " [1.71980543e-01]\n",
      " [3.01959899e-03]\n",
      " [1.36222449e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03890369910109315 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32203622]\n",
      " [ 4.47111613]\n",
      " [ 3.70378253]\n",
      " [ 1.54401086]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  863\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09740317]\n",
      " [10.8135651 ]\n",
      " [18.2452646 ]\n",
      " [18.13191201]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00259683]\n",
      " [ 0.4135651 ]\n",
      " [-0.0547354 ]\n",
      " [-0.36808799]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.74353177e-06]\n",
      " [1.71036089e-01]\n",
      " [2.99596393e-03]\n",
      " [1.35488769e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.038690945677949964 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32206586]\n",
      " [ 4.47221885]\n",
      " [ 3.70466165]\n",
      " [ 1.54365162]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  864\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09745197]\n",
      " [10.8124279 ]\n",
      " [18.245479  ]\n",
      " [18.13290456]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00254803]\n",
      " [ 0.4124279 ]\n",
      " [-0.054521  ]\n",
      " [-0.36709544]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.49247396e-06]\n",
      " [1.70096776e-01]\n",
      " [2.97253987e-03]\n",
      " [1.34759063e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03847935883767746 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3220952 ]\n",
      " [ 4.47331859]\n",
      " [ 3.70553822]\n",
      " [ 1.54329315]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  865\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09750029]\n",
      " [10.81129378]\n",
      " [18.24569231]\n",
      " [18.1338944 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00249971]\n",
      " [ 0.41129378]\n",
      " [-0.05430769]\n",
      " [-0.3661056 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.24856331e-06]\n",
      " [1.69162577e-01]\n",
      " [2.94932467e-03]\n",
      " [1.34033307e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.038268932137686076 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32212425]\n",
      " [ 4.47441536]\n",
      " [ 3.70641224]\n",
      " [ 1.54293545]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  866\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09754814]\n",
      " [10.81016273]\n",
      " [18.24590456]\n",
      " [18.13488155]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00245186]\n",
      " [ 0.41016273]\n",
      " [-0.05409544]\n",
      " [-0.36511845]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.01164056e-06]\n",
      " [1.68233466e-01]\n",
      " [2.92631621e-03]\n",
      " [1.33311480e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.038059659171678674 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.322153  ]\n",
      " [ 4.47550916]\n",
      " [ 3.70728372]\n",
      " [ 1.54257852]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  867\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09759551]\n",
      " [10.80903474]\n",
      " [18.24611575]\n",
      " [18.13586601]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00240449]\n",
      " [ 0.40903474]\n",
      " [-0.05388425]\n",
      " [-0.36413399]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.78154960e-06]\n",
      " [1.67309414e-01]\n",
      " [2.90351239e-03]\n",
      " [1.32593560e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03785153356943567 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32218147]\n",
      " [ 4.47660001]\n",
      " [ 3.70815267]\n",
      " [ 1.54222236]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  868\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09764243]\n",
      " [10.80790979]\n",
      " [18.24632588]\n",
      " [18.13684779]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00235757]\n",
      " [ 0.40790979]\n",
      " [-0.05367412]\n",
      " [-0.36315221]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.55813746e-06]\n",
      " [1.66390397e-01]\n",
      " [2.88091114e-03]\n",
      " [1.31879526e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03764454899660058 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32220966]\n",
      " [ 4.47768792]\n",
      " [ 3.7090191 ]\n",
      " [ 1.54186697]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  869\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09768888]\n",
      " [10.80678789]\n",
      " [18.24653496]\n",
      " [18.1378269 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00231112]\n",
      " [ 0.40678789]\n",
      " [-0.05346504]\n",
      " [-0.3621731 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.34125419e-06]\n",
      " [1.65476387e-01]\n",
      " [2.85851042e-03]\n",
      " [1.31169355e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03743869915446582 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32223756]\n",
      " [ 4.47877288]\n",
      " [ 3.70988301]\n",
      " [ 1.54151235]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  870\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09773488]\n",
      " [10.80566902]\n",
      " [18.246743  ]\n",
      " [18.13880334]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00226512]\n",
      " [ 0.40566902]\n",
      " [-0.053257  ]\n",
      " [-0.36119666]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.13075287e-06]\n",
      " [1.64567357e-01]\n",
      " [2.83630820e-03]\n",
      " [1.30463026e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03723397777976314 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32226519]\n",
      " [ 4.47985491]\n",
      " [ 3.71074441]\n",
      " [ 1.54115849]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  871\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09778043]\n",
      " [10.80455319]\n",
      " [18.24695   ]\n",
      " [18.13977713]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00221957]\n",
      " [ 0.40455319]\n",
      " [-0.05305   ]\n",
      " [-0.36022287]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.92648948e-06]\n",
      " [1.63663282e-01]\n",
      " [2.81430248e-03]\n",
      " [1.29760518e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.037030378644450565 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32229253]\n",
      " [ 4.48093402]\n",
      " [ 3.71160332]\n",
      " [ 1.5408054 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  872\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09782553]\n",
      " [10.80344037]\n",
      " [18.24715597]\n",
      " [18.14074826]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00217447]\n",
      " [ 0.40344037]\n",
      " [-0.05284403]\n",
      " [-0.35925174]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.72832289e-06]\n",
      " [1.62764135e-01]\n",
      " [2.79249128e-03]\n",
      " [1.29061810e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03682789555550672 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32231961]\n",
      " [ 4.48201021]\n",
      " [ 3.71245973]\n",
      " [ 1.54045307]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  873\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09787018]\n",
      " [10.80233057]\n",
      " [18.24736092]\n",
      " [18.14171676]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00212982]\n",
      " [ 0.40233057]\n",
      " [-0.05263908]\n",
      " [-0.35828324]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.53611483e-06]\n",
      " [1.61869889e-01]\n",
      " [2.77087264e-03]\n",
      " [1.28366881e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03662652235472039 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32234641]\n",
      " [ 4.48308349]\n",
      " [ 3.71331366]\n",
      " [ 1.54010151]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  874\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0979144 ]\n",
      " [10.80122378]\n",
      " [18.24756485]\n",
      " [18.14268262]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0020856 ]\n",
      " [ 0.40122378]\n",
      " [-0.05243515]\n",
      " [-0.35731738]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.34972976e-06]\n",
      " [1.60980520e-01]\n",
      " [2.74944464e-03]\n",
      " [1.27675709e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03642625291848775 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32237295]\n",
      " [ 4.48415388]\n",
      " [ 3.71416511]\n",
      " [ 1.53975071]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  875\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09795818]\n",
      " [10.80011998]\n",
      " [18.24776777]\n",
      " [18.14364586]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00204182]\n",
      " [ 0.40011998]\n",
      " [-0.05223223]\n",
      " [-0.35635414]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.16903487e-06]\n",
      " [1.60096001e-01]\n",
      " [2.72820535e-03]\n",
      " [1.26988274e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03622708115760426 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32239922]\n",
      " [ 4.48522137]\n",
      " [ 3.7150141 ]\n",
      " [ 1.53940067]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  876\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09800153]\n",
      " [10.79901918]\n",
      " [18.24796969]\n",
      " [18.14460648]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00199847]\n",
      " [ 0.39901918]\n",
      " [-0.05203031]\n",
      " [-0.35539352]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.99390004e-06]\n",
      " [1.59216307e-01]\n",
      " [2.70715289e-03]\n",
      " [1.26304555e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03602900101706504 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32242523]\n",
      " [ 4.48628597]\n",
      " [ 3.71586062]\n",
      " [ 1.5390514 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  877\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09804444]\n",
      " [10.79792136]\n",
      " [18.24817061]\n",
      " [18.14556449]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00195556]\n",
      " [ 0.39792136]\n",
      " [-0.05182939]\n",
      " [-0.35443551]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.82419776e-06]\n",
      " [1.58341411e-01]\n",
      " [2.68628538e-03]\n",
      " [1.25624531e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.035832006475861176 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32245097]\n",
      " [ 4.4873477 ]\n",
      " [ 3.71670469]\n",
      " [ 1.53870289]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  878\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09808694]\n",
      " [10.79682652]\n",
      " [18.24837054]\n",
      " [18.1465199 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00191306]\n",
      " [ 0.39682652]\n",
      " [-0.05162946]\n",
      " [-0.3534801 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.65980307e-06]\n",
      " [1.57471289e-01]\n",
      " [2.66560099e-03]\n",
      " [1.24948183e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03563609154677799 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32247647]\n",
      " [ 4.48840655]\n",
      " [ 3.71754632]\n",
      " [ 1.53835513]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  879\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09812901]\n",
      " [10.79573465]\n",
      " [18.24856948]\n",
      " [18.14747271]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00187099]\n",
      " [ 0.39573465]\n",
      " [-0.05143052]\n",
      " [-0.35252729]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.50059355e-06]\n",
      " [1.56605915e-01]\n",
      " [2.64509787e-03]\n",
      " [1.24275489e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.035441250276198905 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3225017 ]\n",
      " [ 4.48946254]\n",
      " [ 3.7183855 ]\n",
      " [ 1.53800814]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  880\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09817067]\n",
      " [10.79464574]\n",
      " [18.24876745]\n",
      " [18.14842294]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00182933]\n",
      " [ 0.39464574]\n",
      " [-0.05123255]\n",
      " [-0.35157706]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.34644924e-06]\n",
      " [1.55745263e-01]\n",
      " [2.62477423e-03]\n",
      " [1.23606430e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0352474767439064 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32252668]\n",
      " [ 4.49051568]\n",
      " [ 3.71922226]\n",
      " [ 1.5376619 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  881\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09821191]\n",
      " [10.79355979]\n",
      " [18.24896444]\n",
      " [18.14937059]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00178809]\n",
      " [ 0.39355979]\n",
      " [-0.05103556]\n",
      " [-0.35062941]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.19725261e-06]\n",
      " [1.54889310e-01]\n",
      " [2.60462827e-03]\n",
      " [1.22940985e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03505476506288308 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32255142]\n",
      " [ 4.49156598]\n",
      " [ 3.72005659]\n",
      " [ 1.53731642]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  882\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09825275]\n",
      " [10.79247679]\n",
      " [18.24916047]\n",
      " [18.15031566]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00174725]\n",
      " [ 0.39247679]\n",
      " [-0.05083953]\n",
      " [-0.34968434]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.05288852e-06]\n",
      " [1.54038029e-01]\n",
      " [2.58465824e-03]\n",
      " [1.22279135e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03486310937912144 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3225759 ]\n",
      " [ 4.49261343]\n",
      " [ 3.72088851]\n",
      " [ 1.5369717 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  883\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09829318]\n",
      " [10.79139673]\n",
      " [18.24935553]\n",
      " [18.15125818]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00170682]\n",
      " [ 0.39139673]\n",
      " [-0.05064447]\n",
      " [-0.34874182]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.91324414e-06]\n",
      " [1.53191397e-01]\n",
      " [2.56486237e-03]\n",
      " [1.21620859e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03467250387142612 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32260014]\n",
      " [ 4.49365805]\n",
      " [ 3.72171801]\n",
      " [ 1.53662774]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  884\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0983332 ]\n",
      " [10.7903196 ]\n",
      " [18.24954964]\n",
      " [18.15219813]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0016668 ]\n",
      " [ 0.3903196 ]\n",
      " [-0.05045036]\n",
      " [-0.34780187]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.77820894e-06]\n",
      " [1.52349387e-01]\n",
      " [2.54523894e-03]\n",
      " [1.20966137e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03448294275122101 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32262414]\n",
      " [ 4.49469984]\n",
      " [ 3.72254512]\n",
      " [ 1.53628452]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  885\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09837283]\n",
      " [10.78924539]\n",
      " [18.2497428 ]\n",
      " [18.15313554]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00162717]\n",
      " [ 0.38924539]\n",
      " [-0.0502572 ]\n",
      " [-0.34686446]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.64767465e-06]\n",
      " [1.51511977e-01]\n",
      " [2.52578624e-03]\n",
      " [1.20314951e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.034294420262361694 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3226479 ]\n",
      " [ 4.49573882]\n",
      " [ 3.72336983]\n",
      " [ 1.53594207]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  886\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09841207]\n",
      " [10.78817411]\n",
      " [18.24993502]\n",
      " [18.15407041]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00158793]\n",
      " [ 0.38817411]\n",
      " [-0.05006498]\n",
      " [-0.34592959]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.52153518e-06]\n",
      " [1.50679140e-01]\n",
      " [2.50650259e-03]\n",
      " [1.19667281e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.034106930680941616 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32267142]\n",
      " [ 4.49677499]\n",
      " [ 3.72419216]\n",
      " [ 1.53560036]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  887\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09845091]\n",
      " [10.78710574]\n",
      " [18.2501263 ]\n",
      " [18.15500274]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00154909]\n",
      " [ 0.38710574]\n",
      " [-0.0498737 ]\n",
      " [-0.34499726]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.39968660e-06]\n",
      " [1.49850853e-01]\n",
      " [2.48738631e-03]\n",
      " [1.19023107e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.033920468315106 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32269471]\n",
      " [ 4.49780836]\n",
      " [ 3.72501211]\n",
      " [ 1.53525941]] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************************\n",
      "Iteration =  888\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09848936]\n",
      " [10.78604027]\n",
      " [18.25031665]\n",
      " [18.15593255]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00151064]\n",
      " [ 0.38604027]\n",
      " [-0.04968335]\n",
      " [-0.34406745]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.28202713e-06]\n",
      " [1.49027092e-01]\n",
      " [2.46843574e-03]\n",
      " [1.18382410e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03373502750486097 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32271776]\n",
      " [ 4.49883893]\n",
      " [ 3.72582969]\n",
      " [ 1.53491921]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  889\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09852743]\n",
      " [10.7849777 ]\n",
      " [18.25050607]\n",
      " [18.15685984]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00147257]\n",
      " [ 0.3849777 ]\n",
      " [-0.04949393]\n",
      " [-0.34314016]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.16845704e-06]\n",
      " [1.48207832e-01]\n",
      " [2.44964926e-03]\n",
      " [1.17745171e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0335506026218913 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32274058]\n",
      " [ 4.49986672]\n",
      " [ 3.7266449 ]\n",
      " [ 1.53457976]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  890\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09856512]\n",
      " [10.78391802]\n",
      " [18.25069457]\n",
      " [18.15778461]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00143488]\n",
      " [ 0.38391802]\n",
      " [-0.04930543]\n",
      " [-0.34221539]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.05887864e-06]\n",
      " [1.47393050e-01]\n",
      " [2.43102525e-03]\n",
      " [1.17111371e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03336718806937281 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32276318]\n",
      " [ 4.50089172]\n",
      " [ 3.72745776]\n",
      " [ 1.53424106]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  891\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09860243]\n",
      " [10.78286123]\n",
      " [18.25088216]\n",
      " [18.15870689]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00139757]\n",
      " [ 0.38286123]\n",
      " [-0.04911784]\n",
      " [-0.34129311]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.95319626e-06]\n",
      " [1.46582721e-01]\n",
      " [2.41256211e-03]\n",
      " [1.16480990e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03318477828178789 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32278555]\n",
      " [ 4.50191396]\n",
      " [ 3.72826827]\n",
      " [ 1.53390311]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  892\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09863937]\n",
      " [10.78180731]\n",
      " [18.25106884]\n",
      " [18.15962666]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00136063]\n",
      " [ 0.38180731]\n",
      " [-0.04893116]\n",
      " [-0.34037334]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.85131617e-06]\n",
      " [1.45776822e-01]\n",
      " [2.39425825e-03]\n",
      " [1.15854011e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.033003367724745186 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32280769]\n",
      " [ 4.50293342]\n",
      " [ 3.72907643]\n",
      " [ 1.5335659 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  893\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09867594]\n",
      " [10.78075626]\n",
      " [18.25125462]\n",
      " [18.16054395]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00132406]\n",
      " [ 0.38075626]\n",
      " [-0.04874538]\n",
      " [-0.33945605]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.75314657e-06]\n",
      " [1.44975329e-01]\n",
      " [2.37611212e-03]\n",
      " [1.15230413e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03282295089479696 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32282961]\n",
      " [ 4.50395014]\n",
      " [ 3.72988226]\n",
      " [ 1.53322944]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  894\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09871213]\n",
      " [10.77970807]\n",
      " [18.2514395 ]\n",
      " [18.16145875]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00128787]\n",
      " [ 0.37970807]\n",
      " [-0.0485605 ]\n",
      " [-0.33854125]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.65859756e-06]\n",
      " [1.44178218e-01]\n",
      " [2.35812217e-03]\n",
      " [1.14610180e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.032643522319256366 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32285132]\n",
      " [ 4.5049641 ]\n",
      " [ 3.73068577]\n",
      " [ 1.53289373]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  895\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09874797]\n",
      " [10.77866273]\n",
      " [18.25162349]\n",
      " [18.16237107]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00125203]\n",
      " [ 0.37866273]\n",
      " [-0.04837651]\n",
      " [-0.33762893]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.56758109e-06]\n",
      " [1.43385467e-01]\n",
      " [2.34028687e-03]\n",
      " [1.13993291e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03246507655602364 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3228728 ]\n",
      " [ 4.50597532]\n",
      " [ 3.73148695]\n",
      " [ 1.53255876]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  896\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09878344]\n",
      " [10.77762025]\n",
      " [18.25180659]\n",
      " [18.16328093]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00121656]\n",
      " [ 0.37762025]\n",
      " [-0.04819341]\n",
      " [-0.33671907]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.48001090e-06]\n",
      " [1.42597051e-01]\n",
      " [2.32260470e-03]\n",
      " [1.13379730e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.032287608193402324 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32289408]\n",
      " [ 4.5069838 ]\n",
      " [ 3.73228582]\n",
      " [ 1.53222454]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  897\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09881856]\n",
      " [10.7765806 ]\n",
      " [18.25198881]\n",
      " [18.16418833]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00118144]\n",
      " [ 0.3765806 ]\n",
      " [-0.04801119]\n",
      " [-0.33581167]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.39580255e-06]\n",
      " [1.41812948e-01]\n",
      " [2.30507418e-03]\n",
      " [1.12769477e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0321111118499276 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32291513]\n",
      " [ 4.50798955]\n",
      " [ 3.73308238]\n",
      " [ 1.53189106]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  898\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09885332]\n",
      " [10.77554379]\n",
      " [18.25217016]\n",
      " [18.16509328]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00114668]\n",
      " [ 0.37554379]\n",
      " [-0.04782984]\n",
      " [-0.33490672]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.31487331e-06]\n",
      " [1.41033135e-01]\n",
      " [2.28769381e-03]\n",
      " [1.12162514e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.031935582174185996 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32293598]\n",
      " [ 4.50899259]\n",
      " [ 3.73387664]\n",
      " [ 1.53155832]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  899\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09888773]\n",
      " [10.7745098 ]\n",
      " [18.25235063]\n",
      " [18.16599577]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00111227]\n",
      " [ 0.3745098 ]\n",
      " [-0.04764937]\n",
      " [-0.33400423]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.23714218e-06]\n",
      " [1.40257588e-01]\n",
      " [2.27046215e-03]\n",
      " [1.11558824e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03176101384464383 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32295662]\n",
      " [ 4.50999291]\n",
      " [ 3.73466861]\n",
      " [ 1.53122632]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  900\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09892179]\n",
      " [10.77347863]\n",
      " [18.25253024]\n",
      " [18.16689583]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00107821]\n",
      " [ 0.37347863]\n",
      " [-0.04746976]\n",
      " [-0.33310417]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.16252986e-06]\n",
      " [1.39486285e-01]\n",
      " [2.25337774e-03]\n",
      " [1.10958388e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03158740156947297 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32297706]\n",
      " [ 4.51099052]\n",
      " [ 3.7354583 ]\n",
      " [ 1.53089507]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  901\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09895551]\n",
      " [10.77245027]\n",
      " [18.252709  ]\n",
      " [18.16779346]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00104449]\n",
      " [ 0.37245027]\n",
      " [-0.047291  ]\n",
      " [-0.33220654]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.09095866e-06]\n",
      " [1.38719202e-01]\n",
      " [2.23643915e-03]\n",
      " [1.10361188e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0314147400863784 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32299729]\n",
      " [ 4.51198544]\n",
      " [ 3.7362457 ]\n",
      " [ 1.53056455]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  902\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09898889]\n",
      " [10.77142471]\n",
      " [18.25288689]\n",
      " [18.16868866]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00101111]\n",
      " [ 0.37142471]\n",
      " [-0.04711311]\n",
      " [-0.33131134]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.02235253e-06]\n",
      " [1.37956319e-01]\n",
      " [2.21964496e-03]\n",
      " [1.09767207e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03124302416242725 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32301731]\n",
      " [ 4.51297766]\n",
      " [ 3.73703084]\n",
      " [ 1.53023477]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  903\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09902192]\n",
      " [10.77040196]\n",
      " [18.25306394]\n",
      " [18.16958144]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00097808]\n",
      " [ 0.37040196]\n",
      " [-0.04693606]\n",
      " [-0.33041856]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.56636999e-07]\n",
      " [1.37197611e-01]\n",
      " [2.20299378e-03]\n",
      " [1.09176428e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03107224859387784 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32303714]\n",
      " [ 4.5139672 ]\n",
      " [ 3.73781371]\n",
      " [ 1.52990573]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  904\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09905462]\n",
      " [10.76938199]\n",
      " [18.25324014]\n",
      " [18.17047181]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00094538]\n",
      " [ 0.36938199]\n",
      " [-0.04675986]\n",
      " [-0.32952819]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.93739157e-07]\n",
      " [1.36443056e-01]\n",
      " [2.18648422e-03]\n",
      " [1.08588831e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03090240820601234 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32305677]\n",
      " [ 4.51495406]\n",
      " [ 3.73859433]\n",
      " [ 1.52957742]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  905\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09908699]\n",
      " [10.76836481]\n",
      " [18.25341551]\n",
      " [18.17135977]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00091301]\n",
      " [ 0.36836481]\n",
      " [-0.04658449]\n",
      " [-0.32864023]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.33587611e-07]\n",
      " [1.35692633e-01]\n",
      " [2.17011490e-03]\n",
      " [1.08004401e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.0307334978529663 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3230762 ]\n",
      " [ 4.51593825]\n",
      " [ 3.73937269]\n",
      " [ 1.52924985]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  906\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09911903]\n",
      " [10.7673504 ]\n",
      " [18.25359004]\n",
      " [18.17224534]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00088097]\n",
      " [ 0.3673504 ]\n",
      " [-0.04640996]\n",
      " [-0.32775466]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.76112467e-07]\n",
      " [1.34946319e-01]\n",
      " [2.15388448e-03]\n",
      " [1.07423120e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.030565512417565156 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32309544]\n",
      " [ 4.51691978]\n",
      " [ 3.74014881]\n",
      " [ 1.52892301]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  907\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09915074]\n",
      " [10.76633877]\n",
      " [18.25376374]\n",
      " [18.17312851]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00084926]\n",
      " [ 0.36633877]\n",
      " [-0.04623626]\n",
      " [-0.32687149]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.21245295e-07]\n",
      " [1.34204092e-01]\n",
      " [2.13779162e-03]\n",
      " [1.06844970e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.03039844681115461 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32311449]\n",
      " [ 4.51789865]\n",
      " [ 3.74092269]\n",
      " [ 1.52859691]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  908\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09918213]\n",
      " [10.76532989]\n",
      " [18.25393662]\n",
      " [18.1740093 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00081787]\n",
      " [ 0.36532989]\n",
      " [-0.04606338]\n",
      " [-0.3259907 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.68919105e-07]\n",
      " [1.33465930e-01]\n",
      " [2.12183498e-03]\n",
      " [1.06269934e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.030232295973439474 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32313334]\n",
      " [ 4.51887487]\n",
      " [ 3.74169435]\n",
      " [ 1.52827154]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  909\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09921319]\n",
      " [10.76432377]\n",
      " [18.25410868]\n",
      " [18.17488772]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00078681]\n",
      " [ 0.36432377]\n",
      " [-0.04589132]\n",
      " [-0.32511228]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.19068318e-07]\n",
      " [1.32731811e-01]\n",
      " [2.10601326e-03]\n",
      " [1.05697996e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.030067054872316853 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32315201]\n",
      " [ 4.51984845]\n",
      " [ 3.74246378]\n",
      " [ 1.5279469 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  910\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09924394]\n",
      " [10.7633204 ]\n",
      " [18.25427993]\n",
      " [18.17576376]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00075606]\n",
      " [ 0.3633204 ]\n",
      " [-0.04572007]\n",
      " [-0.32423624]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.71628737e-07]\n",
      " [1.32001714e-01]\n",
      " [2.09032516e-03]\n",
      " [1.05129138e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.029902718503716542 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32317049]\n",
      " [ 4.52081939]\n",
      " [ 3.74323099]\n",
      " [ 1.52762299]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  911\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09927437]\n",
      " [10.76231977]\n",
      " [18.25445036]\n",
      " [18.17663744]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00072563]\n",
      " [ 0.36231977]\n",
      " [-0.04554964]\n",
      " [-0.32336256]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.26537520e-07]\n",
      " [1.31275616e-01]\n",
      " [2.07476940e-03]\n",
      " [1.04563343e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02973928189143564 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32318878]\n",
      " [ 4.52178771]\n",
      " [ 3.743996  ]\n",
      " [ 1.52729981]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  912\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09930449]\n",
      " [10.76132187]\n",
      " [18.25462   ]\n",
      " [18.17750877]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00069551]\n",
      " [ 0.36132187]\n",
      " [-0.04538   ]\n",
      " [-0.32249123]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.83733158e-07]\n",
      " [1.30553497e-01]\n",
      " [2.05934470e-03]\n",
      " [1.04000596e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.029576740086981648 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32320689]\n",
      " [ 4.5227534 ]\n",
      " [ 3.7447588 ]\n",
      " [ 1.52697736]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  913\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0993343 ]\n",
      " [10.76032671]\n",
      " [18.25478883]\n",
      " [18.17837774]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0006657 ]\n",
      " [ 0.36032671]\n",
      " [-0.04521117]\n",
      " [-0.32162226]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.43155444e-07]\n",
      " [1.29835334e-01]\n",
      " [2.04404981e-03]\n",
      " [1.03440878e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.029415088169411303 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32322483]\n",
      " [ 4.52371648]\n",
      " [ 3.7455194 ]\n",
      " [ 1.52665563]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  914\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0993638 ]\n",
      " [10.75933426]\n",
      " [18.25495687]\n",
      " [18.17924437]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0006362 ]\n",
      " [ 0.35933426]\n",
      " [-0.04504313]\n",
      " [-0.32075563]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.04745451e-07]\n",
      " [1.29121108e-01]\n",
      " [2.02888350e-03]\n",
      " [1.02884174e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.029254321245170793 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32324258]\n",
      " [ 4.52467696]\n",
      " [ 3.74627782]\n",
      " [ 1.52633463]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  915\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.099393  ]\n",
      " [10.75834452]\n",
      " [18.25512412]\n",
      " [18.18010866]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.000607  ]\n",
      " [ 0.35834452]\n",
      " [-0.04487588]\n",
      " [-0.31989134]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.68445504e-07]\n",
      " [1.28410796e-01]\n",
      " [2.01384452e-03]\n",
      " [1.02330467e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02909443444794014 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32326015]\n",
      " [ 4.52563483]\n",
      " [ 3.74703406]\n",
      " [ 1.52601436]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  916\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0994219 ]\n",
      " [10.75735749]\n",
      " [18.25529059]\n",
      " [18.18097063]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0005781 ]\n",
      " [ 0.35735749]\n",
      " [-0.04470941]\n",
      " [-0.31902937]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.34199161e-07]\n",
      " [1.27704377e-01]\n",
      " [1.99893167e-03]\n",
      " [1.01779741e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.028935422938475622 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32327755]\n",
      " [ 4.52659011]\n",
      " [ 3.74778812]\n",
      " [ 1.52569481]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  917\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0994505 ]\n",
      " [10.75637316]\n",
      " [18.25545627]\n",
      " [18.18183027]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0005495 ]\n",
      " [ 0.35637316]\n",
      " [-0.04454373]\n",
      " [-0.31816973]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.01951183e-07]\n",
      " [1.27001830e-01]\n",
      " [1.98414374e-03]\n",
      " [1.01231979e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02877728190445381 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32329477]\n",
      " [ 4.52754281]\n",
      " [ 3.74854   ]\n",
      " [ 1.52537599]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  918\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0994788 ]\n",
      " [10.75539152]\n",
      " [18.25562118]\n",
      " [18.18268759]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0005212 ]\n",
      " [ 0.35539152]\n",
      " [-0.04437882]\n",
      " [-0.31731241]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.71647515e-07]\n",
      " [1.26303135e-01]\n",
      " [1.96947954e-03]\n",
      " [1.00687166e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02862000656031787 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32331183]\n",
      " [ 4.52849292]\n",
      " [ 3.74928973]\n",
      " [ 1.52505789]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  919\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09950681]\n",
      " [10.75441257]\n",
      " [18.25578532]\n",
      " [18.1835426 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00049319]\n",
      " [ 0.35441257]\n",
      " [-0.04421468]\n",
      " [-0.3164574 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.43235261e-07]\n",
      " [1.25608271e-01]\n",
      " [1.95493790e-03]\n",
      " [1.00145285e-01]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.028463592147123247 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32332871]\n",
      " [ 4.52944047]\n",
      " [ 3.7500373 ]\n",
      " [ 1.5247405 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  920\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09953453]\n",
      " [10.7534363 ]\n",
      " [18.25594869]\n",
      " [18.18439531]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00046547]\n",
      " [ 0.3534363 ]\n",
      " [-0.04405131]\n",
      " [-0.31560469]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.16662660e-07]\n",
      " [1.24917218e-01]\n",
      " [1.94051765e-03]\n",
      " [9.96063196e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.028308033932384978 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32334542]\n",
      " [ 4.53038545]\n",
      " [ 3.75078272]\n",
      " [ 1.52442384]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  921\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09956196]\n",
      " [10.7524627 ]\n",
      " [18.2561113 ]\n",
      " [18.18524572]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00043804]\n",
      " [ 0.3524627 ]\n",
      " [-0.0438887 ]\n",
      " [-0.31475428]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.91879068e-07]\n",
      " [1.24229953e-01]\n",
      " [1.92621764e-03]\n",
      " [9.90702549e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.028153327209925937 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32336197]\n",
      " [ 4.53132786]\n",
      " [ 3.751526  ]\n",
      " [ 1.5241079 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  922\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0995891 ]\n",
      " [10.75149176]\n",
      " [18.25627316]\n",
      " [18.18609384]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.0004109 ]\n",
      " [ 0.35149176]\n",
      " [-0.04372684]\n",
      " [-0.31390616]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.68834932e-07]\n",
      " [1.23546458e-01]\n",
      " [1.91203673e-03]\n",
      " [9.85370747e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02799946729972706 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32337835]\n",
      " [ 4.53226773]\n",
      " [ 3.75226714]\n",
      " [ 1.52379268]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  923\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09961597]\n",
      " [10.75052348]\n",
      " [18.25643426]\n",
      " [18.18693968]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00038403]\n",
      " [ 0.35052348]\n",
      " [-0.04356574]\n",
      " [-0.31306032]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.47481771e-07]\n",
      " [1.22866712e-01]\n",
      " [1.89797379e-03]\n",
      " [9.80067633e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.027846449547774803 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32339456]\n",
      " [ 4.53320506]\n",
      " [ 3.75300616]\n",
      " [ 1.52347817]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  924\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09964255]\n",
      " [10.74955786]\n",
      " [18.25659461]\n",
      " [18.18778324]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-0.00035745]\n",
      " [ 0.34955786]\n",
      " [-0.04340539]\n",
      " [-0.31221676]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.27772155e-07]\n",
      " [1.22190694e-01]\n",
      " [1.88402771e-03]\n",
      " [9.74793050e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.027694269325915018 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32341062]\n",
      " [ 4.53413984]\n",
      " [ 3.75374305]\n",
      " [ 1.52316438]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  925\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09966885]\n",
      " [10.74859487]\n",
      " [18.25675422]\n",
      " [18.18862453]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.31149035e-04]\n",
      " [ 3.48594872e-01]\n",
      " [-4.32457787e-02]\n",
      " [-3.11375472e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.09659684e-07]\n",
      " [1.21518385e-01]\n",
      " [1.87019738e-03]\n",
      " [9.69546844e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.027542922031703485 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32342651]\n",
      " [ 4.53507209]\n",
      " [ 3.75447782]\n",
      " [ 1.5228513 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  926\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09969488]\n",
      " [10.74763453]\n",
      " [18.25691309]\n",
      " [18.18946355]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.05121230e-04]\n",
      " [ 3.47634527e-01]\n",
      " [-4.30869088e-02]\n",
      " [-3.10536449e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.30989650e-08]\n",
      " [1.20849764e-01]\n",
      " [1.85648171e-03]\n",
      " [9.64328859e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02739240308825882 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32344225]\n",
      " [ 4.53600182]\n",
      " [ 3.75521048]\n",
      " [ 1.52253894]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  927\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09972063]\n",
      " [10.74667681]\n",
      " [18.25707123]\n",
      " [18.19030032]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.79366424e-04]\n",
      " [ 3.46676812e-01]\n",
      " [-4.29287738e-02]\n",
      " [-3.09699684e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.80455986e-08]\n",
      " [1.20184812e-01]\n",
      " [1.84287962e-03]\n",
      " [9.59138942e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02724270794411716 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32345782]\n",
      " [ 4.53692903]\n",
      " [ 3.75594104]\n",
      " [ 1.52222729]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  928\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09974612]\n",
      " [10.74572172]\n",
      " [18.25722863]\n",
      " [18.19113483]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.53882165e-04]\n",
      " [ 3.45721721e-01]\n",
      " [-4.27713695e-02]\n",
      " [-3.08865171e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.44561538e-08]\n",
      " [1.19523508e-01]\n",
      " [1.82939005e-03]\n",
      " [9.53976940e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.027093832073086303 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32347325]\n",
      " [ 4.53785373]\n",
      " [ 3.7566695 ]\n",
      " [ 1.52191636]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  929\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09977133]\n",
      " [10.74476925]\n",
      " [18.25738531]\n",
      " [18.1919671 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.28666026e-04]\n",
      " [ 3.44769247e-01]\n",
      " [-4.26146915e-02]\n",
      " [-3.08032904e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.22881515e-08]\n",
      " [1.18865833e-01]\n",
      " [1.81601193e-03]\n",
      " [9.48842702e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02694577097410056 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32348851]\n",
      " [ 4.53877593]\n",
      " [ 3.75739587]\n",
      " [ 1.52160613]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  930\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09979628]\n",
      " [10.74381938]\n",
      " [18.25754126]\n",
      " [18.19279712]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-2.03715599e-04]\n",
      " [ 3.43819383e-01]\n",
      " [-4.24587355e-02]\n",
      " [-3.07202877e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.15000452e-08]\n",
      " [1.18211768e-01]\n",
      " [1.80274422e-03]\n",
      " [9.43736076e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.026798520171077887 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32350363]\n",
      " [ 4.53969562]\n",
      " [ 3.75812015]\n",
      " [ 1.52129662]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  931\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09982097]\n",
      " [10.74287212]\n",
      " [18.2576965 ]\n",
      " [18.19362492]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.79028497e-04]\n",
      " [ 3.42872123e-01]\n",
      " [-4.23034973e-02]\n",
      " [-3.06375083e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.20512029e-08]\n",
      " [1.17561293e-01]\n",
      " [1.78958589e-03]\n",
      " [9.38656913e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.026652075212778847 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32351859]\n",
      " [ 4.54061283]\n",
      " [ 3.75884235]\n",
      " [ 1.52098781]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  932\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0998454 ]\n",
      " [10.74192746]\n",
      " [18.25785103]\n",
      " [18.19445048]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.54602357e-04]\n",
      " [ 3.41927459e-01]\n",
      " [-4.21489727e-02]\n",
      " [-3.05549515e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.39018887e-08]\n",
      " [1.16914387e-01]\n",
      " [1.77653590e-03]\n",
      " [9.33605062e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02650643167266148 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32353341]\n",
      " [ 4.54152755]\n",
      " [ 3.75956249]\n",
      " [ 1.52067971]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  933\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09986957]\n",
      " [10.74098539]\n",
      " [18.25800484]\n",
      " [18.19527383]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.30434833e-04]\n",
      " [ 3.40985386e-01]\n",
      " [-4.19951574e-02]\n",
      " [-3.04726168e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.70132457e-08]\n",
      " [1.16271033e-01]\n",
      " [1.76359325e-03]\n",
      " [9.28580376e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.026361585148742945 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32354807]\n",
      " [ 4.5424398 ]\n",
      " [ 3.76028055]\n",
      " [ 1.52037232]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  934\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09989348]\n",
      " [10.7400459 ]\n",
      " [18.25815795]\n",
      " [18.19609496]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.06523604e-04]\n",
      " [ 3.40045896e-01]\n",
      " [-4.18420474e-02]\n",
      " [-3.03905036e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.13472782e-08]\n",
      " [1.15631211e-01]\n",
      " [1.75075693e-03]\n",
      " [9.23582707e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.026217531263459323 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32356259]\n",
      " [ 4.54334957]\n",
      " [ 3.76099656]\n",
      " [ 1.52006563]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  935\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09991713]\n",
      " [10.73910898]\n",
      " [18.25831036]\n",
      " [18.19691389]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-8.28663655e-05]\n",
      " [ 3.39108982e-01]\n",
      " [-4.16896384e-02]\n",
      " [-3.03086111e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.86683454e-09]\n",
      " [1.14994902e-01]\n",
      " [1.73802595e-03]\n",
      " [9.18611907e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.026074265663526143 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32357697]\n",
      " [ 4.54425688]\n",
      " [ 3.76171051]\n",
      " [ 1.51975965]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  936\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.09994054]\n",
      " [10.73817464]\n",
      " [18.25846207]\n",
      " [18.19773061]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-5.94608366e-05]\n",
      " [ 3.38174638e-01]\n",
      " [-4.15379264e-02]\n",
      " [-3.02269389e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.53559109e-09]\n",
      " [1.14362086e-01]\n",
      " [1.72539933e-03]\n",
      " [9.13667832e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.025931784019799023 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3235912 ]\n",
      " [ 4.54516173]\n",
      " [ 3.76242242]\n",
      " [ 1.51945437]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  937\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0999637 ]\n",
      " [10.73724286]\n",
      " [18.25861309]\n",
      " [18.19854514]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-3.63047551e-05]\n",
      " [ 3.37242858e-01]\n",
      " [-4.13869074e-02]\n",
      " [-3.01454862e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.31803524e-09]\n",
      " [1.13732745e-01]\n",
      " [1.71287610e-03]\n",
      " [9.08750337e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.025790082027137787 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32360528]\n",
      " [ 4.54606413]\n",
      " [ 3.76313228]\n",
      " [ 1.51914979]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  938\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.0999866 ]\n",
      " [10.73631363]\n",
      " [18.25876342]\n",
      " [18.19935748]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[-1.33958790e-05]\n",
      " [ 3.36313634e-01]\n",
      " [-4.12365771e-02]\n",
      " [-3.00642525e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.79449574e-10]\n",
      " [1.13106860e-01]\n",
      " [1.70045529e-03]\n",
      " [9.03859276e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02564915540426939 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32361923]\n",
      " [ 4.54696408]\n",
      " [ 3.76384012]\n",
      " [ 1.51884591]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  939\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10000927]\n",
      " [10.73538696]\n",
      " [18.25891307]\n",
      " [18.20016763]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 9.26801361e-06]\n",
      " [ 3.35386959e-01]\n",
      " [-4.10869318e-02]\n",
      " [-2.99832371e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.58960763e-11]\n",
      " [1.12484412e-01]\n",
      " [1.68813596e-03]\n",
      " [8.98994506e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02550899989365106 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32363304]\n",
      " [ 4.5478616 ]\n",
      " [ 3.76454592]\n",
      " [ 1.51854274]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  940\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10003169]\n",
      " [10.73446283]\n",
      " [18.25906203]\n",
      " [18.20097561]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 3.16891251e-05]\n",
      " [ 3.34462828e-01]\n",
      " [-4.09379673e-02]\n",
      " [-2.99024395e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.00420065e-09]\n",
      " [1.11865383e-01]\n",
      " [1.67591716e-03]\n",
      " [8.94155885e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.025369611261337254 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32364671]\n",
      " [ 4.54875669]\n",
      " [ 3.7652497 ]\n",
      " [ 1.51824026]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  941\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10005387]\n",
      " [10.73354123]\n",
      " [18.25921032]\n",
      " [18.20178141]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 5.38696383e-05]\n",
      " [ 3.33541233e-01]\n",
      " [-4.07896797e-02]\n",
      " [-2.98218589e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.90193793e-09]\n",
      " [1.11249754e-01]\n",
      " [1.66379797e-03]\n",
      " [8.89343271e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.025230985296844408 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32366024]\n",
      " [ 4.54964934]\n",
      " [ 3.76595146]\n",
      " [ 1.51793848]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  942\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10007581]\n",
      " [10.73262217]\n",
      " [18.25935793]\n",
      " [18.20258505]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 7.58117167e-05]\n",
      " [ 3.32622169e-01]\n",
      " [-4.06420650e-02]\n",
      " [-2.97414950e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.74741639e-09]\n",
      " [1.10637507e-01]\n",
      " [1.65177745e-03]\n",
      " [8.84556523e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.025093117813017516 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32367364]\n",
      " [ 4.55053959]\n",
      " [ 3.76665121]\n",
      " [ 1.5176374 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  943\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10009752]\n",
      " [10.73170563]\n",
      " [18.25950488]\n",
      " [18.20338653]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 9.75175047e-05]\n",
      " [ 3.31705627e-01]\n",
      " [-4.04951194e-02]\n",
      " [-2.96613469e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.50966373e-09]\n",
      " [1.10028623e-01]\n",
      " [1.63985470e-03]\n",
      " [8.79795500e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02495600464589752 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3236869 ]\n",
      " [ 4.55142741]\n",
      " [ 3.76734896]\n",
      " [ 1.51733701]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  944\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10011899]\n",
      " [10.7307916 ]\n",
      " [18.25965116]\n",
      " [18.20418586]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 1.18989128e-04]\n",
      " [ 3.30791602e-01]\n",
      " [-4.03488391e-02]\n",
      " [-2.95814142e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.41584125e-08]\n",
      " [1.09423084e-01]\n",
      " [1.62802881e-03]\n",
      " [8.75060064e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.024819641654590337 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32370003]\n",
      " [ 4.55231284]\n",
      " [ 3.76804471]\n",
      " [ 1.51703732]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  945\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10014023]\n",
      " [10.72988009]\n",
      " [18.25979678]\n",
      " [18.20498304]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 1.40228693e-04]\n",
      " [ 3.29880087e-01]\n",
      " [-4.02032200e-02]\n",
      " [-2.95016961e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.96640862e-08]\n",
      " [1.08820872e-01]\n",
      " [1.61629890e-03]\n",
      " [8.70350075e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.024684024721135997 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32371303]\n",
      " [ 4.55319586]\n",
      " [ 3.76873847]\n",
      " [ 1.51673832]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  946\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10016124]\n",
      " [10.72897108]\n",
      " [18.25994174]\n",
      " [18.20577808]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 1.61238287e-04]\n",
      " [ 3.28971075e-01]\n",
      " [-4.00582585e-02]\n",
      " [-2.94221922e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.59977852e-08]\n",
      " [1.08221968e-01]\n",
      " [1.60466407e-03]\n",
      " [8.65665395e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.024549149750377627 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3237259 ]\n",
      " [ 4.55407649]\n",
      " [ 3.76943024]\n",
      " [ 1.51644002]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  947\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10018202]\n",
      " [10.72806456]\n",
      " [18.26008605]\n",
      " [18.20657098]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 1.82019980e-04]\n",
      " [ 3.28064561e-01]\n",
      " [-3.99139507e-02]\n",
      " [-2.93429018e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.31312733e-08]\n",
      " [1.07626356e-01]\n",
      " [1.59312346e-03]\n",
      " [8.61005888e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.024415012669832314 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32373864]\n",
      " [ 4.55495474]\n",
      " [ 3.77012003]\n",
      " [ 1.5161424 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  948\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10020258]\n",
      " [10.72716054]\n",
      " [18.26022971]\n",
      " [18.20736176]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 2.02575824e-04]\n",
      " [ 3.27160536e-01]\n",
      " [-3.97702929e-02]\n",
      " [-2.92638244e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.10369645e-08]\n",
      " [1.07034016e-01]\n",
      " [1.58167619e-03]\n",
      " [8.56371417e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.024281609429563963 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32375126]\n",
      " [ 4.5558306 ]\n",
      " [ 3.77080785]\n",
      " [ 1.51584548]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  949\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10022291]\n",
      " [10.726259  ]\n",
      " [18.26037272]\n",
      " [18.20815041]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 2.22907851e-04]\n",
      " [ 3.26258996e-01]\n",
      " [-3.96272812e-02]\n",
      " [-2.91849593e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.96879102e-08]\n",
      " [1.06444932e-01]\n",
      " [1.57032142e-03]\n",
      " [8.51761847e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02414893600205329 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32376374]\n",
      " [ 4.55670409]\n",
      " [ 3.77149369]\n",
      " [ 1.51554924]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  950\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10024302]\n",
      " [10.72535993]\n",
      " [18.26051509]\n",
      " [18.20893694]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 2.43018077e-04]\n",
      " [ 3.25359932e-01]\n",
      " [-3.94849121e-02]\n",
      " [-2.91063059e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.90577859e-08]\n",
      " [1.05859086e-01]\n",
      " [1.55905828e-03]\n",
      " [8.47177042e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.024016988382072908 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32377611]\n",
      " [ 4.55757522]\n",
      " [ 3.77217758]\n",
      " [ 1.5152537 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  951\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10026291]\n",
      " [10.72446334]\n",
      " [18.26065682]\n",
      " [18.20972136]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 2.62908499e-04]\n",
      " [ 3.24463340e-01]\n",
      " [-3.93431818e-02]\n",
      " [-2.90278637e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.91208788e-08]\n",
      " [1.05276459e-01]\n",
      " [1.54788595e-03]\n",
      " [8.42616869e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.023885762586559854 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32378835]\n",
      " [ 4.55844398]\n",
      " [ 3.77285951]\n",
      " [ 1.51495884]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  952\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10028258]\n",
      " [10.72356921]\n",
      " [18.26079791]\n",
      " [18.21050368]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 2.82581096e-04]\n",
      " [ 3.23569211e-01]\n",
      " [-3.92020866e-02]\n",
      " [-2.89496320e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.98520759e-08]\n",
      " [1.04697034e-01]\n",
      " [1.53680359e-03]\n",
      " [8.38081194e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.023755254654490278 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32380046]\n",
      " [ 4.55931039]\n",
      " [ 3.77353949]\n",
      " [ 1.51466466]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  953\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10030204]\n",
      " [10.72267754]\n",
      " [18.26093838]\n",
      " [18.2112839 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 3.02037831e-04]\n",
      " [ 3.22677540e-01]\n",
      " [-3.90616229e-02]\n",
      " [-2.88716104e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.12268514e-08]\n",
      " [1.04120795e-01]\n",
      " [1.52581038e-03]\n",
      " [8.33569886e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.023625460646755542 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32381246]\n",
      " [ 4.56017445]\n",
      " [ 3.77421753]\n",
      " [ 1.51437117]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  954\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10032128]\n",
      " [10.72178832]\n",
      " [18.26107821]\n",
      " [18.21206202]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 3.21280649e-04]\n",
      " [ 3.21788321e-01]\n",
      " [-3.89217871e-02]\n",
      " [-2.87937981e-01]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.03221255e-07]\n",
      " [1.03547723e-01]\n",
      " [1.51490551e-03]\n",
      " [8.29082811e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02349637664603703 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32382433]\n",
      " [ 4.56103616]\n",
      " [ 3.77489362]\n",
      " [ 1.51407837]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  955\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10034031]\n",
      " [10.72090155]\n",
      " [18.26121742]\n",
      " [18.21283805]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00034031]\n",
      " [ 0.32090155]\n",
      " [-0.03878258]\n",
      " [-0.28716195]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.15811901e-07]\n",
      " [1.02977802e-01]\n",
      " [1.50408817e-03]\n",
      " [8.24619839e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02336799875668421 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32383609]\n",
      " [ 4.56189554]\n",
      " [ 3.77556779]\n",
      " [ 1.51378625]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  956\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10035913]\n",
      " [10.72001721]\n",
      " [18.26135602]\n",
      " [18.213612  ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00035913]\n",
      " [ 0.32001721]\n",
      " [-0.03864398]\n",
      " [-0.286388  ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.28975955e-07]\n",
      " [1.02411014e-01]\n",
      " [1.49335756e-03]\n",
      " [8.20180840e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.023240323104590777 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32384773]\n",
      " [ 4.5627526 ]\n",
      " [ 3.77624002]\n",
      " [ 1.51349481]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  957\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10037774]\n",
      " [10.7191353 ]\n",
      " [18.26149399]\n",
      " [18.21438388]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00037774]\n",
      " [ 0.3191353 ]\n",
      " [-0.03850601]\n",
      " [-0.28561612]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.42691125e-07]\n",
      " [1.01847343e-01]\n",
      " [1.48271290e-03]\n",
      " [8.15765683e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.023113345837073918 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32385925]\n",
      " [ 4.56360733]\n",
      " [ 3.77691034]\n",
      " [ 1.51320404]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  958\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10039615]\n",
      " [10.71825583]\n",
      " [18.26163135]\n",
      " [18.21515368]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00039615]\n",
      " [ 0.31825583]\n",
      " [-0.03836865]\n",
      " [-0.28484632]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.56935650e-07]\n",
      " [1.01286771e-01]\n",
      " [1.47215341e-03]\n",
      " [8.11374241e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.022987063122753483 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32387066]\n",
      " [ 4.56445974]\n",
      " [ 3.77757874]\n",
      " [ 1.51291396]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  959\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10041435]\n",
      " [10.71737877]\n",
      " [18.2617681 ]\n",
      " [18.21592142]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00041435]\n",
      " [ 0.31737877]\n",
      " [-0.0382319 ]\n",
      " [-0.28407858]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.71688285e-07]\n",
      " [1.00729281e-01]\n",
      " [1.46167831e-03]\n",
      " [8.07006385e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.022861471151430265 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32388195]\n",
      " [ 4.56530984]\n",
      " [ 3.77824523]\n",
      " [ 1.51262456]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  960\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10043235]\n",
      " [10.71650412]\n",
      " [18.26190424]\n",
      " [18.2166871 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00043235]\n",
      " [ 0.31650412]\n",
      " [-0.03809576]\n",
      " [-0.2833129 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[1.86928300e-07]\n",
      " [1.00174857e-01]\n",
      " [1.45128684e-03]\n",
      " [8.02661987e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02273656613396942 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32389313]\n",
      " [ 4.56615763]\n",
      " [ 3.77890982]\n",
      " [ 1.51233583]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  961\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10045015]\n",
      " [10.71563188]\n",
      " [18.26203978]\n",
      " [18.21745073]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00045015]\n",
      " [ 0.31563188]\n",
      " [-0.03796022]\n",
      " [-0.28254927]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.02635458e-07]\n",
      " [9.96234814e-02]\n",
      " [1.44097823e-03]\n",
      " [7.98340922e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.022612344302177192 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3239042 ]\n",
      " [ 4.56700313]\n",
      " [ 3.7795725 ]\n",
      " [ 1.51204778]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  962\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10046775]\n",
      " [10.71476203]\n",
      " [18.26217472]\n",
      " [18.2182123 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00046775]\n",
      " [ 0.31476203]\n",
      " [-0.03782528]\n",
      " [-0.2817877 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.18790014e-07]\n",
      " [9.90751386e-02]\n",
      " [1.43075175e-03]\n",
      " [7.94043061e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.022488801908686205 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32391516]\n",
      " [ 4.56784634]\n",
      " [ 3.7802333 ]\n",
      " [ 1.51176041]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  963\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10048515]\n",
      " [10.71389459]\n",
      " [18.26230906]\n",
      " [18.21897184]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00048515]\n",
      " [ 0.31389459]\n",
      " [-0.03769094]\n",
      " [-0.28102816]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.35372700e-07]\n",
      " [9.85298116e-02]\n",
      " [1.42060665e-03]\n",
      " [7.89768282e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.022365935226837656 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32392601]\n",
      " [ 4.56868726]\n",
      " [ 3.78089221]\n",
      " [ 1.5114737 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  964\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10050236]\n",
      " [10.71302953]\n",
      " [18.26244281]\n",
      " [18.21972933]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00050236]\n",
      " [ 0.31302953]\n",
      " [-0.03755719]\n",
      " [-0.28027067]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.52364718e-07]\n",
      " [9.79874841e-02]\n",
      " [1.41054220e-03]\n",
      " [7.85516458e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.022243740550562774 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32393675]\n",
      " [ 4.5695259 ]\n",
      " [ 3.78154924]\n",
      " [ 1.51118767]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  965\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10051937]\n",
      " [10.71216685]\n",
      " [18.26257597]\n",
      " [18.2204848 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00051937]\n",
      " [ 0.31216685]\n",
      " [-0.03742403]\n",
      " [-0.2795152 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.69747728e-07]\n",
      " [9.74481396e-02]\n",
      " [1.40055767e-03]\n",
      " [7.81287466e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.022122214194268946 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32394738]\n",
      " [ 4.57036226]\n",
      " [ 3.78220439]\n",
      " [ 1.51090231]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  966\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10053619]\n",
      " [10.71130654]\n",
      " [18.26270855]\n",
      " [18.22123824]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00053619]\n",
      " [ 0.31130654]\n",
      " [-0.03729145]\n",
      " [-0.27876176]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[2.87503840e-07]\n",
      " [9.69117619e-02]\n",
      " [1.39065233e-03]\n",
      " [7.77081182e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.022001352492722417 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32395791]\n",
      " [ 4.57119636]\n",
      " [ 3.78285767]\n",
      " [ 1.51061763]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  967\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10055283]\n",
      " [10.7104486 ]\n",
      " [18.26284054]\n",
      " [18.22198966]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00055283]\n",
      " [ 0.3104486 ]\n",
      " [-0.03715946]\n",
      " [-0.27801034]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.05615604e-07]\n",
      " [9.63783348e-02]\n",
      " [1.38082549e-03]\n",
      " [7.72897485e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.021881151800934955 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32396833]\n",
      " [ 4.57202819]\n",
      " [ 3.78350909]\n",
      " [ 1.51033361]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  968\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10056927]\n",
      " [10.70959303]\n",
      " [18.26297195]\n",
      " [18.22273907]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00056927]\n",
      " [ 0.30959303]\n",
      " [-0.03702805]\n",
      " [-0.27726093]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.24066004e-07]\n",
      " [9.58478423e-02]\n",
      " [1.37107643e-03]\n",
      " [7.68736252e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.021761608494049452 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32397864]\n",
      " [ 4.57285777]\n",
      " [ 3.78415865]\n",
      " [ 1.51005025]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  969\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10058552]\n",
      " [10.70873981]\n",
      " [18.26310279]\n",
      " [18.22348646]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00058552]\n",
      " [ 0.30873981]\n",
      " [-0.03689721]\n",
      " [-0.27651354]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.42838444e-07]\n",
      " [9.53202683e-02]\n",
      " [1.36140446e-03]\n",
      " [7.64597361e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.021642718967226603 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32398886]\n",
      " [ 4.5736851 ]\n",
      " [ 3.78480635]\n",
      " [ 1.50976757]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  970\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.1006016 ]\n",
      " [10.70788894]\n",
      " [18.26323305]\n",
      " [18.22423186]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.0006016 ]\n",
      " [ 0.30788894]\n",
      " [-0.03676695]\n",
      " [-0.27576814]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.61916742e-07]\n",
      " [9.47955969e-02]\n",
      " [1.35180888e-03]\n",
      " [7.60480694e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.021524479635532362 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32399897]\n",
      " [ 4.57451019]\n",
      " [ 3.78545221]\n",
      " [ 1.50948555]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  971\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10061748]\n",
      " [10.70704041]\n",
      " [18.26336274]\n",
      " [18.22497525]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00061748]\n",
      " [ 0.30704041]\n",
      " [-0.03663726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-0.27502475]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[3.81285123e-07]\n",
      " [9.42738123e-02]\n",
      " [1.34228901e-03]\n",
      " [7.56386128e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.021406886933825683 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32400898]\n",
      " [ 4.57533304]\n",
      " [ 3.78609623]\n",
      " [ 1.50920419]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  972\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10063319]\n",
      " [10.70619422]\n",
      " [18.26349186]\n",
      " [18.22571665]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00063319]\n",
      " [ 0.30619422]\n",
      " [-0.03650814]\n",
      " [-0.27428335]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.00928207e-07]\n",
      " [9.37548987e-02]\n",
      " [1.33284418e-03]\n",
      " [7.52313547e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.021289937316646537 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32401889]\n",
      " [ 4.57615366]\n",
      " [ 3.78673841]\n",
      " [ 1.5089235 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  973\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10064871]\n",
      " [10.70535036]\n",
      " [18.26362042]\n",
      " [18.22645607]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00064871]\n",
      " [ 0.30535036]\n",
      " [-0.03637958]\n",
      " [-0.27354393]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.20831005e-07]\n",
      " [9.32388405e-02]\n",
      " [1.32347372e-03]\n",
      " [7.48262830e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.021173627258108042 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3240287 ]\n",
      " [ 4.57697205]\n",
      " [ 3.78737876]\n",
      " [ 1.50864347]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  974\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10066406]\n",
      " [10.70450882]\n",
      " [18.26374842]\n",
      " [18.2271935 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00066406]\n",
      " [ 0.30450882]\n",
      " [-0.03625158]\n",
      " [-0.2728065 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.40978907e-07]\n",
      " [9.27256221e-02]\n",
      " [1.31417696e-03]\n",
      " [7.44233860e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.021057953251782627 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32403841]\n",
      " [ 4.57778822]\n",
      " [ 3.78801729]\n",
      " [ 1.50836411]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  975\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10067923]\n",
      " [10.7036696 ]\n",
      " [18.26387586]\n",
      " [18.22792896]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00067923]\n",
      " [ 0.3036696 ]\n",
      " [-0.03612414]\n",
      " [-0.27207104]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.61357675e-07]\n",
      " [9.22152279e-02]\n",
      " [1.30495325e-03]\n",
      " [7.40226520e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.020942911810595363 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32404803]\n",
      " [ 4.57860218]\n",
      " [ 3.78865399]\n",
      " [ 1.5080854 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  976\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10069423]\n",
      " [10.7028327 ]\n",
      " [18.26400275]\n",
      " [18.22866244]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00069423]\n",
      " [ 0.3028327 ]\n",
      " [-0.03599725]\n",
      " [-0.27133756]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[4.81953438e-07]\n",
      " [9.17076425e-02]\n",
      " [1.29580193e-03]\n",
      " [7.36240694e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02082849946671443 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32405755]\n",
      " [ 4.57941393]\n",
      " [ 3.78928888]\n",
      " [ 1.50780735]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  977\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10070905]\n",
      " [10.7019981 ]\n",
      " [18.26412909]\n",
      " [18.22939396]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00070905]\n",
      " [ 0.3019981 ]\n",
      " [-0.03587091]\n",
      " [-0.27060604]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.02752682e-07]\n",
      " [9.12028506e-02]\n",
      " [1.28672237e-03]\n",
      " [7.32276264e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.020714712771442944 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32406697]\n",
      " [ 4.58022348]\n",
      " [ 3.78992196]\n",
      " [ 1.50752996]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  978\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.1007237 ]\n",
      " [10.7011658 ]\n",
      " [18.26425488]\n",
      " [18.23012353]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.0007237 ]\n",
      " [ 0.3011658 ]\n",
      " [-0.03574512]\n",
      " [-0.26987647]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.23742241e-07]\n",
      " [9.07008370e-02]\n",
      " [1.27771392e-03]\n",
      " [7.28333117e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.020601548295111717 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3240763 ]\n",
      " [ 4.58103084]\n",
      " [ 3.79055324]\n",
      " [ 1.50725322]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  979\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10073818]\n",
      " [10.70033579]\n",
      " [18.26438012]\n",
      " [18.23085113]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00073818]\n",
      " [ 0.30033579]\n",
      " [-0.03561988]\n",
      " [-0.26914887]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.44909295e-07]\n",
      " [9.02015865e-02]\n",
      " [1.26877596e-03]\n",
      " [7.24411137e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.02048900262697229 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32408554]\n",
      " [ 4.581836  ]\n",
      " [ 3.79118271]\n",
      " [ 1.50697714]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  980\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10075249]\n",
      " [10.69950807]\n",
      " [18.26450482]\n",
      " [18.23157679]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00075249]\n",
      " [ 0.29950807]\n",
      " [-0.03549518]\n",
      " [-0.26842321]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.66241356e-07]\n",
      " [8.97050839e-02]\n",
      " [1.25990787e-03]\n",
      " [7.20510210e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.020377072375090788 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32409469]\n",
      " [ 4.58263898]\n",
      " [ 3.7918104 ]\n",
      " [ 1.50670172]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  981\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10076663]\n",
      " [10.69868263]\n",
      " [18.26462898]\n",
      " [18.2323005 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00076663]\n",
      " [ 0.29868263]\n",
      " [-0.03537102]\n",
      " [-0.2676995 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[5.87726266e-07]\n",
      " [8.92113142e-02]\n",
      " [1.25110901e-03]\n",
      " [7.16630224e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.020265754166242596 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32410374]\n",
      " [ 4.58343978]\n",
      " [ 3.7924363 ]\n",
      " [ 1.50642694]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  982\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10078061]\n",
      " [10.69785947]\n",
      " [18.26475261]\n",
      " [18.23302227]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00078061]\n",
      " [ 0.29785947]\n",
      " [-0.03524739]\n",
      " [-0.26697773]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.09352189e-07]\n",
      " [8.87202626e-02]\n",
      " [1.24237879e-03]\n",
      " [7.12771064e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.020155044645806745 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3241127 ]\n",
      " [ 4.58423841]\n",
      " [ 3.79306041]\n",
      " [ 1.50615282]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  983\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10079442]\n",
      " [10.69703857]\n",
      " [18.2648757 ]\n",
      " [18.23374211]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00079442]\n",
      " [ 0.29703857]\n",
      " [-0.0351243 ]\n",
      " [-0.26625789]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.31107603e-07]\n",
      " [8.82319141e-02]\n",
      " [1.23371660e-03]\n",
      " [7.08932620e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.020044940477662997 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32412157]\n",
      " [ 4.58503487]\n",
      " [ 3.79368275]\n",
      " [ 1.50587935]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  984\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10080807]\n",
      " [10.69621994]\n",
      " [18.26499826]\n",
      " [18.23446003]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00080807]\n",
      " [ 0.29621994]\n",
      " [-0.03500174]\n",
      " [-0.26553997]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.52981294e-07]\n",
      " [8.77462540e-02]\n",
      " [1.22512183e-03]\n",
      " [7.05114780e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.019935438344087075 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32413036]\n",
      " [ 4.58582917]\n",
      " [ 3.79430332]\n",
      " [ 1.50560653]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  985\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10082156]\n",
      " [10.69540357]\n",
      " [18.26512029]\n",
      " [18.23517601]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00082156]\n",
      " [ 0.29540357]\n",
      " [-0.03487971]\n",
      " [-0.26482399]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.74962349e-07]\n",
      " [8.72632675e-02]\n",
      " [1.21659390e-03]\n",
      " [7.01317432e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.019826534945646193 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32413906]\n",
      " [ 4.58662132]\n",
      " [ 3.79492212]\n",
      " [ 1.50533436]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  986\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10083489]\n",
      " [10.69458944]\n",
      " [18.2652418 ]\n",
      " [18.23589009]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00083489]\n",
      " [ 0.29458944]\n",
      " [-0.0347582 ]\n",
      " [-0.26410991]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[6.97040151e-07]\n",
      " [8.67829401e-02]\n",
      " [1.20813222e-03]\n",
      " [6.97540466e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.019718227001100815 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32414767]\n",
      " [ 4.58741132]\n",
      " [ 3.79553916]\n",
      " [ 1.50506283]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  987\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10084806]\n",
      " [10.69377756]\n",
      " [18.26536279]\n",
      " [18.23660224]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00084806]\n",
      " [ 0.29377756]\n",
      " [-0.03463721]\n",
      " [-0.26339776]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.19204373e-07]\n",
      " [8.63052572e-02]\n",
      " [1.19973619e-03]\n",
      " [6.93783774e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.01961051124729763 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32415619]\n",
      " [ 4.58819917]\n",
      " [ 3.79615445]\n",
      " [ 1.50479196]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  988\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10086107]\n",
      " [10.69296792]\n",
      " [18.26548326]\n",
      " [18.2373125 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00086107]\n",
      " [ 0.29296792]\n",
      " [-0.03451674]\n",
      " [-0.2626875 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.41444968e-07]\n",
      " [8.58302043e-02]\n",
      " [1.19140526e-03]\n",
      " [6.90047245e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.01950338443907184 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32416463]\n",
      " [ 4.58898489]\n",
      " [ 3.79676798]\n",
      " [ 1.50452172]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  989\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10087393]\n",
      " [10.69216052]\n",
      " [18.26560321]\n",
      " [18.23802085]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00087393]\n",
      " [ 0.29216052]\n",
      " [-0.03439679]\n",
      " [-0.26197915]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.63752167e-07]\n",
      " [8.53577671e-02]\n",
      " [1.18313884e-03]\n",
      " [6.86330771e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.019396843349144745 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32417298]\n",
      " [ 4.58976847]\n",
      " [ 3.79737977]\n",
      " [ 1.50425213]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  990\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10088663]\n",
      " [10.69135533]\n",
      " [18.26572266]\n",
      " [18.2387273 ]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00088663]\n",
      " [ 0.29135533]\n",
      " [-0.03427734]\n",
      " [-0.2612727 ]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[7.86116474e-07]\n",
      " [8.48879312e-02]\n",
      " [1.17493637e-03]\n",
      " [6.82634244e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.01929088476802565 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32418125]\n",
      " [ 4.59054993]\n",
      " [ 3.79798982]\n",
      " [ 1.50398319]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  991\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10089918]\n",
      " [10.69055237]\n",
      " [18.26584159]\n",
      " [18.23943186]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00089918]\n",
      " [ 0.29055237]\n",
      " [-0.03415841]\n",
      " [-0.26056814]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.08528654e-07]\n",
      " [8.44206824e-02]\n",
      " [1.16679730e-03]\n",
      " [6.78957558e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.01918550550390863 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32418944]\n",
      " [ 4.59132927]\n",
      " [ 3.79859813]\n",
      " [ 1.50371488]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  992\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10091158]\n",
      " [10.68975163]\n",
      " [18.26596001]\n",
      " [18.24013453]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00091158]\n",
      " [ 0.28975163]\n",
      " [-0.03403999]\n",
      " [-0.25986547]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.30979734e-07]\n",
      " [8.39560065e-02]\n",
      " [1.15872107e-03]\n",
      " [6.75300605e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.019080702382577377 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32419754]\n",
      " [ 4.59210649]\n",
      " [ 3.79920471]\n",
      " [ 1.50344722]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  993\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10092383]\n",
      " [10.68895309]\n",
      " [18.26607793]\n",
      " [18.24083533]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00092383]\n",
      " [ 0.28895309]\n",
      " [-0.03392207]\n",
      " [-0.25916467]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.53460995e-07]\n",
      " [8.34938895e-02]\n",
      " [1.15070713e-03]\n",
      " [6.71663279e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.01897647224730513 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32420557]\n",
      " [ 4.5928816 ]\n",
      " [ 3.79980957]\n",
      " [ 1.50318019]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  994\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10093593]\n",
      " [10.68815676]\n",
      " [18.26619534]\n",
      " [18.24153424]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00093593]\n",
      " [ 0.28815676]\n",
      " [-0.03380466]\n",
      " [-0.25846576]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.75963964e-07]\n",
      " [8.30343173e-02]\n",
      " [1.14275493e-03]\n",
      " [6.68045475e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.018872811958755797 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32421351]\n",
      " [ 4.59365461]\n",
      " [ 3.80041271]\n",
      " [ 1.5029138 ]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  995\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10094788]\n",
      " [10.68736262]\n",
      " [18.26631226]\n",
      " [18.24223129]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00094788]\n",
      " [ 0.28736262]\n",
      " [-0.03368774]\n",
      " [-0.25776871]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[8.98480414e-07]\n",
      " [8.25772760e-02]\n",
      " [1.13486395e-03]\n",
      " [6.64447087e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.01876971839488919 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32422138]\n",
      " [ 4.59442553]\n",
      " [ 3.80101414]\n",
      " [ 1.50264805]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  996\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10095969]\n",
      " [10.68657067]\n",
      " [18.26642868]\n",
      " [18.24292647]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00095969]\n",
      " [ 0.28657067]\n",
      " [-0.03357132]\n",
      " [-0.25707353]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.21002354e-07]\n",
      " [8.21227517e-02]\n",
      " [1.12703364e-03]\n",
      " [6.60868012e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.018667188450862803 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32422916]\n",
      " [ 4.59519435]\n",
      " [ 3.80161385]\n",
      " [ 1.50238294]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  997\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10097135]\n",
      " [10.68578091]\n",
      " [18.2665446 ]\n",
      " [18.24361979]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00097135]\n",
      " [ 0.28578091]\n",
      " [-0.0334554 ]\n",
      " [-0.25638021]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.43522024e-07]\n",
      " [8.16707307e-02]\n",
      " [1.11926349e-03]\n",
      " [6.57308146e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.018565219038935474 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32423687]\n",
      " [ 4.59596108]\n",
      " [ 3.80221187]\n",
      " [ 1.50211845]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  998\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10098287]\n",
      " [10.68499333]\n",
      " [18.26666004]\n",
      " [18.24431125]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00098287]\n",
      " [ 0.28499333]\n",
      " [-0.03333996]\n",
      " [-0.25568875]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.66031896e-07]\n",
      " [8.12211992e-02]\n",
      " [1.11155297e-03]\n",
      " [6.53767385e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.018463807088373484 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.3242445 ]\n",
      " [ 4.59672574]\n",
      " [ 3.80280818]\n",
      " [ 1.50185461]] \n",
      "\n",
      "**********************************************************************************\n",
      "Iteration =  999\n",
      "Step 1: Calculate the y_prediction \n",
      "\n",
      "y_predicted = np.dot(X, theta)\n",
      "[[22.10099425]\n",
      " [10.68420792]\n",
      " [18.26677499]\n",
      " [18.24500086]] \n",
      "\n",
      "error = y_predicted - y\n",
      "[[ 0.00099425]\n",
      " [ 0.28420792]\n",
      " [-0.03322501]\n",
      " [-0.25499914]] \n",
      "\n",
      "sq_error = error **2\n",
      "[[9.88524659e-07]\n",
      " [8.07741437e-02]\n",
      " [1.10390155e-03]\n",
      " [6.50245626e-02]] \n",
      "\n",
      "m =  4\n",
      "cost = sq_error.sum() / (2*m)\n",
      "cost =  0.01836294954535231 \n",
      "\n",
      "Finding optimal parameters using Gradient Descent\n",
      "theta values :\n",
      "[[17.32425206]\n",
      " [ 4.59748831]\n",
      " [ 3.8034028 ]\n",
      " [ 1.50159139]] \n",
      "\n",
      "**********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data1 = pd.DataFrame({\"TV\":[230.1,44.5,17.2,151.5],\"Radio\":[37.8,39.3,45.9,41.3],\n",
    "                      \"News\":[69.1,23.1,34.7,13.2],\"Sales\" : [22.1,10.4,18.3,18.5]})\n",
    "\n",
    "print(data1)\n",
    "\n",
    "X = data1.iloc[:,0:3] # read first two columns into X\n",
    "y = data1.iloc[:,3] # read the third column into y\n",
    "\n",
    "print(\"Input Data = X\")\n",
    "print(X.head())\n",
    "print(\"Shape of input X\", X.shape,\"\\n\")\n",
    "\n",
    "print(\"Target = y\",)\n",
    "print(y.head())\n",
    "print(\"Shape of input y\", y.shape,\"\\n\")\n",
    "\n",
    "# no. of training samples\n",
    "m = len(y) \n",
    "print(\"No of training samples :\",m,\"\\n\")\n",
    "\n",
    "# Normalization\n",
    "print(\"Normalize the Input data X\")\n",
    "X = (X - np.mean(X))/np.std(X)\n",
    "print(X.head(),\"\\n\")\n",
    "\n",
    "# \n",
    "ones = np.ones((m,1))\n",
    "X = np.hstack((ones, X))\n",
    "print(X[0:5])\n",
    "print(\"Shape of X\",X.shape,\"\\n\")\n",
    "\n",
    "y = y[:,np.newaxis]\n",
    "print(y[0:5])\n",
    "print(\"Shape of y\",y.shape,\"\\n\")\n",
    "\n",
    "alpha = 0.01\n",
    "print(\"alpha :\",alpha)\n",
    "num_iters = 400\n",
    "print(\"num_iters :\",num_iters,\"\\n\")\n",
    "theta = np.zeros((4,1))\n",
    "print(\"theta :\")\n",
    "print(theta)\n",
    "print(\"Shape of theta\",theta.shape,\"\\n\")\n",
    "iteration = 1000\n",
    "print(\"**********************************************************************************\")\n",
    "\n",
    "plot_loss = list()\n",
    "plot_iteartion = list()\n",
    "\n",
    "for i in range(iteration):\n",
    "    plot_iteartion.append(i)\n",
    "    print(\"Iteration = \",i)\n",
    "    print(\"Step 1: Calculate the y_prediction\",\"\\n\")\n",
    "    \n",
    "    y_predicted = np.dot(X, theta) \n",
    "    print(\"y_predicted = np.dot(X, theta)\")\n",
    "    print(y_predicted[0:5],\"\\n\")\n",
    "    \n",
    "    error = y_predicted - y\n",
    "    print(\"error = y_predicted - y\")\n",
    "    print(error[0:5],\"\\n\")\n",
    "    \n",
    "    sq_error =error**2\n",
    "    print(\"sq_error = error **2\")\n",
    "    print(sq_error[0:5],\"\\n\")\n",
    "    \n",
    "    print(\"m = \",m)\n",
    "    cost = sq_error.sum() / (2*m)\n",
    "    print(\"cost = sq_error.sum() / (2*m)\")\n",
    "    print(\"cost = \",cost,\"\\n\")\n",
    "    plot_loss.append(plot_loss)\n",
    "    \n",
    "    print(\"Finding optimal parameters using Gradient Descent\")\n",
    "    m = len(y)\n",
    "    temp = y_predicted - y\n",
    "    temp = np.dot(X.T, temp)\n",
    "    theta = theta - (alpha/m) * temp\n",
    "    print(\"theta values :\")\n",
    "    print(theta,\"\\n\")\n",
    "    \n",
    "    print(\"**********************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(plot_iteartion,plot_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
