{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Deep Learning: \n",
    "    - Taking Large volume of structured or unstuctured data and using complex algorithms to train neural network.\n",
    "      It perform complex operations to extract hidden patterns and featu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Why Deep leanring? \n",
    "    - Traditional ML algorithms solve lot of use cases, but they are not usefull while working with high dimensional data,\n",
    "      that is where we have a large number of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Perceptron: \n",
    "    - A system (either hardware or software) that takes in one or more input values, runs a function on the weighted sum of \n",
    "      the inputs, and computes a single output value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Neural Network: \n",
    "    - Computer system modelied like human brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Shallow Neural network : \n",
    "    - Neural network usually have only one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Components in Neural Network : \n",
    "  - Input layer\n",
    "  - Hidden layer\n",
    "  - Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example for poission Distribution:\n",
    "    - Number of customers that will enter a store on a given day, \n",
    "    - The number of emails that will arrive within the next hour\n",
    "    - How many customers that will churn next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Single Layer Perceptron : Single-Layer Perceptrons cannot classify non-linearly separable data points.\n",
    "                          Complex problems, that involve a lot of parameters cannot be solved by Single-Layer Perceptrons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Multi-layer Perceptron(MLP):It is a Artifitial neural network, It is composed of more than one perceptron. \n",
    "they are composed of an input layer to receive the signal, and output layer that makes a decision or predcition about the input,\n",
    "in between those two, number of hidden layers that are the true computational of the MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Activation Function : Activation function translates the inputs into outputs.The purpose of the activation function is to \n",
    "introduce non-linearity into the output of a neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gradient Descent : An optimization algorithm to minimize the cost function or error. The aim is to find the local-global minima\n",
    "of a  function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Backpropagration : Technique to improve the performance of the network. It backpropages the error and updates the weights to \n",
    "reduce the error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Differece Between Feedforwrd Neutal network and Recurrent Neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hyperparameters : Set of parameter whose value is set before the learning process begings.It determinies how the network is \n",
    "trained and the structure of the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Hyerparameters in Deep Learning :\n",
    "  - Number of Hidden units\n",
    "  - Learning rate\n",
    "  - Epochs\n",
    "  - Network weight Initialization\n",
    "  - Activation Function\n",
    "  - Batch Size\n",
    "  - Momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Learning Rate : It controls how quickly or slowly a neural network model learns a problem.\n",
    "\n",
    "Low Learning rate: Training of the model will progress very slowly.\n",
    "\n",
    "High Learning rate: \n",
    "\n",
    "Dropout: Technique to dropping out some of the hidden or visible units of a network randomly to prevent overfitting of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Consider while weight Initilization:\n",
    "    - Weight should be small\n",
    "    - Weight should not be same\n",
    "    - Weight should have good variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "How Weights are Initilized in a Network?\n",
    "\n",
    "    - Weight initialization is used to define the initial values for the parameters in neural network models prior to training \n",
    "      the models on a dataset\n",
    "    - Weights initialization for neural network layers and nodes that use the Sigmoid and Tanh : glorot” or “xavier” \n",
    "      initialization.\n",
    "    - The “xavier” weight initialization was found to have problems when used to initialize networks that use the rectified \n",
    "      linear (ReLU) activation function.\n",
    "    - Weights initialization for neural network layers and nodes that use the rectified linear (ReLU) : “he” initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "What is weights are initialized to very high or low?\n",
    "    - If weights are initialized with very high values the term np.dot(W,X)+b becomes significantly higher and if an activation \n",
    "      function like sigmoid() is applied,the function maps its value near to 1 where the slope of gradient changes slowly and \n",
    "      learning takes a lot of time\n",
    "    - If weights are initialized with low values it gets mapped to 0, where the case is the same as above\n",
    "    - This problem is called vanishing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Default weight initilizer choosen by keras \n",
    "    - Dense (e.g. MLP): glorot_uniform\n",
    "    - LSTM: glorot_uniform\n",
    "    - CNN: glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Glorot_uniform : (Xavier uniform) :They set the weights neither too much bigger than 1, nor too much less than 1. So, the \n",
    "gradients do not vanish or explode too quickly. They help avoid slow convergence, also ensuring that we do not keep oscillating \n",
    "off the minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initializing all weights to 0:\n",
    "    - Initializing all the weights with zeros leads the neurons to learn the same features during training.\n",
    "    - this makes your model equivalent to a linear model. When you set all weight to 0, the derivative with respect to loss \n",
    "      function is the same for every w in W^l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initializing weights randomly :\n",
    "    - Initializing weights randomly, following standard normal distribution. lead to 2 issues?-?vanishing gradients or exploding\n",
    "      gradients\n",
    "      \n",
    "Initilization weights too large :\n",
    "    - A too-large initialization leads to exploding gradients\n",
    "\n",
    "Initilization weights too small:\n",
    "    - A too-small initialization leads to vanishing gradients\n",
    "\n",
    "How to find appropriate initialization values:\n",
    "    - The mean of the activations should be zero.\n",
    "    - The variance of the activations should stay the same across every layer.\n",
    "    \n",
    "Glorot (Xavier) normal initilization:\n",
    "    - range = randomnormal(0,sigma) \n",
    "    - sigma = sqrt( 2 / (fan_in + fan_out))\n",
    "    - The limit value is sqrt( 2 / (fan_in + fan_out)) and the random values are pulled from the normal (also called Gaussian)\n",
    "    \n",
    "Glorot (Xavier) Uniform initilization:\n",
    "    - while weight initialization instead using fixed limits like -0.01 to 0.01, Glorot uniform initilization used limits that \n",
    "      are based on number of nodes in the network\n",
    "    - range (sqrt( 6 / (fan_in + fan_out)), - sqrt( 6 / (fan_in + fan_out)))\n",
    "\n",
    "        ex : nin = 4 and nout = 5\n",
    "        sqrt(6/9) = 0.82 \n",
    "        randome values between  = randomrange(-0.82,0.82)\n",
    "        \n",
    "He_normal Initialization :normalal ditributed values of mean 0 and sigma\n",
    "    - values = range(0,sigma)\n",
    "    - sigma = sqrt(2/ fan_in)\n",
    "\n",
    "He_uniform Initialization : Uniform distribution of values between a and b\n",
    "    - weights = randomRange(a,b)\n",
    "    - a = -sqrt(6/fan_in) \n",
    "    - b =  sqrt(6/fan_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Weight Regularization : \n",
    "    - Use Weight Regularization to Reduce Overfitting of Deep Learning Models\n",
    "    - A network with large network weights can be a sign of an unstable network where small changes in the input can lead to \n",
    "      large changes in the output.\n",
    "    - This can be a sign that the network has overfit the training dataset and will likely perform poorly when making \n",
    "      predictions on new data.\n",
    "    - A solution to this problem is to update the learning algorithm to encourage the network to keep the weights small. \n",
    "    - This is called weight regularization and it can be used as a general technique to reduce overfitting of the training \n",
    "      dataset and improve the generalization of the model.\n",
    "    - Larger weights result in a larger penalty, in the form of a larger loss score\n",
    "    - The optimization algorithm will then push the model to have smaller weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Weight Constraints: \n",
    "    - functions that impose constraints on weight values.\n",
    "    - Weight constraints provide an approach to reduce the overfitting of a deep learning neural network \n",
    "    - The constraints are specified per-layer, but applied and enforced per-node within the layer\n",
    "    - layer  input : kernel_constraint  and bias : bias_constraint \n",
    "    \n",
    "Constrains :\n",
    "    - MaxNorm weight constraint.\n",
    "    - MinMaxNorm weight constraint\n",
    "    - non-negative weight constraints\n",
    "    - RadialConstraint\n",
    "    - UnitNorm :\n",
    "    \n",
    "Weight Constraints on Layers\n",
    "    - MLP Weight Constraint(Dense) : kernel_constraint; bias_constraint\n",
    "    - CNN Weight Constraint : kernel_constraint; bias_constraint\n",
    "    - RNN Weight Constraint : kernel_constraint; recurrent_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate Weight Size:\n",
    "    - Neural network weights are real-values that can be positive or negative, as such, simply adding the weights is not \n",
    "      sufficient\n",
    "    - Approaches used to calculate the size of the weights,\n",
    "        - Calculate the sum of the absolute values of the weights, called L1. (L1 encourages weights to 0.0 if possible,)\n",
    "        - Calculate the sum of the squared values of the weights, called L2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tips for Using Weight Regularization :\n",
    "    - Standardize Input Data (It is generally good practice to update input variables to have the same scale.)\n",
    "    - It is common for larger networks (more layers or more nodes) to more easily overfit the training data.\n",
    "    - When using weight regularization, it is possible to use larger networks with less risk of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Batch normalization: \n",
    "    - It is a technique designed to automatically standardize the inputs to a layer in a deep learning neural network.\n",
    "    - This layer will transform inputs so that they are standardized, meaning that they will have a mean of zero and a standard \n",
    "      deviation of one.\n",
    "    - The BatchNormalization normalization layer can be used to standardize inputs before or after the activation function of \n",
    "      the previous layer\n",
    "    - for CNN adds batch normalization after the activation function between a convolutional and max pooling layers\n",
    "    - for RNN adds batch normalization after the activation function between an LSTM and Dense hidden layers.\n",
    "    - Batch Normalization depends on mini-batch size and may not work properly for smaller batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loss function or Cost function or Error function : \n",
    "As part of the optimization algorithm, the error for the current state of the model must be estimated repeatedly. \n",
    "it requires loss functions.that can be used to estimate the loss of the model so that the weights can be updated to reduce the \n",
    "loss on the next evaluation.\n",
    "\n",
    "Loss Functions :\n",
    "    - BinaryCrossentropy :\n",
    "    - CategoricalCrossentropy\n",
    "    - CategoricalHinge\n",
    "    - CosineSimilarity\n",
    "    - Hinge\n",
    "    - Huber\n",
    "    - KLD\n",
    "    - KLDivergence\n",
    "    - LogCosh\n",
    "    - MAE\n",
    "    - MAPE\n",
    "    - MSE\n",
    "    - MSLE\n",
    "    - poisson\n",
    "    - mean_squared_error\n",
    "\n",
    "Probabilistic Losses\n",
    "    - Binary Crossentropy (BCE)\n",
    "    - Categorical Crossentropy\n",
    "    - Sparse Categorical Crossentropy\n",
    "    - Poisson\n",
    "    - Kullback-Leibler Divergence\n",
    "    \n",
    "Loss Function:\n",
    "    1. mean_squared_error\n",
    "    2. mean_absolute_error\n",
    "    3. mean_absolute_percentage_error\n",
    "    4. mean_squared_logarithmic_error\n",
    "    5. squared_hinge\n",
    "    6. hinge\n",
    "    7. categorical_hinge\n",
    "    8. logcosh\n",
    "    9. huber_loss\n",
    "    10. categorical_crossentropy\n",
    "    11. sparse_categorical_crossentropy\n",
    "    12. binary_crossentropy\n",
    "    13. kullback_leibler_divergence\n",
    "    14. poisson\n",
    "    15. cosine_proximity\n",
    "    16. is_categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Regression losses\n",
    "    - Mean Squared error\n",
    "    - Mean Absolute Error\n",
    "    - Mean Absolute percentage error\n",
    "    - Mean Squared Logarithmic Error\n",
    "    - Cosine Similarity\n",
    "    - Huber\n",
    "    - Log Cosh\n",
    "\n",
    "Hinge losses for “maximum-margin” classification\n",
    "    - Hinge\n",
    "    - Squared Hinge\n",
    "    - Categorical Hinge\n",
    "    \n",
    "\n",
    "Mean Squared Error Loss : \n",
    "    - The Mean Squared Error, or MSE, loss is the default loss to use for regression problems.\n",
    "    - The average of the squared differences between the predicted and actual values.\n",
    "    \n",
    "Mean Squared Logarithmic Error Loss(MSLE)\n",
    "    - You can first calculate the natural logarithm of each of the predicted values, then calculate the mean squared error.\n",
    "    - Mean squared logarithmic error (MSLE) can be interpreted as a measure of the ratio between the true and predicted values.\n",
    "    - MSLE  is the relative difference between the true and the predicted value, or in other words, it only cares about the \n",
    "      percentual difference between them\n",
    "    - MSLE penalizes underestimates more than overestimates\n",
    "    - RMSLE is usually used when you don't want to penalize huge differences in the predicted and the actual values when both \n",
    "      predicted and true values are huge numbers.\n",
    "      \n",
    "Difference between MSE and MSLE:\n",
    "    - In the case of MSE, the presence of outliers can explode the error term to a very high value (Becasue it is squaring the \n",
    "      value). \n",
    "    - But, in the case of RMLSE the outliers are drastically scaled down therefore nullifying their effect\n",
    "        Ex: MSLE Robustness to the effect of the outliers\n",
    "            Y = 60 80 90;X = 67 78 91 Calculating RMSE = 4.242 and RMSLE = 0.6466\n",
    "            Introduce an outlier in the data\n",
    "            Y = 60 80 90 750; X = 67 78 91 102  RMSE = 374.724 and RMSLE = 1.160 \n",
    "            We can clearly see that the value of the RMSE explodes in magnitude as soon as it encounters an outlier.\n",
    "    - Relative Error\n",
    "        Case 1: Y =100; X=90 RMLSE: 0.1053 and RMSE = 10\n",
    "        Case 2: Y = 10000; X= 9000 RMSLE: 0.1053 and RMSE : 1000\n",
    "        RMSLE metric only considers the relative error between and the Predicted and the actual value and the scale of the \n",
    "        error is not significant.\n",
    "    - Biased Penalty\n",
    "        RMSLE incurs a larger penalty for the underestimation of the Actual variable than the Overestimation\n",
    "        Case 1: Underestimation of Actual Value\n",
    "        Y = 1000;X = 600 RMSE :400 RMSLE : 0.510\n",
    "\n",
    "        Case2: Overestimation of Actual Value\n",
    "        Y = 1000;X = 1400 RMSE :400;RMSLE 0.33\n",
    "\n",
    "Mean Absolute Error Loss \n",
    "    - On some regression problems, the distribution of the target variable may be mostly Gaussian, but may have outliers, e.g. \n",
    "      large or small values far from the mean value.\n",
    "    - The Mean Absolute Error, or MAE, loss is an appropriate loss function in this case as it is more robust to outliers.\n",
    "\n",
    "Binary Classification Loss Functions:\n",
    "    - Binary classification are those predictive modeling problems where examples are assigned one of two labels.\n",
    "\n",
    "    - Binary classification where the target values are in the set {0, 1}\n",
    "\n",
    "Hinge Loss :\n",
    "    - Hinge loss is primarily used with Support Vector Machine (SVM) Classifiers with class labels -1 and 1.\n",
    "    - Hinge Loss not only penalizes the wrong predictions but also the right predictions that are not confident.\n",
    "    - Alternative to cross-entropy for binary classification problems is the hinge loss function\n",
    "    - It is intended for use with binary classification where the target values are in the set {-1, 1}.\n",
    "\n",
    "Squared Hinge Loss :\n",
    "    - simply calculates the square of the score hinge loss\n",
    "    - It has the effect of smoothing the surface of the error function and making it numerically easier to work with\n",
    "    - If using a hinge loss does result in better performance on a given binary classification problem, is likely \n",
    "      that a squared hinge loss may be appropriate.\n",
    "\n",
    "Categorical Cross Entropy :\n",
    "    - It is used when there are two or more label classes present in our problem use case like animal classification:\n",
    "        - Ex: at, dog, elephant, horse\n",
    "    - if your Yi's are one-hot encoded, use categorical_crossentropy\n",
    "        - Examples (for a 3-class classification): [1,0,0] , [0,1,0], [0,0,1]\n",
    "\n",
    "Sparse Categorical Crossentropy loss:\n",
    "    - It is used when there are two or more label classes present in our problem use case like animal classification\n",
    "    - labels are expected to be provided in integers\n",
    "    - Examples for above 3-class classification problem: [1] , [2], [3]\n",
    "\n",
    "Poisson loss:\n",
    "    - The poisson loss function is used for regression when modeling count data.\n",
    "    - The Poisson loss is the mean of the elements of the Tensor y_pred – y_true * log(y_pred)\n",
    "    - Use the Poisson loss when you believe that the target value comes from a Poisson distribution\n",
    "    - Ex: If I am forecasting sales of a product per week (just count of sales per week)\n",
    "\n",
    "Kullback-Leibler Divergence :\n",
    "    - \n",
    "\n",
    "CosineSimilarity loss : \n",
    "    - Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space\n",
    "    - It is just a number between -1 and 1.\n",
    "    - When it is a negative number between -1 and 0,\n",
    "        - 0 indicates orthogonality,\n",
    "        - and values closer to -1 indicate greater similarity\n",
    "\n",
    "Huber :\n",
    "    - Huber loss is both MSE and MAE means it is quadratic(MSE) when the error is small else MAE.\n",
    "    - it depends on an additional parameter call delta that influences the shape of the loss function.\n",
    "    - When the values are large (far from the minima) the function has the behavior of the MAE, closed to the minima, the \n",
    "      function behaves like the MSE. So the delta parameter is your sensitivity to outliers.\n",
    "\n",
    "LogCosh : \n",
    "    - logarithm of the hyperbolic cosine of the prediction error\n",
    "    - logCosh = Summation(log(cosh(ytrue-ypred))\n",
    "    - log(cosh(x)) is approximately equal to (x ** 2) / 2 for small x and to abs(x) - log(2) for large x (x = error)\n",
    "    - logcosh' works mostly like the mean squared error, but will not be so strongly affected by the occasional wildly \n",
    "      incorrect prediction\n",
    "\n",
    "Deciding which loss function to use(MSE and MAE):\n",
    "    - If the outliers represent anomalies that are important for business and should be detected, then we should use MSE\n",
    "    - If we believe that the outliers just represent corrupted data, then we should choose MAE as loss.\n",
    "\n",
    "Outlierss Data:Metrics: Use MAE instead of RMSE as a loss function. We can also use truncated loss:\n",
    "\n",
    "Metrics: Use MAE instead of RMSE as a loss function. We can also use truncated loss:\n",
    "\n",
    "The MSE function is very sensitive to outliers because the difference is a square that gives more importance to outliers\n",
    "\n",
    "The MAE function is more robust to outliers because it is based on absolute value compared to the square of the MSE. It’s like \n",
    "a median, outliers can’t really impact her behavior.\n",
    "\n",
    "targets  are one-hot encoded, use categorical_crossentropy. Examples (for a 3-class classification): [1,0,0] , [0,1,0], [0,0,1]\n",
    "targets are integers, use sparse_categorical_crossentropy. Examples for above 3-class classification problem: [1] , [2], [3]\n",
    "\n",
    "How Optmizations works?\n",
    "    - Any ML or NN are trained using some optimization algorithm with weights are updated using backpropagation of error \n",
    "      algorithm\n",
    "    - The model with a given set of weights is used to make predictions and the error(Loss Function) for those predictions is \n",
    "      calculated\n",
    "    - The gradient descent algorithm seeks to change the weights so that the next evaluation reduces the error.meaning the \n",
    "      optimization algorithm is navigating down the gradient\n",
    "\n",
    "Difference Between Loss function and Metrics?\n",
    "    - The loss function is used to optimize your model. This is the function that will get minimized by the optimizer.\n",
    "    - A metric is used to judge the performance of your model. This is only for you to look at and has nothing to do with the \n",
    "      optimization process.\n",
    "\n",
    "\n",
    "what is Cross-Entropy (Log Loss): \n",
    "    - Cross-entropy is a measure of the difference between two probability distributions for a given random variable or set of \n",
    "      events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Layes in CNN\n",
    "  - Convolutional layer\n",
    "  - Relu Layer\n",
    "  - Pooling layer\n",
    "  - Fully Connected Layer\n",
    "\n",
    "Pooling : Technique to reduce the spatial dimensions of a CNN.It performs down-sampling operations to reduce the dimensionality\n",
    "\n",
    "LSTM : Long-Short-Trem-Memory : Special kind of RNN it is capable of learning long term dependecies,remembering information for\n",
    "long periods as default behaviour.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Vanishing and Exploding Gradients:\n",
    "During the Training of RNN, slode(Griadent) becomes either too small or too large, This makes training difficult.\n",
    "\n",
    "When the slope is too small, the problem is Vanishing Gradient\n",
    "When the slope is tends to grow exponentially instead of decaying, it is called 'Exploding Gradient'\n",
    "This problems leading to Long training time,poor performance,and low accuracy.\n",
    "\n",
    "Epochs : Represnts one itertaion over the entire dataset.\n",
    "\n",
    "Batch : Refers to when we cannot pass the entire dataset into the neural network at once, we divide the dataset into several \n",
    "bataches.\n",
    "\n",
    "Iteration : If we have 10000 images and Batch size of 200, the epoch should be run for 50 iteration(10000 divided by 200)\n",
    "\n",
    "Early Stopping : Method that allows you to specify large number of training epochs but stop training once the model performance \n",
    "stops improving on a holdout validation dataset.\n",
    "\n",
    "Momentum: Momentum helps to know the direction of the next step with the knowledge of the previous steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Why is zero initialization not a good weight initialization process?\n",
    "If the set of weights in the network to a zero, then all the neurons at each layer will start producing the same output and \n",
    "the same gradients during backpropagation.\n",
    "\n",
    "Sigmoid Function(Logistic Function): Transfer input value between 0.0 and 1.0\n",
    "\n",
    "Tanh (Hyperbolic Function) : Transform input value between -1.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Activation Function Types :\n",
    "    - Linear or Identity Activation Function\n",
    "        - Non-linear Activation Functions\n",
    "\n",
    "Linear Activation Function :\n",
    "    - It takes the inputs, multiplied by the weights for each neuron, and creates an output signal proportional to the input.\n",
    "        - Range: (-8, +8)\n",
    "        - Issue : Back-propagation is not possible \n",
    "        - The derivative of the function is a constant, and has no relation to the input, X. So it’s not possible to go back \n",
    "          and understand which weights in the input neurons can provide a better prediction\n",
    "        - All layers of the neural network collapse into one\n",
    "            - with linear activation functions, no matter how many layers in the neural network, the last layer will be a \n",
    "              linear function of the first layer\n",
    "\n",
    "Non Linear Activation Function\n",
    "    - Non-linear functions address the problems of a linear activation function:\n",
    "        - Allow back-propagation because they have a derivative function which is related to the inputs\n",
    "        - They allow “stacking” of multiple layers of neurons to create a deep neural network. Multiple hidden layers of \n",
    "          neurons are needed to learn complex data sets with high levels of accuracy.\n",
    "\n",
    "Activation Functions:\n",
    "\n",
    "    1. relu function : Rectified Linear Activation Function \n",
    "    2. Sigmoid \n",
    "    3. Softmax\n",
    "    4. Softplus\n",
    "    5. Softsign\n",
    "    6. Tanh : Hyperbolic tangent activation function\n",
    "    7. selu : Scaled Exponential Linear Unit \n",
    "    8. elu  : Exponential Linear Unit\n",
    "    9. gelu : Gaussian error linear unit (GELU)\n",
    "    10.hard_sigmoid\n",
    "    11.linear\n",
    "    13.Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Derivative or Differential: Change in y-axis w.r.t. change in x-axis.It is also known as slope\n",
    "\n",
    "Monotonic function: A function which is either entirely non-increasing or non-decreasing.\n",
    "\n",
    "\n",
    "\n",
    "Linear Activation Function : The output of the functions will not be confined between any range.\n",
    "        - Range : (-infinity to infinity)\n",
    "\n",
    "\n",
    "Sigmoid Activation Function :\n",
    "    - The function maps any real value into another value between 0 and  1\n",
    "        - f(x) = s= 1/(1+e??)\n",
    "    - The function is differentiable.That means, we can find the slope of the sigmoid curve at any two points\n",
    "    - Issues\n",
    "        - Vanishing gradient — for very high or very low values of X, there is almost no change to the prediction, causing a \n",
    "          vanishing gradient problem.\n",
    "        - Due to vanishing gradient problem, sigmoids have slow convergence.\n",
    "        - Outputs not zero centered\n",
    "        - Computationally expensive\n",
    "\n",
    "\n",
    "Tan-h / Hyperbolic tangent:\n",
    "    - Equation : f(x) = a =tanh(x) =(ex - e-x)/(ex +e-x)\n",
    "    - Range: (-1, 1)\n",
    "    - Zero centered  : making it easier to model inputs that have strongly negative, neutral, and strongly positive values.\n",
    "    - The function and its derivative both are monotonic\n",
    "    - Works better than sigmoid function\n",
    "    - Issue :\n",
    "        - It also suffers vanishing gradient problem and hence slow convergence.\n",
    "\n",
    "ReLU (Rectified Linear Unit) :\n",
    "    - f(x) = a =max(0,x)\n",
    "    - Range: (0, +8)\n",
    "    - Computationally efficient — allows the network to converge very quickly\n",
    "    - Non-linear - although it looks like a linear function, ReLU has a derivative function and allows for back-propagation\n",
    "    - Issue \n",
    "        - The Dying ReLU problem : when inputs approach zero, or are negative, the gradient of the function becomes zero, the \n",
    "          network cannot perform back-propagation and cannot learn.\n",
    "\n",
    "Leaky ReLU : Introduce  a small slope to keep the update alive\n",
    "    - f(x)= a = max(0.01x, x)\n",
    "    - Range: (0.01, +8)\n",
    "    - Prevents dying ReLU problem : this variation of ReLU has a small positive slope in the negative area, so it does enable \n",
    "      back-propagation, even for negative input values\n",
    "    - Issue :\n",
    "        - Results not consistent — leaky ReLU does not provide consistent predictions for negative input values.\n",
    "        - During the front propagation if the learning rate is set very high it will overshoot killing the neuron\n",
    "\n",
    "Parametric ReLU (PReLU):\n",
    "    - Leaky ReLU has a small slope for negative values, instead of altogether zero\n",
    "    - Parametric ReLU (PReLU) is a type of leaky ReLU that, instead of having a predetermined slope like 0.01\n",
    "    - makes it a parameter for the neural network to figure out itself: y = ax when x < 0 (a = parameter)\n",
    "\n",
    "ELU :  Exponential Linear Unit \n",
    "    - f(x) = x ( if x > 0)\n",
    "          f(x) = a(ex-1) ( if x < 0)\n",
    "    - ELu is variant of Rectiufied Linear Unit (ReLU) that modifies the slope of the negative part of the function.\n",
    "    - If you input an x-value that is greater than zero, then it's the same as the ReLU\n",
    "    - if the input value x is less than 0, we get a value slightly below zero\n",
    "    - Unlike the leaky relu and parametric ReLU functions, instead of a straight line\n",
    "    - The ELU is an excellent alternative to the ReLU – it decreases bias shifts by pushing mean activation towards zero during \n",
    "      the training process.\n",
    "\n",
    "gelu : Gaussian error linear unit (GELU) : \n",
    "    - Gaussian Error Linear Unit. An activation function used in the most recent Transformer (GPT-2 and BERT)\n",
    "    - \n",
    "\n",
    "Softmax : \n",
    "    - # z = np.exp(x); z_ = z/z.sum()\n",
    "    - Softmax function calculates the probabilities distribution of the event over ’n’ different events.\n",
    "    - Range: (0, 1)\n",
    "    - Abilty to handle Multiple Classifcation\n",
    "\n",
    "Softplus : \n",
    "    - log(exp(x) + 1)\n",
    "\n",
    "Softsign :\n",
    "    - x / (abs(x) + 1)\n",
    "    - Similar to tanh functions\n",
    "    - Tanh function that converges exponentially and The softsign function converges in a polynomial form\n",
    "\n",
    "Swish Function:\n",
    "    - f(x) = x*sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recommendation on Activation Functions\n",
    "    - Softmax is used only for the output layer\n",
    "    - Sigmoid and tanh functions are sometimes avoided due to the vanishing gradient problem\n",
    "    - Tanh is avoided most of the time due to dead neuron problem\n",
    "    - ReLU function should only be used in the hidden layers\n",
    "    - An output layer can be linear activation function in case of regression problems.\n",
    "    - Multilayer Perceptron (MLP): ReLU activation function.\n",
    "    - Convolutional Neural Network (CNN): ReLU activation function.\n",
    "    - Recurrent Neural Network: Tanh and/or Sigmoid activation function.\n",
    "    - As a rule of thumb, you can begin with using ReLU function and then move over to other activation functions in case ReLU \n",
    "      doesn’t provide with optimum results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gradient Descent Optimization Algorithms :\n",
    "  - Momentum\n",
    "  - Nesterov’s Accelerated Gradient\n",
    "  - Adagrad\n",
    "  - RMSprop\n",
    "  - Adadelta\n",
    "  - Adam\n",
    "  - Adamax\n",
    "  - Nadam\n",
    "\n",
    "Gradient Descent variants :\n",
    "  - Batch gradient descent: Use whole dataset to compute gradient\n",
    "  - Stochastic gradient descent : Use one data sample to compute gradient\n",
    "  - Mini-batch gradient descent : Use few number of samples(mini-batch) to compute gradient\n",
    "\n",
    "\n",
    "Optimizer :\n",
    "    1. Adadelta : Extension of Adagrad : Adadelta(adaptive delta)\n",
    "    2. Adagrad  : Adaptive Gradient Algorithm\n",
    "    3. Adam     : Adaptive Moment Estimation\n",
    "    4. Adamax   :\n",
    "    5. Ftrl     : Follow The Regularized Leader\n",
    "    6. Nadam    : Nesterov-accelerated Adaptive Moment Estimation\n",
    "    7. RMSprop  : Root Mean Square Propagation \n",
    "    8. SGD      : Stochastic Gradient Descent\n",
    "    \n",
    "Daterministic : models, the output of the model is fully determined by the parameter values and the initial conditions\n",
    "Stochastic : models possess some inherent randomness.The same set of parameter values and initial conditions will lead to an \n",
    "ensemble of different outputs\n",
    "\n",
    "First-order optimization algorithm :\n",
    "    - Momentum\n",
    "    - Nesterov accelerated gradient\n",
    "    - Adagrad\n",
    "    - Adadelta\n",
    "    - RMSprop\n",
    "    - Adam\n",
    "    - Adamax\n",
    "    - Nadam\n",
    "    - AMSGrad\n",
    "\n",
    "Second-order optimization algorithm\n",
    "    - Newton method\n",
    "    - Conjugate gradient\n",
    "    - Quasi-Newton method\n",
    "    - Levenberg-Marquardt algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gradient: First-order derivative for a multivariate objective function.\n",
    "\n",
    "Gradeint Descent : it is a way to optimize the objective function (cost function). by updating weights of GD function.\n",
    "\n",
    "Learning rate : It decides the size of the step we take to reach the minimum of the objective function.\n",
    "\n",
    "Gradient Descent Types\n",
    "    - Batch Gradient Descent (Weights are updated considering whole dataset)\n",
    "    - Stochastic Gradient Descent (Weights are updated considering each training samples in dataset)\n",
    "    - Mini Batch Gradient Descent (weights are updated considering Mini-Batch(n training) samples)\n",
    "\n",
    "Advantages :\n",
    "    Stochatsic Gradient Descent\n",
    "        - Frequent updates of model parameters hence, converges in less time\n",
    "        - Requires less memory as no need to store values of loss functions.\n",
    "        - May get new minima’s.\n",
    "    Mini Batch Gradient Descent\n",
    "        - Frequently updates the model parameters and also has less variance.\n",
    "    Momentum :\n",
    "        - Reduces the oscillations and high variance of the parameters.\n",
    "        - Converges faster than gradient descent.\n",
    "    NAG :\n",
    "        - Does not miss the local minima.\n",
    "        - Slows if minima’s are occurring.\n",
    "    AdaGrad:\n",
    "        - Learning rate changes for each training parameter.\n",
    "        - Don’t need to manually tune the learning rate.\n",
    "        - Able to train on sparse data.\n",
    "    Adadelta :\n",
    "        - Now the learning rate does not decay and the training does not stop.\n",
    "\n",
    "Disadvantages :\n",
    "    Batch Gradient Descent\n",
    "        - It consider complte or whole datset while computing the weights. so it is slow\n",
    "        - May trap at local minima.\n",
    "        - Does't allow update model online\n",
    "        - Weights are changed after calculating gradient on the whole dataset. So, if the dataset is too large than this may \n",
    "          take years to converge to the minima.\n",
    "        - Requires large memory to calculate gradient on the whole dataset.\n",
    "    Stochatsic Gradient Descent\n",
    "        - Since it updates weights frequently for each samples in dataset, so high variance that cause objective function \n",
    "          fluctuate heavly.\n",
    "        - High variance in model parameters.\n",
    "        - May shoot even after achieving global minima.\n",
    "        - To get the same convergence as gradient descent needs to slowly reduce the value of learning rate\n",
    "    Momentum:\n",
    "        - One more hyper-parameter is added which needs to be selected manually and accurately.\n",
    "    AdaGrad :\n",
    "        - The learning rate is always decreasing results in slow training.\n",
    "        - Its main weakness is that its learning rate is always Decreasing and decaying.\n",
    "\n",
    "Disadvantages of Gradient Descent:\n",
    "    - Choosing Learinng rate is difficult\n",
    "        - Too small learning leads to painfully slow convergence.\n",
    "        - Too large learning leads hinder convergence\n",
    "    - Sample learning rate is applies to all the parameters updates. if our data is sparse or scattered and features have very \n",
    "      different frequencies.we might not want to update all of them to the same extent.\n",
    "\n",
    "Strategies for Optimizing SGD:\n",
    "    - Shuffle the training data after every epoch\n",
    "    - Supplying the trainig examples in a meaningful order.\n",
    "    - with using Batch Normalization part of the model we would be able to use higher learning rate and pay less attention to \n",
    "      the initilization parameters\n",
    "    - pay attention and monitor error on a validation set during training and stop if validation error does not improve enough \n",
    "      [Early Stopping]\n",
    "\n",
    "Variations of Gradient Descent\n",
    "    - Momentum : Accelerate the SGD (Speedup the SGD)\n",
    "    - Nesterov Accelerated Gradient\n",
    "    - Adagrad : This is for using Different Learning rate\n",
    "    - Adadelta/RMSProp\n",
    "    - Adam\n",
    "\n",
    "Momentum : \n",
    "    - Momentum takes past gradients into account to smooth out the steps of gradient descent\n",
    "    - Momentum is a method that helps to accelerate SGD in the relevant direction and reduces oscillations(variance)\n",
    "    - Momentum was invented for reducing high variance in SGD and softens the convergence\n",
    "    - It accelerates the convergence towards the relevant direction and reduces the fluctuation to the irrelevant direction. \n",
    "    - One more hyperparameter is used in this method known as momentum \n",
    "\n",
    "SGD without momentum : Update takes longer verticle steps[Slower Learnig] then horizontal steps[faster learning]\n",
    "\n",
    "SGD without momentum : Update takes longer horizontal steps[Fatser Learnig] then verticle steps[Slower learning]\n",
    "\n",
    "Problem of Momemtum :\n",
    "    - Think of the problem like rolling a ball from the hill top , it will rest in the valley(Minima value) for sure but it \n",
    "      will oscillate(Swing) to and from near the valley before resting.\n",
    "\n",
    "NAG : \n",
    "    - Momentum may be a good method but if the momentum is too high the algorithm may miss the local minima and may continue to \n",
    "      rise up.\n",
    "    - It is a look ahead method.\n",
    "    - We’d like to have a smarter ball, a ball that has a notion of where it is going so that it knows to slow down before the \n",
    "      hill slopes up again.\n",
    "    - Nesterov momentum has slightly less overshooting compare to standard momentum\n",
    "    \n",
    "Common mini-batch sizes range between 50 and 256\n",
    "\n",
    "Advantges of NAG over Momentum : \n",
    "    - The oscillations are smaller and the chances of escaping the minima valley also smaller.\n",
    "\n",
    "Why need of AdaGrad?\n",
    "    - Idea of AdaGrad is that different learning rate(?) for different feature at each iteration(time) depending on their \n",
    "      importance\n",
    "\n",
    "\n",
    "Sample problem example why need of AdaGrad :\n",
    "    -  Let us consider the dataset which has dense features and sparse feature. During training if learning rate (?) is fixed \n",
    "       to some value (Say ? =0.001) then training happens with same eta across the dataset. Okay well and good.But there is a \n",
    "       problem,if the feature is dense[Word2vec] then there updates will be faster and when the feature are sparse [BOW]then \n",
    "       updates will be slower.\n",
    "\n",
    "    - Hence this will result in slower convergence.To avoid this problem we come with technique called Adaptive Gradient\n",
    "\n",
    "Problem with AdaGrad : \n",
    "    - In the AdaGrad equation when denominator accumulation of the squared gradients. since every added term is positive the \n",
    "      accumulated sums keeps growing Casuing the learning rate to shrink and eventually becomes very very small resulting in \n",
    "      “very slow convergence” and “vanishing gradient problem”.\n",
    "\n",
    "AdaDelta and RMSprop : \n",
    "    - It is an extension of AdaGrad which tends to remove the decaying learning Rate problem of it.\n",
    "    - RMSprop deals with the above issue by using a moving average of squared gradients to normalize the gradient.\n",
    "    - AdaDelta and RMSprop both are small enhancement over AdaGrad.\n",
    "    - solves the problem of slower convergence is addressed by these algorithms.\n",
    "    - Instead inefficeintly storing all prevoious squared gradients, recursilvely reducing the same by averaging of all the \n",
    "      past squared gradients.which keeps learing rate optimally high\n",
    "    - This normalization balances the step size (momentum), decreasing the step for large gradients to avoid exploding and \n",
    "      increasing the step for small gradients to avoid vanishing.\n",
    "    - RMSprop uses an adaptive learning rate instead of treating the learning rate as a hyperparameter. This means that the \n",
    "      learning rate changes over time.\n",
    "\n",
    "Adam((Adaptive Moment Estimation) = Momentum + RMSProp\n",
    "\n",
    "\n",
    "Why do we need different learning rates?\n",
    "    - Data sets have two types of features:\n",
    "        - Dense features, e.g. House Price Data set (Large number of non-zero valued features), where we should perform smaller \n",
    "          updates on such features; and\n",
    "        - Sparse Features, e.g. Bag of words (Large number of zero valued features), where we should perform larger updates on \n",
    "          such features.\n",
    "\n",
    "Adadelta :\n",
    "It is an extension of AdaGrad which tends to remove the decaying learning Rate problem of it. Instead of accumulating all \n",
    "previously squared gradients, Adadelta limits the window of accumulated past gradients to some fixed size w. \n",
    "In this exponentially moving average is used rather than the sum of all the gradients.\n",
    "\n",
    "How AdaDelta and RMSprop differes from AdaGrad\n",
    "    - Idea of AdaDelta and RMSprop is that instead simply using the square root summation of squared history gradient why can’t \n",
    "      we use exponential decaying average(eda)/exponentially moving average /running average.\n",
    "\n",
    "\n",
    "Adam ( Adaptive moment estimator): \n",
    "    - Idea of Adam optimizer is that instead of only using the exponentially weighted average of square of history of gradients,\n",
    "      why can’t we use the exponentially weighted average of square of history of gradients .\n",
    "\n",
    "\n",
    "When to use it?\n",
    "    - Mini Batch SGD -->  use when network is small or shallow\n",
    "    - Momentum with GD/ SGD --> Works well most of the cases but slighly slower in converges\n",
    "    - AdaGrad/AdaDelte/RMSProp --> Use when there is sparse data\n",
    "    - Adam and Its Variation --> Always Recommended\n",
    "\n",
    "Note : (Optimization Algorithms)\n",
    "    - If the learning rate is too small than gradient descent may take ages(long time) to converge\n",
    "    - Momentum was invented for reducing high variance in SGD (weights updated for every values in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metrics :\n",
    "\n",
    "    1. AUC : Area Under Curve\n",
    "    2. Accuracy\n",
    "    3. Binary Accuracy\n",
    "    4. BinaryCrossEntropy\n",
    "    5. CategoricalAccuracy\n",
    "    6. CategoricalCrossEntropy\n",
    "    7. CategoricalHinge\n",
    "    8. CosineSimilarity\n",
    "    9. FalseNegative\n",
    "    10. FalsePositive\n",
    "    11. Hinge\n",
    "    12. KLDivergence\n",
    "    13. LogCoshError\n",
    "    14. Mean\n",
    "    15. MeanAbolsuteError\n",
    "    16. MeanAbsolutePercentageError\n",
    "    17. MeanIou\n",
    "    18. MeanRelatievError\n",
    "    19. MeanSqaredError\n",
    "    20. MeanSquaredLogarithmicError\n",
    "    21. MeanTensor\n",
    "    22. Poission\n",
    "    23. PrecisionAtRecall\n",
    "    24. Recall\n",
    "    25. RecallAtPrecision\n",
    "    26. RootMeanSquaredError\n",
    "    27. SensitivityAtSpecificity\n",
    "    28. SparseCatgoricalAccuracy\n",
    "    29. SparseTopKCategoricalAccuracy\n",
    "    30.SpecificityAtSensivity\n",
    "    31.SquardHinge\n",
    "    32. Sum\n",
    "    33. TopKCategoricalAccuracy\n",
    "    34. TrueNegative\n",
    "    35 TruePositives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LSTM : It is having 3 gates (Input;Output and Forget)\n",
    "GRU : It is having 2 gates (Reset and Updates)\n",
    "\n",
    "Componenets of LSTM : \n",
    "  - Forget Gate “f” ( a NN with sigmoid)\n",
    "  - Candidate layer “C\"(a NN with Tanh)\n",
    "  - Input Gate “I” ( a NN with sigmoid )\n",
    "  - Output Gate “O”( a NN with sigmoid)\n",
    "  - Hidden state “H” ( a vector )\n",
    "  - Memory state “C” ( a vector)\n",
    "  - Inputs to the LSTM cell at any step are Xt (current input) , Ht-1 (previous hidden state ) and Ct-1 (previous memory state).\n",
    "  - Outputs from the LSTM cell are Ht (current hidden state ) and Ct (current memory state)\n",
    "\n",
    "Single LSTM : The original LSTM model is comprised of a single hidden LSTM layer followed by a standard feedforward output \n",
    "layer.\n",
    "\n",
    "The Stacked LSTM is an extension to this model that has multiple hidden LSTM layers where each layer contains multiple memory \n",
    "cells.\n",
    "\n",
    "Bidirectional LSTM : It depends on type of applications and there is no single answer as only empirical analysis can answer \n",
    "it correctly. You should use it in the applications where getting the past and future information can improve the performance.\n",
    "\n",
    "When To use Bidirectional LSTM : \n",
    "Let us take an example of missing word generation in the I am ___ student.\n",
    "Unidirectional LSTMs will use only ‘I am’ to generate next word and based on the example it has seen during training it will \n",
    "generate a new word (it may be ‘a’, ‘very’ etc.). \n",
    "But bidirectional LSTMs have information of past (I am) and future (student), so it can easily see that here it has to be a. \n",
    "\n",
    "Standard LSTM : it can have access to only the past information and hence the output can only be generated based on what the \n",
    "network has seen(Past data)\n",
    "\n",
    "Bidirectional LSTMs : It has two networks, one access information in forward direction and another access in the reverse \n",
    "direction.\n",
    "These networks have access to the past as well as the future information and hence the output is generated from both the \n",
    "past and future context.\n",
    "\n",
    "Input to LSTM : input to every LSTM layer must be three-dimensional with shape(Samples, Timesteps, Features).\n",
    "\n",
    "Univariate LSTM :  the number of features is 1\n",
    "\n",
    "epochs : Numbr of times the model is exposed to the training set.At each iteration, the optimizer tries to adjest the weights \n",
    "so that the objectives function is minimized\n",
    "\n",
    "Batch_size : Number of instance of the training oberved before the optimizer perform a weight update\n",
    "\n",
    "Hyperparameter tuning is the process of finding the optimal combination of parameters that minimize cost functions.\n",
    "\n",
    "Improving Simple Keras Network :\n",
    "    - By adding additional layers (Hidden)\n",
    "    - Randomly drop with the dropout probability some of the values propagated\n",
    "    - Try different Optimizers  (RMSProp,Adam,SGD)\n",
    "    - Increasing number of epochs(20 to 200) : Increasing  the value by 10\n",
    "    - Controlling Optimizer learning rate[0.1,0.01,0.001,0.001,0.0001,0.0001] = [1E-0, 1E-1, 1E-2, 1E-3, 1E-4, 1E-5, 1E-6, 1E-7]\n",
    "    - Increasing the number of internal hidden neurons [32,64,128,255,512,1024]\n",
    "    - Increasing the size of batch computation[64,128,256,512]\n",
    "    - try Different Types of regularization(L1 regularization;L2 regularization; Elastic net regularization:)\n",
    "\n",
    "Hyperamaters in Optimizers :\n",
    "    - SGD - (Learning rate,decay)\n",
    "    - AdaGrad - (Learning rate, epsilon,decay)\n",
    "    - AdaDelta - (Learning rate, rho, epsilon, decay)\n",
    "    - Adam - (Learning rate, beta1,beta2,epsilon,decay)\n",
    "    - RMSProp - (Learning rate,rho,epsilon,decay)\n",
    "    - Momentum - (Learning rate,momentum,decay)\n",
    "    - Nesterov Accelerated Gradient(NAG) - (Learning rate,momentum,decay)\n",
    "\n",
    "Word Embedding : Dense vector representation of a word or document.\n",
    "\n",
    "Word Embedding Arguments\n",
    "    - input_dim : Size of Vocabulary in the text data.\n",
    "    - output_dim : Vector space in which words will be embedded(dimensions)\n",
    "    - input_length : length of the input sequence\n",
    "\n",
    "Top Deep learning Algorithms You Should Know about :\n",
    "    - Convolutional Neural network\n",
    "    - Long Short Term Memory Network\n",
    "    - Recurrent Neural Network\n",
    "    - Generative Adversarial Network\n",
    "    - Radial Basis Function Network\n",
    "    - Multilayer Perceptron\n",
    "    - Self Organizing Map\n",
    "    - Deep Belief Network\n",
    "    - Restricted Boltzmanm Machine\n",
    "    - Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A potential drawback with one-hot encoded feature vector approaches such as N-Grams, bag of words and TF-IDF approach is that \n",
    "the feature vector for each document can be huge. For instance, if you have a half million unique words in your corpus and you \n",
    "want to represent a sentence that contains 10 words, your feature vector will be a half million dimensional one-hot encoded \n",
    "vector where only 10 indexes will have 1. This is a wastage of space and increases algorithm complexity exponentially resulting \n",
    "in the curse of dimentionality.\n",
    "\n",
    "The words that are similar will have similar vector. Word embeddings techniques such as GloVe and Word2Vec have proven to be \n",
    "extremely efficient for converting words into corresponding dense vectors. The vector size is small and none of the indexes in \n",
    "the vector is actually empty.\n",
    "\n",
    "The Dense layer takes three regularizers, which all default to None. These are kernel_regularizer(applied to weights), \n",
    "bias_regularizer(applied to bias unit), and activity_regularizer(applied to layer activation).\n",
    "\n",
    "\n",
    "BatchNormalization :\n",
    "Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each \n",
    "mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs \n",
    "required to train deep networks.\n",
    "\n",
    "\n",
    "All types of Gradient Descent have some challenges:\n",
    "Choosing an optimum value of the learning rate. If the learning rate is too small than gradient descent may take ages to \n",
    "converge.\n",
    "Have a constant learning rate for all the parameters. There may be some parameters which we may not want to change at the \n",
    "same rate. May get trapped at local minima.\n",
    "\n",
    "\n",
    "Gradient Clipping ;\n",
    "Gradient clipping is a technique that tackles exploding gradients. The idea of gradient clipping is very simple: If the gradient\n",
    "gets too large, we rescale it to keep it small. More precisely, if ?g? = c, then\n",
    "\n",
    "g ? c · g/?g?\n",
    "\n",
    "where c is a hyperparameter, g is the gradient, and ?g? is the norm of g. Since g/?g? is a unit vector, after rescaling the new \n",
    "g will have norm c. Note that if ?g? < c, then we don’t need to do anything.\n",
    "\n",
    "\n",
    "Exploding and Vanishing Gradients :\n",
    "Exploding gradients refer to the problem that the gradients get too large in training, making the model unstable. Similarly, \n",
    "vanishing gradients refer to gradients getting too small in training. This prevents the network weights from changing their \n",
    "values.\n",
    "\n",
    "Learning Rate Schedules:\n",
    "    - Constant Learning Rate\n",
    "    - Time-based decay\n",
    "    - Step Decay\n",
    "    - Exponential Decay\n",
    "    \n",
    "- Too small a learning rate and your neural network may not learn at all and it requires many updates \n",
    "   before reaching the minimal point\n",
    "- Too large a learning rate and you may overshoot areas of low loss \n",
    "- oscillations in behavior for the too-large learning rate of 1.0\n",
    "- Inability of the model to learn anything with the too-small learning rates of 1E-6 and 1E-7.\n",
    "\n",
    "\n",
    "Poor choice of learning rate that results in large weight updates.\n",
    "Poor choice of data preparation, allowing large differences in the target variable.\n",
    "Poor choice of loss function, allowing the calculation of large error values.\n",
    "\n",
    "\n",
    "Gradient Scaling.\n",
    "Gradient Clipping.\n",
    "\n",
    "\n",
    "Gradient scaling involves normalizing the error gradient vector such that vector norm (magnitude) equals a defined value, such \n",
    "as 1.0.\n",
    "\n",
    "\n",
    "Gradient clipping involves forcing the gradient values (element-wise) to a specific minimum or maximum value if the gradient \n",
    "exceeded an expected range.\n",
    "\n",
    "random_uniform: Weights are initialized to uniformly random small values in (-0.05, 0.05).\n",
    "\n",
    "random_normal: Weights are initialized according to a Gaussian, with a zero mean and small standard deviation of 0.05.\n",
    "\n",
    "zero: All weights are initialized to zero.\n",
    "\n",
    "Improving The Keras Model \n",
    "\t- Add additional layers to our network(Hidden layers with neurons)\n",
    "\t- Improving the simple net in Keras with dropout\n",
    "\t- Testing different optimizers in Keras\n",
    "\t- Increasing the number of epochs\n",
    "\t- Controlling the optimizer learning rate\n",
    "\t- Increasing the number of internal hidden neurons\n",
    "\t- Increasing the size of batch computation(Batch Size)\n",
    "\t- Adopting regularization for avoiding overfitting\n",
    "\t- Hyperparameters tuning\n",
    "\t\t- hidden neurons, BATCH_SIZE,epochs,\t\n",
    "\n",
    "\n",
    "How to select the right regression model?\n",
    "Life is usually simple, when you know only one or two techniques. One of the training institutes I know of tells their students \n",
    "– if the outcome is continuous – apply linear regression. If it is binary – use logistic regression! However, higher the number \n",
    "of options available at our disposal, more difficult it becomes to choose the right one. A similar case happens with regression \n",
    "models.\n",
    "\n",
    "Within multiple types of regression models, it is important to choose the best suited technique based on type of independent \n",
    "and dependent variables, dimensionality in the data and other essential characteristics of the data. Below are the key factors \n",
    "that you should practice to select the right regression model:\n",
    "\n",
    "Data exploration is an inevitable part of building predictive model. It should be you first step before selecting the right \n",
    "model like identify the relationship and impact of variables\n",
    "To compare the goodness of fit for different models, we can analyse different metrics like statistical significance of \n",
    "parameters, R-square, Adjusted r-square, AIC, BIC and error term. Another one is the Mallow’s Cp criterion. This essentially \n",
    "checks for possible bias in your model, by comparing the model with all possible submodels (or a careful selection of them).\n",
    "Cross-validation is the best way to evaluate models used for prediction. Here you divide your data set into two group (train \n",
    "and validate). A simple mean squared difference between the observed and predicted values give you a measure for the prediction\n",
    "accuracy.\n",
    "If your data set has multiple confounding variables, you should not choose automatic model selection method because you do not\n",
    "want to put these in a model at the same time.\n",
    "It’ll also depend on your objective. It can occur that a less powerful model is easy to implement as compared to a highly \n",
    "statistically significant model.\n",
    "Regression regularization methods(Lasso, Ridge and ElasticNet) works well in case of high dimensionality and multicollinearity \n",
    "among the variables in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Autoencoder\n",
    "    - Autoencoders are a specific type of feedforward neural networks where the input is the same as the output\n",
    "    - They compress the input into a lower-dimensional code and then reconstruct the output from this representation.\n",
    "    - An autoencoder consists of 3 components: encoder, code and decoder. \n",
    "    - The encoder compresses the input and produces the code, the decoder then reconstructs the input only using this code.\n",
    "    - Autoencoders are mainly a dimensionality reduction (or compression) algorithm with a couple of important properties.\n",
    "    - Autoencoders are a very useful dimensionality reduction technique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
